{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#pixeltable-the-multimodal-ai-data-plane","title":"Pixeltable: The Multimodal AI Data Plane","text":"<p>Pixeltable is a Python library that lets AI engineers and data scientists focus on exploration, modeling, and app development without having to deal with the customary data plumbing.</p> <p>Pixeltable redefines data infrastructure and workflow orchestration for AI development. It brings together data storage, versioning, and indexing with orchestration and model versioning under a declarative table interface, with transformations, model inference, and custom logic represented as computed columns.</p>"},{"location":"#installation","title":"Installation","text":"<p>Pixeltable works with Python 3.9, 3.10, or 3.11 running on Linux or MacOS.</p> <pre><code>pip install pixeltable\n</code></pre> <p>To verify that it's working:</p> <pre><code>import pixeltable as pxt\ncl = pxt.Client()\n</code></pre> <p>For more detailed installation instructions, see the Getting Started with Pixeltable guide. Then, check out the Pixeltable Basics tutorial for a tour of its most important features.</p>"},{"location":"#what-problems-does-pixeltable-solve","title":"What problems does Pixeltable solve?","text":"<p>Today\u2019s solutions for AI app development require extensive custom coding and infrastructure plumbing. Tracking lineage and versions between and across data transformations, models, and deployment is cumbersome. Pixeltable is a replacement for traditional data plumbing, providing a unified plane for data, models, and orchestration. It removes the data plumbing overhead in building and productionizing AI applications.</p>"},{"location":"#why-should-you-use-pixeltable","title":"Why should you use Pixeltable?","text":"<ul> <li>It gives you transparency and reproducibility<ul> <li>All generated data is automatically recorded and versioned</li> <li>You will never need to re-run a workload because you lost track of the input data</li> </ul> </li> <li>It saves you money<ul> <li>All data changes are automatically incremental</li> <li>You never need to re-run pipelines from scratch because you\u2019re adding data</li> </ul> </li> <li>It integrates with any existing Python code or libraries<ul> <li>Bring your ever-changing code and workloads</li> <li>You choose the models, tools, and AI practices (e.g., your embedding model for a vector index); Pixeltable orchestrates the data</li> </ul> </li> </ul>"},{"location":"#example-use-cases","title":"Example Use Cases","text":"<ul> <li>Interact with video data at the frame level without having to think about frame extraction, intermediate file storage, or storage space explosion.</li> <li>Augment your data incrementally and interactively with built-in functions and UDFs, such as image transformations, model inference, and visualizations, without having to think about data pipelines, incremental updates, or capturing function output.</li> <li>Interact with all the data relevant to your AI application (video, images, documents, audio, structured data, JSON) through a simple dataframe-style API directly in Python. This includes:<ul> <li>similarity search on embeddings, supported by high-dimensional vector indexing</li> <li>path expressions and transformations on JSON data</li> <li>PIL and OpenCV image operations</li> <li>assembling frames into videos</li> </ul> </li> <li>Perform keyword and image similarity search at the video frame level without having to worry about frame storage.</li> <li>Access all Pixeltable-resident data directly as a PyTorch dataset in your training scripts.</li> <li>Understand the compute and storage costs of your data at the granularity of individual augmentations and get cost projections before adding new data and new augmentations.</li> <li>Rely on Pixeltable's automatic versioning and snapshot functionality to protect against regressions and to ensure reproducibility.</li> </ul>"},{"location":"api_cheat_sheet/","title":"API Cheat Sheet","text":"<p>Import conventions:</p> <pre><code>import pixeltable as pxt\nimport pixeltable.functions as pxtf\n</code></pre> <p>Creating a client</p> <pre><code>cl = pxt.Client()\n</code></pre>"},{"location":"api_cheat_sheet/#client-operations-summary","title":"Client operations summary","text":"Task Code Create a (mutable) table t = cl.create_table('table_name', {'col_1': pxt.StringType(), 'col_2': pxt.IntType(), ...}) Create a view t = cl.create_view('view_name', base_tbl, schema={'col_1': pxt.StringType, ...}, filter=base_tbl.col &gt; 10) Create a snapshot t = cl.create_view('snapshot_name', t, is_snapshot=True) <p>The following functions apply to tables, views, and snapshots.</p> Task Code Use an existing table t = cl.get_table('video_data') Rename a table cl.move('video_data', 'vd') Move a table cl.move('video_data', 'experiments.video_data') List tables cl.list_tables() Delete a table cl.drop_table('video_data')"},{"location":"api_cheat_sheet/#directories","title":"Directories","text":"Task Code Create a directory cl.create_dir('experiments') Rename or move a directory cl.move('experiments', 'project_x.experiments') Delete a directory f = cl.rm_dir('experiments') List directories cl.list_dirs('project_x')"},{"location":"api_cheat_sheet/#functions","title":"Functions","text":"Task Code Create a stored function cl.create_function('func_name', ...) Load a stored function f = cl.get_function('func_name') Rename a stored function cl.move('func_name', 'better_name') Move a stored function cl.move('func_name', 'experiments.func_name') Update a stored function cl.update_function('func_name', ...) Delete a stored function cl.drop_function('func_name')"},{"location":"api_cheat_sheet/#frame-extraction-for-video-data","title":"Frame extraction for video data","text":"<p>Create a table with video data and view for the frames:</p> <pre><code>v = cl.create_table('tbl_name', [pxt.Column('video', pxt.VideoType())])\nfrom pixeltable.iterators import FrameIterator\nargs = {'video': v.video, 'fps': 0}\nf = cl.create_view('frame_view_name', v, iterator_class=FrameIterator, iterator_args=args)\n</code></pre> <p><code>fps: 0</code> extracts frames at the original frame rate.</p>"},{"location":"api_cheat_sheet/#pixeltable-types","title":"Pixeltable types","text":"Pixeltable type Python type <code>pxt.StringType()</code> <code>str</code> <code>pxt.IntType()</code> <code>int</code> <code>pxt.FloatType()</code> <code>float</code> <code>pxt.BoolType()</code> <code>bool</code> <code>pxt.TimestampType()</code> <code>datetime.datetime</code> <code>pxt.JsonType()</code> lists and dicts that can be converted to JSON <code>pxt.ArrayType()</code> <code>numpy.ndarray</code> <code>pxt.ImageType()</code> <code>PIL.Image.Image</code> <code>pxt.VideoType()</code> <code>str</code> (the file path) <code>pxt.AudioType()</code> <code>str</code> (the file path)"},{"location":"api_cheat_sheet/#table-operations-summary","title":"Table operations summary","text":"Action Code Print table schema t.describe() Query a table t.select(t.col2, t.col3 + 5).where(t.col1 == 'green').show() Insert a single row into a table t.insert(col1='green', ...) Insert multiple rows into a table t.insert([{'col1': 'green', ...}, {'col1': 'red', ...}, ...]) Add a column t.add_column(new_col_name=pxt.IntType()) Rename a column t.rename_column('col_name', 'new_col_name') Drop a column t.drop_column('col_name') Undo the last update operation (add/rename/drop column or insert) t.revert()"},{"location":"api_cheat_sheet/#querying-a-table","title":"Querying a table","text":"Action Code Look at 10 rows t.show(10) Look at the oldest 10 rows t.head(n=10) Look at the most recently added 10 rows t.tail(n=10) Look at all rows t.collect() Iterate over all rows as dictionaries for row in t.collect(): ... Look at row for frame 15 t.[where][pixeltable.Table.where}(t.pos  == 15).show() Look at rows before index 15 t.where(t.pos &lt; 15).show(0) Look at rows before index 15 with RGB frames t.where((t.pos &lt; 15) &amp; (t.frame.mode == 'RGB')).collect() <p>Pixeltable supports the standard comparison operators (<code>&gt;=</code>, <code>&gt;</code>, <code>==</code>, <code>&lt;=</code>, <code>&lt;</code>). <code>== None</code> is the equivalent of <code>isna()/isnull()</code> in Pandas.</p> <p>Boolean operators are the same as in Pandas: <code>&amp;</code> for <code>and</code>, <code>|</code> for <code>or</code>, <code>~</code> for <code>not</code>. They also require parentheses, for example: <code>(t.pos &lt; 15) &amp; (t.frame.mode == 'RGB')</code> or <code>~(t.frame.mode == 'RGB')</code>.</p>"},{"location":"api_cheat_sheet/#selecting-and-transforming-columns","title":"Selecting and transforming columns","text":"Action Code Only retrieve the frame index and frame t.select(t.frame_idx, t.frame).collect() Look at frames rotated 90 degrees t.select(t.frame.rotate(90)).collect() Overlay frame with itself rotated 90 degrees t.select(pxt.functions.pil.image.blend(t.frame, t.frame.rotate(90))).collect()"},{"location":"api_cheat_sheet/#computed-columns","title":"Computed columns","text":"<p>The values in a computed column are automatically filled when data is added:</p> <pre><code>t.add_column(c_added=t.frame.rotate(30))\n</code></pre> <p>Alternatively:</p> <pre><code>t['c_added'] = t.frame.rotate(30)\n</code></pre> <p>Computed columns and media columns (video, image, audio) have attributes <code>errortype</code> and <code>errormsg</code>, which contain the exception type and string in rows where the computation expression or media type validation results in an exception (the column value itself will be <code>None</code>).</p> <p>Example:</p> <pre><code>t.where(t.c_added.errortype != None).select(t.c_added.errortype, t.c_added.errormsg).show()\n</code></pre> <p>returns the exception type and message for rows with an exception.</p>"},{"location":"api_cheat_sheet/#inserting-data-into-a-table","title":"Inserting data into a table","text":"<pre><code>t.insert([{'video': '/path/to/video1.mp4'}, {'video': '/path/to/video2.mp4'}])\n</code></pre> <p>Each row is a dictionary mapping column names to column values (do not provide values for computed columns).</p>"},{"location":"api_cheat_sheet/#attributes-and-methods-on-image-data","title":"Attributes and methods on image data","text":"<p>Images are currently represented as <code>PIL.Image.Image</code> instances in memory and support a lot of the attributes and methods documented here.</p> <p>Available attributes are: <code>mode</code>, <code>height</code>, <code>width</code>.</p> <p>Available methods are: <code>convert</code>, <code>crop</code>, <code>effect_spread</code>, <code>entropy</code>, <code>filter</code>, <code>getbands</code>, <code>getbbox</code>, <code>getchannel</code>, <code>getcolors</code>, <code>getextrema</code>, <code>getpalette</code>, <code>getpixel</code>, <code>getprojection</code>, <code>histogram</code>, <code>point</code>, <code>quantize</code>, <code>reduce</code>, <code>remap_palette</code>, <code>resize</code>, <code>rotate</code>, <code>transform</code>, <code>transpose</code>.</p> <p>Methods can be chained, for example: <code>t.frame.resize((224, 224)).rotate(90).convert('L')</code></p>"},{"location":"api_cheat_sheet/#functions_1","title":"Functions","text":"<p>Functions can be used to transform data, both during querying as well as when data is added to a table.</p> <pre><code>@pxt.udf(return_type=pxt.IntType(), param_types=[pxt.IntType()])\ndef add1(x):\n    return x + 1\n</code></pre> <p>For querying: <code>t.select(t.frame_idx, add1(t.frame_idx)).show()</code></p> <p>As a computed column: <code>t.add_column(c=add1(t.frame_idx))</code></p>"},{"location":"differences_with_pandas/","title":"Differences with Pandas","text":"Pandas Pixeltable reading data Read from file system with <code>pd.read_*</code> methods: eg, <code>.csv</code>, <code>.json</code>, <code>.parquet</code>, etc. In <code>pixeltable</code>, data is stored in tables. <code>cl.list_tables</code>, <code>tab = cl.get_table('mytable')</code> saving data (fist time) Save to file system, format of choice <code>table.insert</code> updating data to update data persistently, use <code>pd.write_*()</code>  to over-write or save new versions of the dataset <code>table.update</code> statements on tables allow for fine-grained persistent updates only on columns with specific values selecting rows <code>df[ df.col &gt; 1 ]</code> <code>tab.where(tab.col &gt; 1)</code> selecting rows (predicates) <code>df[(df.a &gt; 0) &amp; (df.b &gt; 0)]</code> <code>df.where((df.a &gt; 0) &amp; (df.b &gt; 0))</code> both will error if <code>and</code> or <code>or</code> is used. selecting columns (aka projection) <code>df[['col']]</code> <code>tab.select(tab.col)</code> new column with computed value <code>df.assign(new_col= fun(df.input_col1, df.input_col2,..))</code> or <code>df['new_col'] = fun(df.input_col1, df.input_col2,..))</code> (the latter acts in-place, modifying the df object) <code>tab.select(old_colA, old_colB,  new_col=fun(tab.input_col1, tab.input_col2,...))</code> computing new values row by row <code>df['new_col'] = df.apply(fun, axis=1)</code> <code>df.select(old_colA, old_colB, ..., new_col=pxt.function(fun)(tab.input_col1, tab.input_col2,...)</code>"},{"location":"getting-started/","title":"Getting Started with Pixeltable","text":"<p>This is a step-by-step guide to setting up a local installation of Pixeltable.</p> <p>You'll want to install Pixeltable in a Python virtual environment; we'll use Apache Miniconda in this guide, but any environment manager should work. Pixeltable works with Python 3.9, 3.10, or 3.11 running on Linux or MacOS.</p>"},{"location":"getting-started/#install-pixeltable","title":"Install Pixeltable","text":"<ol> <li>Install Miniconda here:</li> <li>Installing Miniconda</li> <li>Create your environment:</li> <li><code>conda create --name pxt python=3.10</code></li> <li><code>conda activate pxt</code></li> <li>Install pixeltable and Jupyter inside the new environment:</li> <li><code>pip install pixeltable jupyter</code></li> </ol>"},{"location":"getting-started/#create-a-notebook","title":"Create a Notebook","text":"<ol> <li>Start your Jupyter notebook server and create a new notebook:</li> <li><code>jupyter notebook</code></li> <li>Select \"Python 3 (ipykernel)\" as the kernel</li> <li>File / New / Notebook</li> <li>Test that everything is working by entering these commands into the notebook:</li> <li> <p><code>import pixeltable as pxt      cl = pxt.Client()</code></p> </li> <li> <p>Wait a minute for Pixeltable to load; then you should see a message indicating that    Pixeltable has successfully connected to the database.</p> </li> </ol> <p>At this point, you're set up to start using pixeltable! For a tour of what it can do, a good place to start is the Pixeltable Basics tutorial.</p>"},{"location":"api/client/","title":"Client","text":"<p>Use instances of pixeltable.Client to create and manage tables, snapshots, functions, and directories in the database.</p> <p>Insertable tables, views and snapshots of these all have a tabular interface and are generically referred to as \"tables\" below.</p>"},{"location":"api/client/#overview","title":"Overview","text":"Table Operations <code>create_table</code> Create a new (insertable) table <code>create_view</code> Create a new view <code>drop_table</code> Delete a table <code>get_table</code> Get a handle to a table <code>list_tables</code> List the tables in a directory Directory Operations <code>create_dir</code> Create a directory <code>rm_dir</code> Remove a directory <code>list_dirs</code> List the directories in a directory Misc <code>move</code> Move a schema object to a new directory and/or rename a schema object <code>logging</code> Configure logging"},{"location":"api/client/#pixeltable.Client","title":"pixeltable.Client","text":"<p>Client for interacting with a Pixeltable environment.</p>"},{"location":"api/client/#pixeltable.Client.__init__","title":"__init__","text":"<pre><code>__init__(reload: bool = False) -&gt; None\n</code></pre> <p>Constructs a client.</p>"},{"location":"api/client/#pixeltable.Client.create_table","title":"create_table","text":"<pre><code>create_table(path_str: str, schema: Dict[str, Any], primary_key: Optional[Union[str, List[str]]] = None, num_retained_versions: int = 10, comment: str = '') -&gt; InsertableTable\n</code></pre> <p>Create a new <code>InsertableTable</code>.</p> <p>Parameters:</p> <ul> <li> <code>path_str</code>             (<code>str</code>)         \u2013          <p>Path to the table.</p> </li> <li> <code>schema</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>dictionary mapping column names to column types, value expressions, or to column specifications.</p> </li> <li> <code>num_retained_versions</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Number of versions of the table to retain.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>InsertableTable</code>         \u2013          <p>The newly created table.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>if the path already exists or is invalid.</p> </li> </ul> <p>Examples:</p> <p>Create a table with an int and a string column:</p> <pre><code>&gt;&gt;&gt; table = cl.create_table('my_table', schema={'col1': IntType(), 'col2': StringType()})\n</code></pre> <p>Create a table with a single indexed image column:</p> <pre><code>&gt;&gt;&gt; table = cl.create_table('my_table', schema={'col1': {'type': ImageType(), 'indexed': True}})\n</code></pre>"},{"location":"api/client/#pixeltable.Client.create_view","title":"create_view","text":"<pre><code>create_view(path_str: str, base: Table, *, schema: Optional[Dict[str, Any]] = None, filter: Optional[Predicate] = None, is_snapshot: bool = False, iterator_class: Optional[Type[ComponentIterator]] = None, iterator_args: Optional[Dict[str, Any]] = None, num_retained_versions: int = 10, comment: str = '', ignore_errors: bool = False) -&gt; View\n</code></pre> <p>Create a new <code>View</code>.</p> <p>Parameters:</p> <ul> <li> <code>path_str</code>             (<code>str</code>)         \u2013          <p>Path to the view.</p> </li> <li> <code>base</code>             (<code>Table</code>)         \u2013          <p>Table (ie, table or view or snapshot) to base the view on.</p> </li> <li> <code>schema</code>             (<code>Optional[Dict[str, Any]]</code>, default:                 <code>None</code> )         \u2013          <p>dictionary mapping column names to column types, value expressions, or to column specifications.</p> </li> <li> <code>filter</code>             (<code>Optional[Predicate]</code>, default:                 <code>None</code> )         \u2013          <p>Predicate to filter rows of the base table.</p> </li> <li> <code>is_snapshot</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether the view is a snapshot.</p> </li> <li> <code>iterator_class</code>             (<code>Optional[Type[ComponentIterator]]</code>, default:                 <code>None</code> )         \u2013          <p>Class of the iterator to use for the view.</p> </li> <li> <code>iterator_args</code>             (<code>Optional[Dict[str, Any]]</code>, default:                 <code>None</code> )         \u2013          <p>Arguments to pass to the iterator class.</p> </li> <li> <code>num_retained_versions</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Number of versions of the view to retain.</p> </li> <li> <code>ignore_errors</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>if True, fail silently if the path already exists or is invalid.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>View</code>         \u2013          <p>The newly created view.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>if the path already exists or is invalid.</p> </li> </ul> <p>Examples:</p> <p>Create a view with an additional int and a string column and a filter:</p> <pre><code>&gt;&gt;&gt; view = cl.create_view(\n    'my_view', base, schema={'col3': IntType(), 'col4': StringType()}, filter=base.col1 &gt; 10)\n</code></pre> <p>Create a table snapshot:</p> <pre><code>&gt;&gt;&gt; snapshot_view = cl.create_view('my_snapshot_view', base, is_snapshot=True)\n</code></pre> <p>Create an immutable view with additional computed columns and a filter:</p> <pre><code>&gt;&gt;&gt; snapshot_view = cl.create_view(\n    'my_snapshot', base, schema={'col3': base.col2 + 1}, filter=base.col1 &gt; 10, is_snapshot=True)\n</code></pre>"},{"location":"api/client/#pixeltable.Client.get_table","title":"get_table","text":"<pre><code>get_table(path: str) -&gt; Table\n</code></pre> <p>Get a handle to a table (including views and snapshots).</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>)         \u2013          <p>Path to the table.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>         \u2013          <p>A <code>InsertableTable</code> or <code>View</code> object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the path does not exist or does not designate a table.</p> </li> </ul> <p>Examples:</p> <p>Get handle for a table in the top-level directory:</p> <pre><code>&gt;&gt;&gt; table = cl.get_table('my_table')\n</code></pre> <p>For a table in a subdirectory:</p> <pre><code>&gt;&gt;&gt; table = cl.get_table('subdir.my_table')\n</code></pre> <p>For a snapshot in the top-level directory:</p> <pre><code>&gt;&gt;&gt; table = cl.get_table('my_snapshot')\n</code></pre>"},{"location":"api/client/#pixeltable.Client.move","title":"move","text":"<pre><code>move(path: str, new_path: str) -&gt; None\n</code></pre> <p>Move a schema object to a new directory and/or rename a schema object.</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>)         \u2013          <p>absolute path to the existing schema object.</p> </li> <li> <code>new_path</code>             (<code>str</code>)         \u2013          <p>absolute new path for the schema object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If path does not exist or new_path already exists.</p> </li> </ul> <p>Examples:</p> <p>Move a table to a different directory:</p> <pre><code>&gt;&gt;&gt;&gt; cl.move('dir1.my_table', 'dir2.my_table')\n</code></pre> <p>Rename a table:</p> <pre><code>&gt;&gt;&gt;&gt; cl.move('dir1.my_table', 'dir1.new_name')\n</code></pre>"},{"location":"api/client/#pixeltable.Client.list_tables","title":"list_tables","text":"<pre><code>list_tables(dir_path: str = '', recursive: bool = True) -&gt; List[str]\n</code></pre> <p>List the tables in a directory.</p> <p>Parameters:</p> <ul> <li> <code>dir_path</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>Path to the directory. Defaults to the root directory.</p> </li> <li> <code>recursive</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to list tables in subdirectories as well.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>A list of table paths.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the path does not exist or does not designate a directory.</p> </li> </ul> <p>Examples:</p> <p>List tables in top-level directory:</p> <pre><code>&gt;&gt;&gt; cl.list_tables()\n['my_table', ...]\n</code></pre> <p>List tables in 'dir1':</p> <pre><code>&gt;&gt;&gt; cl.list_tables('dir1')\n[...]\n</code></pre>"},{"location":"api/client/#pixeltable.Client.drop_table","title":"drop_table","text":"<pre><code>drop_table(path: str, force: bool = False, ignore_errors: bool = False) -&gt; None\n</code></pre> <p>Drop a table.</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>)         \u2013          <p>Path to the table.</p> </li> <li> <code>force</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to drop the table even if it has unsaved changes.</p> </li> <li> <code>ignore_errors</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to ignore errors if the table does not exist.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the path does not exist or does not designate a table and ignore_errors is False.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cl.drop_table('my_table')\n</code></pre>"},{"location":"api/client/#pixeltable.Client.create_dir","title":"create_dir","text":"<pre><code>create_dir(path_str: str, ignore_errors: bool = False) -&gt; None\n</code></pre> <p>Create a directory.</p> <p>Parameters:</p> <ul> <li> <code>path_str</code>             (<code>str</code>)         \u2013          <p>Path to the directory.</p> </li> <li> <code>ignore_errors</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>if True, silently returns on error</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the path already exists or the parent is not a directory.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cl.create_dir('my_dir')\n</code></pre> <p>Create a subdirectory:</p> <pre><code>&gt;&gt;&gt; cl.create_dir('my_dir.sub_dir')\n</code></pre>"},{"location":"api/client/#pixeltable.Client.rm_dir","title":"rm_dir","text":"<pre><code>rm_dir(path_str: str) -&gt; None\n</code></pre> <p>Remove a directory.</p> <p>Parameters:</p> <ul> <li> <code>path_str</code>             (<code>str</code>)         \u2013          <p>Path to the directory.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the path does not exist or does not designate a directory or if the directory is not empty.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cl.rm_dir('my_dir')\n</code></pre> <p>Remove a subdirectory:</p> <pre><code>&gt;&gt;&gt; cl.rm_dir('my_dir.sub_dir')\n</code></pre>"},{"location":"api/client/#pixeltable.Client.list_dirs","title":"list_dirs","text":"<pre><code>list_dirs(path_str: str = '', recursive: bool = True) -&gt; List[str]\n</code></pre> <p>List the directories in a directory.</p> <p>Parameters:</p> <ul> <li> <code>path_str</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>Path to the directory.</p> </li> <li> <code>recursive</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to list subdirectories recursively.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>List of directory paths.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the path does not exist or does not designate a directory.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cl.list_dirs('my_dir', recursive=True)\n['my_dir', 'my_dir.sub_dir1']\n</code></pre>"},{"location":"api/client/#pixeltable.Client.logging","title":"logging","text":"<pre><code>logging(*, to_stdout: Optional[bool] = None, level: Optional[int] = None, add: Optional[str] = None, remove: Optional[str] = None) -&gt; None\n</code></pre> <p>Configure logging.</p> <p>Parameters:</p> <ul> <li> <code>to_stdout</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>if True, also log to stdout</p> </li> <li> <code>level</code>             (<code>Optional[int]</code>, default:                 <code>None</code> )         \u2013          <p>default log level</p> </li> <li> <code>add</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>comma-separated list of 'module name:log level' pairs; ex.: add='video:10'</p> </li> <li> <code>remove</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>comma-separated list of module names</p> </li> </ul>"},{"location":"api/data_frame/","title":"DataFrame","text":"<p><code>DataFrame</code> represents a query against a specific table. Unlike computation container frameworks like pandas or Dask, Pixeltable dataframes do not hold data or allow you to update data (use insert/update/delete for that purpose). Another difference to pandas is that query execution needs to be initiated explicitly in order to return results.</p>"},{"location":"api/data_frame/#overview","title":"Overview","text":"Query Construction <code>select</code> Select output expressions <code>where</code> Filter table rows <code>group_by</code> Group table rows in order to apply aggregate functions <code>order_by</code> Order output rows <code>limit</code> Limit the number of output rows Query Execution <code>collect</code> Return all output rows <code>show</code> Return a number of output rows <code>head</code> Return the oldest rows <code>tail</code> Return the most recently added rows Data Export <code>to_pytorch_dataset</code> Return the query result as a pytorch <code>IterableDataset</code> <code>to_coco_dataset</code> Return the query result as a COCO dataset"},{"location":"api/data_frame/#pixeltable.DataFrame","title":"pixeltable.DataFrame","text":""},{"location":"api/data_frame/#pixeltable.DataFrame.select","title":"select","text":"<pre><code>select(*items: Any, **named_items: Any) -&gt; DataFrame\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.where","title":"where","text":"<pre><code>where(pred: Predicate) -&gt; DataFrame\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.group_by","title":"group_by","text":"<pre><code>group_by(*grouping_items: Any) -&gt; DataFrame\n</code></pre> <p>Add a group-by clause to this DataFrame. Variants: - group_by(): group a component view by their respective base table rows - group_by(, ...): group by the given expressions"},{"location":"api/data_frame/#pixeltable.DataFrame.order_by","title":"order_by","text":"<pre><code>order_by(*expr_list: Expr, asc: bool = True) -&gt; DataFrame\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.limit","title":"limit","text":"<pre><code>limit(n: int) -&gt; DataFrame\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.collect","title":"collect","text":"<pre><code>collect() -&gt; DataFrameResultSet\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.show","title":"show","text":"<pre><code>show(n: int = 20) -&gt; DataFrameResultSet\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.head","title":"head","text":"<pre><code>head(n: int = 10) -&gt; DataFrameResultSet\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.tail","title":"tail","text":"<pre><code>tail(n: int = 10) -&gt; DataFrameResultSet\n</code></pre>"},{"location":"api/data_frame/#pixeltable.DataFrame.to_pytorch_dataset","title":"to_pytorch_dataset","text":"<pre><code>to_pytorch_dataset(image_format: str = 'pt') -&gt; 'torch.utils.data.IterableDataset'\n</code></pre> <p>Convert the dataframe to a pytorch IterableDataset suitable for parallel loading with torch.utils.data.DataLoader.</p> <p>This method requires pyarrow &gt;= 13, torch and torchvision to work.</p> <p>This method serializes data so it can be read from disk efficiently and repeatedly without re-executing the query. This data is cached to disk for future re-use.</p> <p>Parameters:</p> <ul> <li> <code>image_format</code>             (<code>str</code>, default:                 <code>'pt'</code> )         \u2013          <p>format of the images. Can be 'pt' (pytorch tensor) or 'np' (numpy array).     'np' means image columns return as an RGB uint8 array of shape HxWxC.     'pt' means image columns return as a CxHxW tensor with values in [0,1] and type torch.float32.         (the format output by torchvision.transforms.ToTensor())</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>'torch.utils.data.IterableDataset'</code>         \u2013          <p>A pytorch IterableDataset: Columns become fields of the dataset, where rows are returned as a dictionary compatible with torch.utils.data.DataLoader default collation.</p> </li> </ul> Constraints <p>The default collate_fn for torch.data.util.DataLoader cannot represent null values as part of a pytorch tensor when forming batches. These values will raise an exception while running the dataloader.</p> <p>If you have them, you can work around None values by providing your custom collate_fn to the DataLoader (and have your model handle it). Or, if these are not meaningful values within a minibtach, you can modify or remove any such values through selections and filters prior to calling to_pytorch_dataset().</p>"},{"location":"api/data_frame/#pixeltable.DataFrame.to_coco_dataset","title":"to_coco_dataset","text":"<pre><code>to_coco_dataset() -&gt; Path\n</code></pre> <p>Convert the dataframe to a COCO dataset. This dataframe must return a single json-typed output column in the following format: {     'image': PIL.Image.Image,     'annotations': [         {             'bbox': [x: int, y: int, w: int, h: int],             'category': str | int,         },         ...     ], }</p> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Path to the COCO dataset file.</p> </li> </ul>"},{"location":"api/insertable_table/","title":"InsertableTable","text":"<p>Instances of class <code>InsertableTable</code> are handles to Pixeltable tables.</p> <p>Use this handle to query and update the table and to add and drop columns.</p> <p><code>InsertableTable</code> instances are created by calling <code>Client.create_table</code> or <code>Client.get_table</code>.</p>"},{"location":"api/insertable_table/#overview","title":"Overview","text":"Column Operations <code>add_column</code> Adds a column to the table <code>drop_column</code> Remove a column from the table <code>rename_column</code> Rename a column Data Operations <code>insert</code> Insert rows into table <code>update</code> Upate rows in table <code>delete</code> Delete rows from table Versioning <code>revert</code> Reverts the last change"},{"location":"api/insertable_table/#pixeltable.InsertableTable","title":"pixeltable.InsertableTable","text":"<p>A <code>Table</code> that allows inserting and deleting rows.</p>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.add_column","title":"add_column","text":"<pre><code>add_column(*, type: Optional[ColumnType] = None, stored: Optional[bool] = None, indexed: Optional[bool] = None, print_stats: bool = False, **kwargs: Any) -&gt; UpdateStatus\n</code></pre> <p>Adds a column to the table.</p> <p>Parameters:</p> <ul> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Exactly one keyword argument of the form <code>column-name=type|value-expression</code>.</p> </li> <li> <code>type</code>             (<code>Optional[ColumnType]</code>, default:                 <code>None</code> )         \u2013          <p>The type of the column. Only valid and required if <code>value-expression</code> is a Callable.</p> </li> <li> <code>stored</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Whether the column is materialized and stored or computed on demand. Only valid for image columns.</p> </li> <li> <code>indexed</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Whether the column is indexed.</p> </li> <li> <code>print_stats</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If <code>True</code>, print execution metrics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>UpdateStatus</code>         \u2013          <p>execution status</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the column name is invalid or already exists.</p> </li> </ul> <p>Examples:</p> <p>Add an int column with <code>None</code> values:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(new_col=IntType())\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['new_col'] = IntType()\n</code></pre> <p>For a table with int column <code>int_col</code>, add a column that is the factorial of <code>int_col</code>. The names of the parameters of the Callable must correspond to existing column names (the column values are then passed as arguments to the Callable). In this case, the column type needs to be specified explicitly:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(factorial=lambda int_col: math.factorial(int_col), type=IntType())\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['factorial'] = {'value': lambda int_col: math.factorial(int_col), 'type': IntType()}\n</code></pre> <p>For a table with an image column <code>frame</code>, add an image column <code>rotated</code> that rotates the image by 90 degrees. In this case, the column type is inferred from the expression. Also, the column is not stored (by default, computed image columns are not stored but recomputed on demand):</p> <pre><code>&gt;&gt;&gt; tbl.add_column(rotated=tbl.frame.rotate(90))\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['rotated'] = tbl.frame.rotate(90)\n</code></pre> <p>Do the same, but now the column is stored:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(rotated=tbl.frame.rotate(90), stored=True)\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['rotated'] = {'value': tbl.frame.rotate(90), 'stored': True}\n</code></pre> <p>Add a resized version of the <code>frame</code> column and index it. The column does not need to be stored in order to be indexed:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(small_frame=tbl.frame.resize([224, 224]), indexed=True)\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['small_frame'] = {'value': tbl.frame.resize([224, 224]), 'indexed': True}\n</code></pre>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.drop_column","title":"drop_column","text":"<pre><code>drop_column(name: str) -&gt; None\n</code></pre> <p>Drop a column from the table.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the column to drop.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the column does not exist or if it is referenced by a computed column.</p> </li> </ul> <p>Examples:</p> <p>Drop column <code>factorial</code>:</p> <pre><code>&gt;&gt;&gt; tbl.drop_column('factorial')\n</code></pre>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.rename_column","title":"rename_column","text":"<pre><code>rename_column(old_name: str, new_name: str) -&gt; None\n</code></pre> <p>Rename a column.</p> <p>Parameters:</p> <ul> <li> <code>old_name</code>             (<code>str</code>)         \u2013          <p>The current name of the column.</p> </li> <li> <code>new_name</code>             (<code>str</code>)         \u2013          <p>The new name of the column.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the column does not exist or if the new name is invalid or already exists.</p> </li> </ul> <p>Examples:</p> <p>Rename column <code>factorial</code> to <code>fac</code>:</p> <pre><code>&gt;&gt;&gt; tbl.rename_column('factorial', 'fac')\n</code></pre>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.insert","title":"insert","text":"<pre><code>insert(*args, **kwargs) -&gt; UpdateStatus\n</code></pre> <p>Insert rows into table.</p> <p>To insert multiple rows at a time:</p> <p><code>insert(rows: List[Dict[str, Any]], print_stats: bool = False, fail_on_exception: bool = True)</code></p> <p>To insert just a single row, you can use the more convenient syntax: <code>insert(print_stats: bool = False, fail_on_exception: bool = True, **kwargs: Any)</code></p> <p>Parameters:</p> <ul> <li> <code>rows</code>         \u2013          <p>(if inserting multiple rows) A list of rows to insert, each of which is a dictionary mapping column names to values.</p> </li> <li> <code>kwargs</code>         \u2013          <p>(if inserting a single row) keyword-argument pairs representing column names and values.</p> </li> <li> <code>print_stats</code>         \u2013          <p>If <code>True</code>, print statistics about the cost of computed columns.</p> </li> <li> <code>fail_on_exception</code>         \u2013          <p>Determines how exceptions in computed columns and invalid media files (e.g., corrupt images) are handled. If <code>False</code>, store error information (accessible as column properties 'errortype' and 'errormsg') for those cases, but continue inserting rows. If <code>True</code>, raise an exception that aborts the insert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>UpdateStatus</code>         \u2013          <p>execution status</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>if a row does not match the table schema or contains values for computed columns</p> </li> </ul> <p>Examples:</p> <p>Insert two rows into a table with three int columns <code>a</code>, <code>b</code>, and <code>c</code>. Column <code>c</code> is nullable.</p> <pre><code>&gt;&gt;&gt; tbl.insert([{'a': 1, 'b': 1, 'c': 1}, {'a': 2, 'b': 2}])\n</code></pre> <p>Insert a single row into a table with three int columns <code>a</code>, <code>b</code>, and <code>c</code>.</p> <pre><code>&gt;&gt;&gt; tbl.insert(a=1, b=1, c=1)\n</code></pre>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.update","title":"update","text":"<pre><code>update(value_spec: Dict[str, Union['pixeltable.exprs.Expr', Any]], where: Optional['pixeltable.exprs.Predicate'] = None, cascade: bool = True) -&gt; UpdateStatus\n</code></pre> <p>Update rows in this table.</p> <p>Parameters:</p> <ul> <li> <code>value_spec</code>             (<code>Dict[str, Union['pixeltable.exprs.Expr', Any]]</code>)         \u2013          <p>a dictionary mapping column names to literal values or Pixeltable expressions.</p> </li> <li> <code>where</code>             (<code>Optional['pixeltable.exprs.Predicate']</code>, default:                 <code>None</code> )         \u2013          <p>a Predicate to filter rows to update.</p> </li> <li> <code>cascade</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>if True, also update all computed columns that transitively depend on the updated columns.</p> </li> </ul> <p>Examples:</p> <p>Set newly-added column <code>int_col</code> to 1 for all rows:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': 1})\n</code></pre> <p>Set newly-added column <code>int_col</code> to 1 for all rows where <code>int_col</code> is 0:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': 1}, where=tbl.int_col == 0)\n</code></pre> <p>Set <code>int_col</code> to the value of <code>other_int_col</code> + 1:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': tbl.other_int_col + 1})\n</code></pre> <p>Increment <code>int_col</code> by 1 for all rows where <code>int_col</code> is 0:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': tbl.int_col + 1}, where=tbl.int_col == 0)\n</code></pre>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.delete","title":"delete","text":"<pre><code>delete(where: Optional['pixeltable.exprs.Predicate'] = None) -&gt; UpdateStatus\n</code></pre> <p>Delete rows in this table.</p> <p>Parameters:</p> <ul> <li> <code>where</code>             (<code>Optional['pixeltable.exprs.Predicate']</code>, default:                 <code>None</code> )         \u2013          <p>a Predicate to filter rows to delete.</p> </li> </ul> <p>Examples:</p> <p>Delete all rows in a table:</p> <pre><code>&gt;&gt;&gt; tbl.delete()\n</code></pre> <p>Delete all rows in a table where column <code>a</code> is greater than 5:</p> <pre><code>&gt;&gt;&gt; tbl.delete(tbl.a &gt; 5)\n</code></pre>"},{"location":"api/insertable_table/#pixeltable.InsertableTable.revert","title":"revert","text":"<pre><code>revert() -&gt; None\n</code></pre> <p>Reverts the table to the previous version.</p> <p>.. warning::     This operation is irreversible.</p>"},{"location":"api/table/","title":"Table","text":"<p>The <code>Table</code> base class provides convenience functions for querying tables and views without having to construct <code>DataFrame</code> instances explicitly.</p>"},{"location":"api/table/#pixeltable.Table","title":"pixeltable.Table","text":"<p>Base class for all tabular SchemaObjects.</p>"},{"location":"api/table/#pixeltable.Table.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(col_name: str) -&gt; 'pixeltable.exprs.ColumnRef'\n</code></pre> <p>Return a ColumnRef for the given column name.</p>"},{"location":"api/table/#pixeltable.Table.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index: object) -&gt; Union['pixeltable.exprs.ColumnRef', 'pixeltable.dataframe.DataFrame']\n</code></pre> <p>Return a ColumnRef for the given column name, or a DataFrame for the given slice.</p>"},{"location":"api/table/#pixeltable.Table.df","title":"df","text":"<pre><code>df() -&gt; 'pixeltable.dataframe.DataFrame'\n</code></pre> <p>Return a DataFrame for this table.</p>"},{"location":"api/table/#pixeltable.Table.select","title":"select","text":"<pre><code>select(*items: Any, **named_items: Any) -&gt; 'pixeltable.dataframe.DataFrame'\n</code></pre> <p>Return a DataFrame for this table.</p>"},{"location":"api/table/#pixeltable.Table.where","title":"where","text":"<pre><code>where(pred: 'exprs.Predicate') -&gt; 'pixeltable.dataframe.DataFrame'\n</code></pre> <p>Return a DataFrame for this table.</p>"},{"location":"api/table/#pixeltable.Table.show","title":"show","text":"<pre><code>show(*args, **kwargs) -&gt; 'pixeltable.dataframe.DataFrameResultSet'\n</code></pre> <p>Return rows from this table.</p>"},{"location":"api/table/#pixeltable.Table.head","title":"head","text":"<pre><code>head(*args, **kwargs) -&gt; 'pixeltable.dataframe.DataFrameResultSet'\n</code></pre> <p>Return the first n rows inserted into this table.</p>"},{"location":"api/table/#pixeltable.Table.tail","title":"tail","text":"<pre><code>tail(*args, **kwargs) -&gt; 'pixeltable.dataframe.DataFrameResultSet'\n</code></pre> <p>Return the last n rows inserted into this table.</p>"},{"location":"api/table/#pixeltable.Table.count","title":"count","text":"<pre><code>count() -&gt; int\n</code></pre> <p>Return the number of rows in this table.</p>"},{"location":"api/table/#pixeltable.Table.describe","title":"describe","text":"<pre><code>describe() -&gt; None\n</code></pre>"},{"location":"api/view/","title":"View","text":"<p>Instances of class <code>View</code> are handles to Pixeltable views and snapshots (the latter require <code>is_snapshot=True</code> when creating the view).</p> <p>Use this handle to query and update the view and to add and drop columns.</p> <p><code>View</code> instances are created by calling <code>Client.create_view</code> or <code>Client.get_table</code>.</p>"},{"location":"api/view/#overview","title":"Overview","text":"Column Operations <code>add_column</code> Adds a column to the view <code>drop_column</code> Removes a column from the view <code>rename_column</code> Renames a column Data Operations <code>update</code> Update rows in the view Versioning <code>revert</code> Revert the last change to the view"},{"location":"api/view/#pixeltable.View","title":"pixeltable.View","text":"<p>A <code>Table</code> that presents a virtual view of another table (or view).</p> <p>A view is typically backed by a store table, which records the view's columns and is joined back to the bases at query execution time. The exception is a snapshot view without a predicate and without additional columns: in that case, the view is simply a reference to a specific set of base versions.</p>"},{"location":"api/view/#pixeltable.View.add_column","title":"add_column","text":"<pre><code>add_column(*, type: Optional[ColumnType] = None, stored: Optional[bool] = None, indexed: Optional[bool] = None, print_stats: bool = False, **kwargs: Any) -&gt; UpdateStatus\n</code></pre> <p>Adds a column to the table.</p> <p>Parameters:</p> <ul> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Exactly one keyword argument of the form <code>column-name=type|value-expression</code>.</p> </li> <li> <code>type</code>             (<code>Optional[ColumnType]</code>, default:                 <code>None</code> )         \u2013          <p>The type of the column. Only valid and required if <code>value-expression</code> is a Callable.</p> </li> <li> <code>stored</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Whether the column is materialized and stored or computed on demand. Only valid for image columns.</p> </li> <li> <code>indexed</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Whether the column is indexed.</p> </li> <li> <code>print_stats</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If <code>True</code>, print execution metrics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>UpdateStatus</code>         \u2013          <p>execution status</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the column name is invalid or already exists.</p> </li> </ul> <p>Examples:</p> <p>Add an int column with <code>None</code> values:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(new_col=IntType())\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['new_col'] = IntType()\n</code></pre> <p>For a table with int column <code>int_col</code>, add a column that is the factorial of <code>int_col</code>. The names of the parameters of the Callable must correspond to existing column names (the column values are then passed as arguments to the Callable). In this case, the column type needs to be specified explicitly:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(factorial=lambda int_col: math.factorial(int_col), type=IntType())\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['factorial'] = {'value': lambda int_col: math.factorial(int_col), 'type': IntType()}\n</code></pre> <p>For a table with an image column <code>frame</code>, add an image column <code>rotated</code> that rotates the image by 90 degrees. In this case, the column type is inferred from the expression. Also, the column is not stored (by default, computed image columns are not stored but recomputed on demand):</p> <pre><code>&gt;&gt;&gt; tbl.add_column(rotated=tbl.frame.rotate(90))\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['rotated'] = tbl.frame.rotate(90)\n</code></pre> <p>Do the same, but now the column is stored:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(rotated=tbl.frame.rotate(90), stored=True)\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['rotated'] = {'value': tbl.frame.rotate(90), 'stored': True}\n</code></pre> <p>Add a resized version of the <code>frame</code> column and index it. The column does not need to be stored in order to be indexed:</p> <pre><code>&gt;&gt;&gt; tbl.add_column(small_frame=tbl.frame.resize([224, 224]), indexed=True)\n</code></pre> <p>Alternatively, this can also be expressed as:</p> <pre><code>&gt;&gt;&gt; tbl['small_frame'] = {'value': tbl.frame.resize([224, 224]), 'indexed': True}\n</code></pre>"},{"location":"api/view/#pixeltable.View.drop_column","title":"drop_column","text":"<pre><code>drop_column(name: str) -&gt; None\n</code></pre> <p>Drop a column from the table.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the column to drop.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the column does not exist or if it is referenced by a computed column.</p> </li> </ul> <p>Examples:</p> <p>Drop column <code>factorial</code>:</p> <pre><code>&gt;&gt;&gt; tbl.drop_column('factorial')\n</code></pre>"},{"location":"api/view/#pixeltable.View.rename_column","title":"rename_column","text":"<pre><code>rename_column(old_name: str, new_name: str) -&gt; None\n</code></pre> <p>Rename a column.</p> <p>Parameters:</p> <ul> <li> <code>old_name</code>             (<code>str</code>)         \u2013          <p>The current name of the column.</p> </li> <li> <code>new_name</code>             (<code>str</code>)         \u2013          <p>The new name of the column.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Error</code>           \u2013          <p>If the column does not exist or if the new name is invalid or already exists.</p> </li> </ul> <p>Examples:</p> <p>Rename column <code>factorial</code> to <code>fac</code>:</p> <pre><code>&gt;&gt;&gt; tbl.rename_column('factorial', 'fac')\n</code></pre>"},{"location":"api/view/#pixeltable.View.update","title":"update","text":"<pre><code>update(value_spec: Dict[str, Union['pixeltable.exprs.Expr', Any]], where: Optional['pixeltable.exprs.Predicate'] = None, cascade: bool = True) -&gt; UpdateStatus\n</code></pre> <p>Update rows in this table.</p> <p>Parameters:</p> <ul> <li> <code>value_spec</code>             (<code>Dict[str, Union['pixeltable.exprs.Expr', Any]]</code>)         \u2013          <p>a dictionary mapping column names to literal values or Pixeltable expressions.</p> </li> <li> <code>where</code>             (<code>Optional['pixeltable.exprs.Predicate']</code>, default:                 <code>None</code> )         \u2013          <p>a Predicate to filter rows to update.</p> </li> <li> <code>cascade</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>if True, also update all computed columns that transitively depend on the updated columns.</p> </li> </ul> <p>Examples:</p> <p>Set newly-added column <code>int_col</code> to 1 for all rows:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': 1})\n</code></pre> <p>Set newly-added column <code>int_col</code> to 1 for all rows where <code>int_col</code> is 0:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': 1}, where=tbl.int_col == 0)\n</code></pre> <p>Set <code>int_col</code> to the value of <code>other_int_col</code> + 1:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': tbl.other_int_col + 1})\n</code></pre> <p>Increment <code>int_col</code> by 1 for all rows where <code>int_col</code> is 0:</p> <pre><code>&gt;&gt;&gt; tbl.update({'int_col': tbl.int_col + 1}, where=tbl.int_col == 0)\n</code></pre>"},{"location":"api/view/#pixeltable.View.revert","title":"revert","text":"<pre><code>revert() -&gt; None\n</code></pre> <p>Reverts the table to the previous version.</p> <p>.. warning::     This operation is irreversible.</p>"},{"location":"howto/working_with_external_files/","title":"Working with External Files","text":"In\u00a0[1]: Copied! <pre>import tempfile\nimport random\nimport shutil\nimport pixeltable as pxt\n\ncl = pxt.Client()\ncl.create_dir('external_data', ignore_errors=True)\n</pre> import tempfile import random import shutil import pixeltable as pxt  cl = pxt.Client() cl.create_dir('external_data', ignore_errors=True) <pre>2024-01-04 10:21:53,470 INFO env env.py:191: found store container\n2024-01-04 10:21:53,471 INFO env env.py:214: connecting to NOS\n2024-01-04 10:21:53.537 | INFO     | nos.server:init:131 - Inference server already running (name=nos-inference-service-gpu, image=&lt;Image: 'autonomi/nos:0.0.9-gpu'&gt;, id=87be2b6a5d19).\n2024-01-04 10:21:53,537 INFO env env.py:217: waiting for NOS\n2024-01-04 10:21:53,548 INFO env env.py:238: connecting to OpenAI\n</pre> <pre>/home/marcel/pixeltable/pixeltable/exec/expr_eval_node.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n</pre> <pre>2024-01-04 10:21:53,587 INFO env env.py:180: found database postgresql://postgres:*****@localhost:6543/pixeltable\n</pre> In\u00a0[2]: Copied! <pre>cl.drop_table('external_data.videos', ignore_errors=True)\nv = cl.create_table('external_data.videos', {'video': pxt.VideoType()})\n\nprefix = 's3://multimedia-commons/'\npaths = [\n    'data/videos/mp4/ffe/ffb/ffeffbef41bbc269810b2a1a888de.mp4',\n    'data/videos/mp4/ffe/feb/ffefebb41485539f964760e6115fbc44.mp4',\n    'data/videos/mp4/ffe/f73/ffef7384d698b5f70d411c696247169.mp4'\n]\nv.insert([{'video': prefix + p} for p in paths])\n</pre> cl.drop_table('external_data.videos', ignore_errors=True) v = cl.create_table('external_data.videos', {'video': pxt.VideoType()})  prefix = 's3://multimedia-commons/' paths = [     'data/videos/mp4/ffe/ffb/ffeffbef41bbc269810b2a1a888de.mp4',     'data/videos/mp4/ffe/feb/ffefebb41485539f964760e6115fbc44.mp4',     'data/videos/mp4/ffe/f73/ffef7384d698b5f70d411c696247169.mp4' ] v.insert([{'video': prefix + p} for p in paths]) <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>inserted 3 rows with 0 errors \n</pre> Out[2]: <pre>UpdateStatus(num_rows=3, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>We just inserted 3 rows with video files residing in S3. When we now query these, we are presented with their locally cached counterparts.</p> <p>(Note: we don't simply display the output of <code>collect()</code> here, because that is formatted as an HTML table with a media player and so would obscure the file path.)</p> In\u00a0[3]: Copied! <pre>rows = list(v.select(v.video).collect())\nrows[0]\n</pre> rows = list(v.select(v.video).collect()) rows[0] Out[3]: <pre>{'video': '/home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_1fcfcb221263cff76a2853250fbbb2e90375dd495454c0007bc6ff4430c9a4a7'}</pre> <p>Let's make a local copy of the first file and insert that separately. First, the copy:</p> In\u00a0[4]: Copied! <pre>local_path = tempfile.mktemp(suffix='.mp4')\nshutil.copyfile(rows[0]['video'], local_path)\nlocal_path\n</pre> local_path = tempfile.mktemp(suffix='.mp4') shutil.copyfile(rows[0]['video'], local_path) local_path Out[4]: <pre>'/tmp/tmpjywb2igi.mp4'</pre> <p>Now the insert:</p> In\u00a0[5]: Copied! <pre>v.insert([{'video': local_path}])\n</pre> v.insert([{'video': local_path}]) <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>inserted 1 row with 0 errors \n</pre> Out[5]: <pre>UpdateStatus(num_rows=1, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>When we query this again, we see that local paths are preserved:</p> In\u00a0[6]: Copied! <pre>rows = list(v.select(v.video).collect())\nrows\n</pre> rows = list(v.select(v.video).collect()) rows Out[6]: <pre>[{'video': '/home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_1fcfcb221263cff76a2853250fbbb2e90375dd495454c0007bc6ff4430c9a4a7'},\n {'video': '/home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_fc11428b32768ae782193a57ebcbad706f45bbd9fa13354471e0bcd798fee3ea'},\n {'video': '/home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_b9fb0d9411bc9cd183a36866911baa7a8834f22f665bce47608566b38485c16a'},\n {'video': '/tmp/tmpjywb2igi.mp4'}]</pre> <p>UDFs also see local paths:</p> In\u00a0[7]: Copied! <pre>@pxt.udf(return_type=pxt.IntType(), param_types=[pxt.VideoType()])\ndef f(v):\n    print(f'{type(v)}: {v}')\n    return 1\n</pre> @pxt.udf(return_type=pxt.IntType(), param_types=[pxt.VideoType()]) def f(v):     print(f'{type(v)}: {v}')     return 1 In\u00a0[8]: Copied! <pre>v.select(f(v.video)).show()\n</pre> v.select(f(v.video)).show() <pre>&lt;class 'str'&gt;: /home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_1fcfcb221263cff76a2853250fbbb2e90375dd495454c0007bc6ff4430c9a4a7\n&lt;class 'str'&gt;: /home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_fc11428b32768ae782193a57ebcbad706f45bbd9fa13354471e0bcd798fee3ea\n&lt;class 'str'&gt;: /home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_b9fb0d9411bc9cd183a36866911baa7a8834f22f665bce47608566b38485c16a\n&lt;class 'str'&gt;: /tmp/tmpjywb2igi.mp4\n</pre> Out[8]: col_0 1 1 1 1 In\u00a0[9]: Copied! <pre>v.insert([{'video': prefix + 'bad_path.mp4'}])\n</pre> v.insert([{'video': prefix + 'bad_path.mp4'}]) <pre>\n---------------------------------------------------------------------------\nError                                     Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 v.insert([{'video': prefix + 'bad_path.mp4'}])\n\nFile ~/pixeltable/pixeltable/catalog/insertable_table.py:88, in InsertableTable.insert(self, rows, print_stats, fail_on_exception)\n     86         raise exc.Error('rows must be a list of dictionaries')\n     87 self._validate_input_rows(rows)\n---&gt; 88 result = self.tbl_version.insert(rows, print_stats=print_stats, fail_on_exception=fail_on_exception)\n     90 if result.num_excs == 0:\n     91     cols_with_excs_str = ''\n\nFile ~/pixeltable/pixeltable/catalog/table_version.py:383, in TableVersion.insert(self, rows, print_stats, fail_on_exception)\n    381 ts = time.time()\n    382 with Env.get().engine.begin() as conn:\n--&gt; 383     return self._insert(plan, conn, ts, print_stats)\n\nFile ~/pixeltable/pixeltable/catalog/table_version.py:394, in TableVersion._insert(self, exec_plan, conn, ts, print_stats)\n    392 from pixeltable.plan import Planner\n    393 result = UpdateStatus()\n--&gt; 394 num_rows, num_excs, cols_with_excs = self.store_tbl.insert_rows(exec_plan, conn, v_min=self.version)\n    395 self.next_rowid = num_rows\n    396 result.num_rows = num_rows\n\nFile ~/pixeltable/pixeltable/store.py:276, in StoreBase.insert_rows(self, exec_plan, conn, v_min)\n    274 try:\n    275     exec_plan.open()\n--&gt; 276     for row_batch in exec_plan:\n    277         num_rows += len(row_batch)\n    278         for batch_start_idx in range(0, len(row_batch), batch_size):\n    279             # compute batch of rows and convert them into table rows\n\nFile ~/pixeltable/pixeltable/exec/media_validation_node.py:26, in MediaValidationNode.__next__(self)\n     24 def __next__(self) -&gt; DataRowBatch:\n     25     assert self.input is not None\n---&gt; 26     row_batch = next(self.input)\n     27     for row in row_batch:\n     28         for slot_idx, col in [(c.slot_idx, c.col) for c in self.media_slots]:\n\nFile ~/pixeltable/pixeltable/exec/cache_prefetch_node.py:68, in CachePrefetchNode.__next__(self)\n     65     futures[executor.submit(self._fetch_url, row, info.slot_idx)] = (row, info)\n     66 for future in concurrent.futures.as_completed(futures):\n     67     # TODO:  does this need to deal with recoverable errors (such as retry after throttling)?\n---&gt; 68     tmp_path = future.result()\n     69     if tmp_path is None:\n     70         continue\n\nFile /usr/lib/python3.10/concurrent/futures/_base.py:451, in Future.result(self, timeout)\n    449     raise CancelledError()\n    450 elif self._state == FINISHED:\n--&gt; 451     return self.__get_result()\n    453 self._condition.wait(timeout)\n    455 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\nFile /usr/lib/python3.10/concurrent/futures/_base.py:403, in Future.__get_result(self)\n    401 if self._exception:\n    402     try:\n--&gt; 403         raise self._exception\n    404     finally:\n    405         # Break a reference cycle with the exception in self._exception\n    406         self = None\n\nFile /usr/lib/python3.10/concurrent/futures/thread.py:58, in _WorkItem.run(self)\n     55     return\n     57 try:\n---&gt; 58     result = self.fn(*self.args, **self.kwargs)\n     59 except BaseException as exc:\n     60     self.future.set_exception(exc)\n\nFile ~/pixeltable/pixeltable/exec/cache_prefetch_node.py:99, in CachePrefetchNode._fetch_url(self, row, slot_idx)\n     97         self.row_builder.set_exc(row, slot_idx, exc)\n     98         if not self.ctx.ignore_errors:\n---&gt; 99             raise exc from None  # suppress original exception\n    100         return None\n    101 assert False, f'Unsupported URL scheme: {parsed.scheme}'\n\nError: Failed to download s3://multimedia-commons/bad_path.mp4: An error occurred (404) when calling the HeadObject operation: Not Found</pre> <p>The same happens for corrupted files:</p> In\u00a0[10]: Copied! <pre># create invalid .mp4\nwith tempfile.NamedTemporaryFile(mode='wb', suffix='.mp4', delete=False) as temp_file:\n    temp_file.write(random.randbytes(1024))\n    corrupted_path = temp_file.name\n\nv.insert([{'video': corrupted_path}])\n</pre> # create invalid .mp4 with tempfile.NamedTemporaryFile(mode='wb', suffix='.mp4', delete=False) as temp_file:     temp_file.write(random.randbytes(1024))     corrupted_path = temp_file.name  v.insert([{'video': corrupted_path}]) <pre>moov atom not found\n</pre> <pre>\n---------------------------------------------------------------------------\nError                                     Traceback (most recent call last)\nCell In[10], line 6\n      3     temp_file.write(random.randbytes(1024))\n      4     corrupted_path = temp_file.name\n----&gt; 6 v.insert([{'video': corrupted_path}])\n\nFile ~/pixeltable/pixeltable/catalog/insertable_table.py:88, in InsertableTable.insert(self, rows, print_stats, fail_on_exception)\n     86         raise exc.Error('rows must be a list of dictionaries')\n     87 self._validate_input_rows(rows)\n---&gt; 88 result = self.tbl_version.insert(rows, print_stats=print_stats, fail_on_exception=fail_on_exception)\n     90 if result.num_excs == 0:\n     91     cols_with_excs_str = ''\n\nFile ~/pixeltable/pixeltable/catalog/table_version.py:383, in TableVersion.insert(self, rows, print_stats, fail_on_exception)\n    381 ts = time.time()\n    382 with Env.get().engine.begin() as conn:\n--&gt; 383     return self._insert(plan, conn, ts, print_stats)\n\nFile ~/pixeltable/pixeltable/catalog/table_version.py:394, in TableVersion._insert(self, exec_plan, conn, ts, print_stats)\n    392 from pixeltable.plan import Planner\n    393 result = UpdateStatus()\n--&gt; 394 num_rows, num_excs, cols_with_excs = self.store_tbl.insert_rows(exec_plan, conn, v_min=self.version)\n    395 self.next_rowid = num_rows\n    396 result.num_rows = num_rows\n\nFile ~/pixeltable/pixeltable/store.py:276, in StoreBase.insert_rows(self, exec_plan, conn, v_min)\n    274 try:\n    275     exec_plan.open()\n--&gt; 276     for row_batch in exec_plan:\n    277         num_rows += len(row_batch)\n    278         for batch_start_idx in range(0, len(row_batch), batch_size):\n    279             # compute batch of rows and convert them into table rows\n\nFile ~/pixeltable/pixeltable/exec/media_validation_node.py:41, in MediaValidationNode.__next__(self)\n     39             self.row_builder.set_exc(row, slot_idx, exc)\n     40             if not self.ctx.ignore_errors:\n---&gt; 41                 raise exc\n     43 return row_batch\n\nFile ~/pixeltable/pixeltable/exec/media_validation_node.py:37, in MediaValidationNode.__next__(self)\n     34     continue\n     36 try:\n---&gt; 37     col.col_type.validate_media(path)\n     38 except excs.Error as exc:\n     39     self.row_builder.set_exc(row, slot_idx, exc)\n\nFile ~/pixeltable/pixeltable/type_system.py:844, in VideoType.validate_media(self, val)\n    842                 break\n    843 except av.AVError:\n--&gt; 844     raise exc.Error(f'Not a valid video: {val}') from None\n\nError: Not a valid video: /tmp/tmpaytobnkb.mp4</pre> <p>Alternatively, Pixeltable can also be instructed to record error conditions and proceed with the ingest, via the <code>fail_on_exception</code> flag (default: <code>True</code>):</p> In\u00a0[11]: Copied! <pre>v.insert([{'video': prefix + 'bad_path.mp4'}, {'video': corrupted_path}], fail_on_exception=False)\n</pre> v.insert([{'video': prefix + 'bad_path.mp4'}, {'video': corrupted_path}], fail_on_exception=False) <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>inserted 2 rows with 2 errors across 1 column (videos.video)\n</pre> Out[11]: <pre>UpdateStatus(num_rows=2, num_computed_values=0, num_excs=2, updated_cols=[], cols_with_excs=['videos.video'])</pre> <p>Every media column has properties <code>errortype</code> and <code>errormsg</code> (both containing <code>string</code> data) that indicate whether the column value is valid. Invalid values show up as <code>None</code> and have non-null <code>errortype</code>/<code>errormsg</code>:</p> In\u00a0[12]: Copied! <pre>v.select(v.video == None, v.video.errortype, v.video.errormsg).collect()\n</pre> v.select(v.video == None, v.video.errortype, v.video.errormsg).collect() Out[12]: col_0 video_errortype video_errormsg False None None False None None False None None False None None True Error Failed to download s3://multimedia-commons/bad_path.mp4: An error occurred (404) when calling the HeadObject operation: Not Found True Error Not a valid video: /tmp/tmpaytobnkb.mp4 <p>Errors can now be inspected (and corrected) after the ingest:</p> In\u00a0[13]: Copied! <pre>v.where(v.video.errortype != None).select(v.video.errormsg).collect()\n</pre> v.where(v.video.errortype != None).select(v.video.errormsg).collect() Out[13]: video_errormsg Failed to download s3://multimedia-commons/bad_path.mp4: An error occurred (404) when calling the HeadObject operation: Not Found Not a valid video: /tmp/tmpaytobnkb.mp4 In\u00a0[14]: Copied! <pre>v.select(v.video.fileurl, v.video.localpath).collect()\n</pre> v.select(v.video.fileurl, v.video.localpath).collect() Out[14]: video_fileurl video_localpath s3://multimedia-commons/data/videos/mp4/ffe/ffb/ffeffbef41bbc269810b2a1a888de.mp4 /home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_1fcfcb221263cff76a2853250fbbb2e90375dd495454c0007bc6ff4430c9a4a7 s3://multimedia-commons/data/videos/mp4/ffe/feb/ffefebb41485539f964760e6115fbc44.mp4 /home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_fc11428b32768ae782193a57ebcbad706f45bbd9fa13354471e0bcd798fee3ea s3://multimedia-commons/data/videos/mp4/ffe/f73/ffef7384d698b5f70d411c696247169.mp4 /home/marcel/.pixeltable/file_cache/df8c499dc988432b86d18e87e537e944_0_b9fb0d9411bc9cd183a36866911baa7a8834f22f665bce47608566b38485c16a file:///tmp/tmpjywb2igi.mp4 /tmp/tmpjywb2igi.mp4 None None None None <p>Note that for local media files, the <code>fileurl</code> property still returns a parsable URL.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"howto/working_with_external_files/#working-with-external-files","title":"Working with External Files\u00b6","text":"<p>In Pixeltable, all media data (videos, images, audio) resides in external files, and Pixeltable stores references to those. The files can be local or remote (e.g., in S3). For the latter, Pixeltable automatically caches the files locally on access.</p> <p>When interacting with media data via Pixeltable, either through queries or UDFs, the user sees the following Python types:</p> <ul> <li><code>ImageType</code>: <code>PIL.Image.Image</code></li> <li><code>VideoType</code>: <code>string</code> (local path)</li> <li><code>AudioType</code>: <code>string</code> (local path)</li> </ul> <p>Let's create a table and load some data to see what that looks like:</p>"},{"location":"howto/working_with_external_files/#dealing-with-errors","title":"Dealing with errors\u00b6","text":"<p>When interacting with media data in Pixeltable, the user can assume that the underlying files exist, are local and are valid for their respective data type. In other words, the user doesn't need to consider error conditions.</p> <p>To that end, Pixeltable validates media data on ingest. The default behavior is to reject invalid media files:</p>"},{"location":"howto/working_with_external_files/#accessing-the-original-file-paths","title":"Accessing the original file paths\u00b6","text":"<p>In some cases, it will be necessary to access file paths (not, say, the <code>PIL.Image.Image</code>), and Pixeltable provides the column properties <code>fileurl</code> and <code>localpath</code> for that purpose:</p>"},{"location":"tutorials/comparing_object_detection_models_for_video/","title":"Comparing Object Detection Models for Video","text":"<p>In this tutorial we'll demonstrate how to use Pixeltable to do frame-by-frame object detection, made simple through Pixeltable's video-related functionality:</p> <ul> <li>automatic frame extraction</li> <li>running complex functions against frames (in this case, an object detection model)</li> <li>reassembling frames back into videos</li> </ul> <p>We'll be working with a single video file (from Pixeltable's test data directory). Let's download that now:</p> In\u00a0[\u00a0]: Copied! <pre>import urllib.request\n\ndownload_url = 'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/bangkok.mp4'\nfilename, _ = urllib.request.urlretrieve(download_url)\n</pre> import urllib.request  download_url = 'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/bangkok.mp4' filename, _ = urllib.request.urlretrieve(download_url) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\ndisplay(HTML(\"&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;\"))\n</pre> from IPython.display import display, HTML display(HTML(\"\")) In\u00a0[\u00a0]: Copied! <pre>import pixeltable as pxt\n\ncl = pxt.Client()\ncl.create_dir('model_comparison', ignore_errors=True)\n</pre> import pixeltable as pxt  cl = pxt.Client() cl.create_dir('model_comparison', ignore_errors=True) <p>We create a table for our videos, with a single column:</p> In\u00a0[\u00a0]: Copied! <pre>video_path = 'model_comparison.videos'\nframe_path = 'model_comparison.frames'\ncl.drop_table(frame_path, ignore_errors=True)\ncl.drop_table(video_path, ignore_errors=True)\nv = cl.create_table(video_path, {'video': pxt.VideoType()})\n</pre> video_path = 'model_comparison.videos' frame_path = 'model_comparison.frames' cl.drop_table(frame_path, ignore_errors=True) cl.drop_table(video_path, ignore_errors=True) v = cl.create_table(video_path, {'video': pxt.VideoType()}) <p>In order to interact with the frames, we take advantage of Pixeltable's component view concept: we create a \"view\" of our video table that contains one row for each frame. Pixeltable provides the built-in <code>FrameIterator</code> class for this.</p> In\u00a0[\u00a0]: Copied! <pre>from pixeltable.iterators import FrameIterator\nargs = {'video': v.video, 'fps': 0}\nf = cl.create_view(frame_path, v, iterator_class=FrameIterator, iterator_args=args)\n</pre> from pixeltable.iterators import FrameIterator args = {'video': v.video, 'fps': 0} f = cl.create_view(frame_path, v, iterator_class=FrameIterator, iterator_args=args) <p>The <code>fps</code> parameter determines the frame rate, with <code>0</code> indicating the native frame rate.</p> <p>Running this creates a view with six columns:</p> <ul> <li><code>frame_idx</code>, <code>pos_msec</code>, <code>pos_frame</code> and <code>frame</code> are created by the <code>FrameIterator</code> class.</li> <li><code>pos</code> is a system column in every component view</li> <li><code>video</code> is the column for our base table (all base table columns are visible in the view, to facilitate querying)</li> </ul> <p>Note that you could create additional views on the <code>videos</code> table, each with its own frame rate.</p> In\u00a0[\u00a0]: Copied! <pre>f\n</pre> f <p>We now insert a single row containing the name of the video file we just downloaded, which is expanded into 462 frames/rows in the <code>frames</code> view.</p> <p>In general, <code>insert()</code> takes as its first argument a list of rows, each of which is a dictionary mapping column names to column values.</p> In\u00a0[\u00a0]: Copied! <pre>v.insert([{'video': filename}])\n</pre> v.insert([{'video': filename}]) <p>We loaded a video that shows a busy intersection in Bangkok. Let's look at the first frame:</p> In\u00a0[\u00a0]: Copied! <pre>f.where(f.pos == 200).select(f.frame, f.frame.width, f.frame.height).show(1)\n</pre> f.where(f.pos == 200).select(f.frame, f.frame.width, f.frame.height).show(1) <p>When we create the <code>frames</code> view, Pixeltable does not physically store the frames. Instead, Pixeltable re-extracts the frames on retrieval using the <code>pos</code> column value, which can be done very efficiently and avoids any storage overhead (which would be very substantial for video frames).</p> In\u00a0[\u00a0]: Copied! <pre>from pixeltable.functions.nos.object_detection_2d import yolox_tiny as model1\n</pre> from pixeltable.functions.nos.object_detection_2d import yolox_tiny as model1 <p>We can then use <code>model1()</code> in the Pixeltable index operator using standard Python function call syntax:</p> In\u00a0[\u00a0]: Copied! <pre>f.where(f.frame_idx == 0).select(f.frame, model1(f.frame)).show(1)\n</pre> f.where(f.frame_idx == 0).select(f.frame, model1(f.frame)).show(1) <p>This works as expected, and we now add the detections as a computed column <code>detections_1</code> to the table (there'll be a <code>detections_2</code> later).</p> <p>Running model inference is generally an expensive operation; adding it as a computed column makes sure it only runs once, at the time the row is inserted. After that, the result is available as part of the stored table data.</p> <p>Note that for computed columns of any type other than <code>image</code>, the computed values are always stored (ie, <code>stored=True</code>).</p> In\u00a0[\u00a0]: Copied! <pre>f.add_column(detections_1=model1(f.frame))\n</pre> f.add_column(detections_1=model1(f.frame)) <p>The column is now part of <code>f</code>'s schema:</p> In\u00a0[\u00a0]: Copied! <pre>f\n</pre> f <p>We can create a simple user-defined function <code>draw_boxes()</code> to visualize detections:</p> In\u00a0[\u00a0]: Copied! <pre>import PIL.ImageDraw\n\n@pxt.udf(return_type=pxt.ImageType(), param_types=[pxt.ImageType(), pxt.JsonType()])\ndef draw_boxes(img, boxes):\n    result = img.copy()\n    d = PIL.ImageDraw.Draw(result)\n    for box in boxes:\n        d.rectangle(box, width=3)\n    return result\n</pre> import PIL.ImageDraw  @pxt.udf(return_type=pxt.ImageType(), param_types=[pxt.ImageType(), pxt.JsonType()]) def draw_boxes(img, boxes):     result = img.copy()     d = PIL.ImageDraw.Draw(result)     for box in boxes:         d.rectangle(box, width=3)     return result <p>This function takes two arguments:</p> <ul> <li><code>img</code> has type <code>image</code> and receives an instance of <code>PIL.Image.Image</code></li> <li><code>boxes</code> has type <code>json</code> and receives a JSON-serializable structure, in this case a list of 4-element lists of floats</li> </ul> <p>When we \"call\" this function, we need to pass in the frame and the bounding boxes identified in that frame. The latter can be selected with the JSON path expression <code>t.detections.boxes</code>:</p> In\u00a0[\u00a0]: Copied! <pre>f.where(f.pos == 0).select(f.frame, draw_boxes(f.frame, f.detections_1.bboxes)).show(1)\n</pre> f.where(f.pos == 0).select(f.frame, draw_boxes(f.frame, f.detections_1.bboxes)).show(1) <p>Looking at individual frames gives us some idea of how well our detection algorithm works, but it would be more instructive to turn the visualization output back into a video.</p> <p>We do that with the built-in function <code>make_video()</code>, which is an aggregation function that takes a frame index (actually: any expression that can be used to order the frames; a timestamp would also work) and an image, and then assembles the sequence of images into a video:</p> In\u00a0[\u00a0]: Copied! <pre>f.select(pxt.make_video(f.pos, draw_boxes(f.frame, f.detections_1.bboxes))).group_by(v).show()\n</pre> f.select(pxt.make_video(f.pos, draw_boxes(f.frame, f.detections_1.bboxes))).group_by(v).show() In\u00a0[\u00a0]: Copied! <pre>from pixeltable.functions.nos.object_detection_2d import yolox_medium as model2\n</pre> from pixeltable.functions.nos.object_detection_2d import yolox_medium as model2 <p>We're using the alternative form of adding table columns:</p> In\u00a0[\u00a0]: Copied! <pre>f['detections_2'] = model2(f.frame)\n</pre> f['detections_2'] = model2(f.frame) <p>We don't have ground truth data yet, but visualizing the output in the form of a video gives us some clue how much a smaller model affects the result:</p> In\u00a0[\u00a0]: Copied! <pre>f.select(\n    pxt.make_video(f.frame_idx, draw_boxes(f.frame, f.detections_1.bboxes)),\n    pxt.make_video(f.frame_idx, draw_boxes(f.frame, f.detections_2.bboxes)),\n).group_by(v).show(1)\n</pre> f.select(     pxt.make_video(f.frame_idx, draw_boxes(f.frame, f.detections_1.bboxes)),     pxt.make_video(f.frame_idx, draw_boxes(f.frame, f.detections_2.bboxes)), ).group_by(v).show(1) In\u00a0[\u00a0]: Copied! <pre>from pixeltable.functions.nos.object_detection_2d import yolox_xlarge\n</pre> from pixeltable.functions.nos.object_detection_2d import yolox_xlarge In\u00a0[\u00a0]: Copied! <pre>f['gt'] = yolox_xlarge(f.frame)\n</pre> f['gt'] = yolox_xlarge(f.frame) <p>We now have two columns with detections, <code>detections_1</code> and <code>detections_2</code>, and one column <code>gt</code> with synthetic ground-truth data, which we're going to use as the basis for evaluation:</p> In\u00a0[\u00a0]: Copied! <pre>f\n</pre> f <p>We're going to be evaluating the generated detections with the commonly-used mean average precision metric (mAP).</p> <p>The mAP metric is based on per-frame metrics, such as true and false positives per detected class, which are then aggregated into a single (per-class) number. In Pixeltable, functionality is available via the <code>eval_detections()</code> and <code>mean_ap()</code> built-in functions:</p> In\u00a0[\u00a0]: Copied! <pre>from pixeltable.functions.eval import eval_detections, mean_ap\n</pre> from pixeltable.functions.eval import eval_detections, mean_ap <p>The <code>eval_detections()</code> function computes the required per-frame metrics, and we're going to add those as computed columns in order to cache the output (and avoid having to re-type the call to <code>eval_detections()</code> repeatedly later).</p> In\u00a0[\u00a0]: Copied! <pre>f['eval_1'] = eval_detections(\n    f.detections_1.bboxes, f.detections_1.labels, f.detections_1.scores, f.gt.bboxes, f.gt.labels)\n</pre> f['eval_1'] = eval_detections(     f.detections_1.bboxes, f.detections_1.labels, f.detections_1.scores, f.gt.bboxes, f.gt.labels) In\u00a0[\u00a0]: Copied! <pre>f['eval_2'] = eval_detections(\n    f.detections_2.bboxes, f.detections_2.labels, f.detections_2.scores, f.gt.bboxes, f.gt.labels)\n</pre> f['eval_2'] = eval_detections(     f.detections_2.bboxes, f.detections_2.labels, f.detections_2.scores, f.gt.bboxes, f.gt.labels) <p>Let's take a look at the output:</p> In\u00a0[\u00a0]: Copied! <pre>f.select(f.eval_1, f.eval_2).show(1)\n</pre> f.select(f.eval_1, f.eval_2).show(1) <p>The computation of the mAP metric is now simply a query over the evaluation output, aggregated with the <code>mean_ap()</code> function:</p> In\u00a0[\u00a0]: Copied! <pre>f.select(mean_ap(f.eval_1), mean_ap(f.eval_2)).show(1)\n</pre> f.select(mean_ap(f.eval_1), mean_ap(f.eval_2)).show(1) <p>This two-step process allows you to compute mAP at every granularity: over your entire dataset, only for specific videos, only for videos that pass a certain filter, etc. Moreover, you can compute this metric any time, not just during training, and use it to guide your understand of your dataset and how it affects the quality of your models.</p> In\u00a0[\u00a0]: Copied! <pre>@pxt.udf(return_type=pxt.JsonType(nullable=False), param_types=[pxt.JsonType(nullable=False)])\ndef yolo_to_coco(detections):\n    bboxes, labels = detections['bboxes'], detections['labels']\n    num_annotations = len(detections['bboxes'])\n    assert num_annotations == len(detections['labels'])\n    result = []\n    for i in range(num_annotations):\n        bbox = bboxes[i]\n        ann = {\n            'bbox': [round(bbox[0]), round(bbox[1]), round(bbox[2] - bbox[0]), round(bbox[3] - bbox[1])],\n            'category': labels[i],\n        }\n        result.append(ann)\n    return result\n</pre> @pxt.udf(return_type=pxt.JsonType(nullable=False), param_types=[pxt.JsonType(nullable=False)]) def yolo_to_coco(detections):     bboxes, labels = detections['bboxes'], detections['labels']     num_annotations = len(detections['bboxes'])     assert num_annotations == len(detections['labels'])     result = []     for i in range(num_annotations):         bbox = bboxes[i]         ann = {             'bbox': [round(bbox[0]), round(bbox[1]), round(bbox[2] - bbox[0]), round(bbox[3] - bbox[1])],             'category': labels[i],         }         result.append(ann)     return result In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/comparing_object_detection_models_for_video/#comparing-object-detection-models-for-video","title":"Comparing Object Detection Models for Video\u00b6","text":""},{"location":"tutorials/comparing_object_detection_models_for_video/#creating-a-tutorial-directory-and-table","title":"Creating a tutorial directory and table\u00b6","text":"<p>In Pixeltable, all data resides in tables, which in turn located inside directories.</p> <p>Let's start by creating a client and a <code>video_tutorial</code> directory:</p>"},{"location":"tutorials/comparing_object_detection_models_for_video/#object-detection-with-pixeltable","title":"Object detection with Pixeltable\u00b6","text":"<p>Pixeltable comes pre-packaged with a number of object detection models. We're going to explore one from the YoloX family.</p>"},{"location":"tutorials/comparing_object_detection_models_for_video/#comparing-multiple-detection-models","title":"Comparing multiple detection models\u00b6","text":"<p>The output of YoloX-tiny seems reasonable, but we're curious how much better a slightly larger model, such as YoloX-medium, would be for our particular use case. Instead of creating another table and reloading the data, etc., we can simply add another column to our existing table:</p>"},{"location":"tutorials/comparing_object_detection_models_for_video/#evaluating-the-models-against-ground-truth","title":"Evaluating the models against ground truth\u00b6","text":"<p>In order to have something to base the evaluation on, let's generate some 'ground truth' data by running the largest YoloX model available.</p>"},{"location":"tutorials/comparing_object_detection_models_for_video/#exporting-detection-data-as-a-coco-dataset","title":"Exporting Detection Data as a COCO Dataset\u00b6","text":""},{"location":"tutorials/image-operations/","title":"Image Operations in Pixeltable","text":"<p>In this tutorial we're going to be working with a subset of the COCO dataset (10 samples each for the train, test, and validation splits). To avoid further installs, the tutorial comes pre-packaged with a data file (of JSON records) and a set of images, which we're going to download into a temp directory now:</p> In\u00a0[1]: Copied! <pre>import json\nimport urllib.request\nimport tempfile\nimport tqdm\n\ndownload_prefix = 'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data'\njson_data_url = f'{download_prefix}/coco-records.json'\n\nrecords = json.loads(urllib.request.urlopen(json_data_url).read().decode('utf-8'))\n\nimage_dir = tempfile.mkdtemp()\nfor r in tqdm.tqdm(records):\n    filename = r['filepath'].split('/')[1]\n    out_filepath = f'{image_dir}/{filename}'\n    url = f'{download_prefix}/{r[\"filepath\"]}'\n    r['img'] = out_filepath\n    del r['filepath']\n    img_data = urllib.request.urlopen(url).read()\n    with open(out_filepath, 'wb') as img_file:\n        img_file.write(img_data)\n</pre> import json import urllib.request import tempfile import tqdm  download_prefix = 'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data' json_data_url = f'{download_prefix}/coco-records.json'  records = json.loads(urllib.request.urlopen(json_data_url).read().decode('utf-8'))  image_dir = tempfile.mkdtemp() for r in tqdm.tqdm(records):     filename = r['filepath'].split('/')[1]     out_filepath = f'{image_dir}/{filename}'     url = f'{download_prefix}/{r[\"filepath\"]}'     r['img'] = out_filepath     del r['filepath']     img_data = urllib.request.urlopen(url).read()     with open(out_filepath, 'wb') as img_file:         img_file.write(img_data) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:12&lt;00:00,  2.48it/s]\n</pre> <p>Each data record is a dictionary with top-level fields img, tag, metadata, and ground_truth.</p> In\u00a0[2]: Copied! <pre>records[0]\n</pre> records[0] Out[2]: <pre>{'metadata': {'width': 640, 'height': 480},\n 'ground_truth': {'detections': [{'attributes': {},\n    'tags': [],\n    'label': 'bowl',\n    'bounding_box': [0.0016875000000000002,\n     0.3910208333333333,\n     0.9556093750000001,\n     0.5954999999999999],\n    'supercategory': 'kitchen',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'bowl',\n    'bounding_box': [0.48707812500000003,\n     0.008979166666666667,\n     0.49887499999999996,\n     0.47641666666666665],\n    'supercategory': 'kitchen',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'broccoli',\n    'bounding_box': [0.39,\n     0.4776458333333334,\n     0.49412500000000004,\n     0.5105833333333334],\n    'supercategory': 'food',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'bowl',\n    'bounding_box': [0.0, 0.02814583333333333, 0.678875, 0.7815],\n    'supercategory': 'kitchen',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'orange',\n    'bounding_box': [0.5878125, 0.08408333333333333, 0.118046875, 0.0969375],\n    'supercategory': 'food',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'orange',\n    'bounding_box': [0.7277812499999999,\n     0.0811875,\n     0.090734375,\n     0.09722916666666667],\n    'supercategory': 'food',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'orange',\n    'bounding_box': [0.60265625,\n     0.15345833333333334,\n     0.13128125,\n     0.14689583333333334],\n    'supercategory': 'food',\n    'iscrowd': 0},\n   {'attributes': {},\n    'tags': [],\n    'label': 'orange',\n    'bounding_box': [0.568828125, 0.0051875, 0.1480625, 0.14806249999999999],\n    'supercategory': 'food',\n    'iscrowd': 0}]},\n 'tag': 'train',\n 'img': '/tmp/tmp6gr0t1dv/000000000009.jpg'}</pre> In\u00a0[3]: Copied! <pre>import pixeltable as pxt\n\ncl = pxt.Client()\ncl.create_dir('overview', ignore_errors=True)\n</pre> import pixeltable as pxt  cl = pxt.Client() cl.create_dir('overview', ignore_errors=True) <pre>/home/marcel/pixeltable/pixeltable/exec/expr_eval_node.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n</pre> <pre>setting up Pixeltable at /home/marcel/.pixeltable\n2024-03-25 16:27:29,040 INFO pixeltable env.py:208: creating database at postgresql://postgres:@/pixeltable?host=/home/marcel/.pixeltable/pgdata\n2024-03-25 16:27:30,179 INFO pixeltable env.py:257: Initializing OpenAI client.\n2024-03-25 16:27:30,252 INFO pixeltable env.py:231: connecting to NOS\n2024-03-25 16:27:30.274 | INFO     | nos.server:init:131 - Inference server already running (name=nos-inference-service-gpu, image=&lt;Image: 'autonomi/nos:0.0.9-gpu'&gt;, id=cc6f90997373).\n2024-03-25 16:27:30,275 INFO pixeltable env.py:234: waiting for NOS\nCreated directory `overview`.\n</pre> In\u00a0[4]: Copied! <pre>schema = {\n    'img': {'type': pxt.ImageType(nullable=False), 'indexed': True},\n    'tag': pxt.StringType(nullable=False),\n    'metadata': pxt.JsonType(nullable=False),\n    'ground_truth': pxt.JsonType(nullable=True),\n}\n</pre> schema = {     'img': {'type': pxt.ImageType(nullable=False), 'indexed': True},     'tag': pxt.StringType(nullable=False),     'metadata': pxt.JsonType(nullable=False),     'ground_truth': pxt.JsonType(nullable=True), } <p><code>nullable=False</code> means the values in this column can't be <code>None</code>, which Pixeltable will check at data insertion time (<code>nullable=False</code> is the default, so we'll leave that out from now on). <code>indexed=True</code> tells Pixeltable to create a vector index for embeddings (using CLIP) for the images in this column, which enables text and image similarity search. More on that later.</p> <p>The available data types in Pixeltable are:</p> Pixeltable type Python type <code>pxt.StringType()</code> <code>str</code> <code>pxt.IntType()</code> <code>int</code> <code>pxt.FloatType()</code> <code>float</code> <code>pxt.BoolType()</code> <code>bool</code> <code>pxt.TimestampType()</code> <code>datetime.datetime</code> <code>pxt.JsonType()</code> lists and dicts that can be converted to JSON <code>pxt.ArrayType()</code> <code>numpy.ndarray</code> <code>pxt.ImageType()</code> <code>PIL.Image.Image</code> <code>pxt.VideoType()</code> <code>str</code> (the file path) <p>We then create a table <code>data</code>:</p> In\u00a0[5]: Copied! <pre>cl.drop_table('overview.data', ignore_errors=True)\ndata = cl.create_table('overview.data', schema)\n</pre> cl.drop_table('overview.data', ignore_errors=True) data = cl.create_table('overview.data', schema) <pre>Created table `data`.\n</pre> <p>At this point, table <code>data</code> contains no data:</p> In\u00a0[6]: Copied! <pre>data.count()\n</pre> data.count() Out[6]: <pre>0</pre> <p>In order to populate <code>data</code> with what's in <code>records</code>, we call the <code>insert()</code> function, which requires a list of rows, each of which is a dictionary mapping column names to column values.</p> In\u00a0[7]: Copied! <pre>data.insert(records)\n</pre> data.insert(records) <pre>Computing cells:   0%|          | 0/30 [00:00&lt;?, ?cells/s]</pre> <pre>Inserting rows into `data`: 0 rows [00:00, ? rows/s]</pre> <pre>Inserted 30 rows with 0 errors.\n</pre> Out[7]: <pre>UpdateStatus(num_rows=30, num_computed_values=30, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>In Pixeltable, images are 'inserted' as file paths, and Pixeltable only stores these paths and not the images themselves, so there is no duplication of storage.</p> <p>Let's look at the first 3 rows:</p> In\u00a0[8]: Copied! <pre>data.head(3)\n</pre> data.head(3) Out[8]: img tag metadata ground_truth train {'width': 640, 'height': 480} {'detections': [{'tags': [], 'label': 'bowl', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.0016875000000000002, 0.3910208333333333, 0.9556093750000001, 0.5954999999999999], 'supercategory': 'kitchen'}, {'tags': [], 'label': 'bowl', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.48707812500000003, 0.008979166666666667, 0.49887499999999996, 0.47641666666666665], 'supercategory': 'kitchen'}, {'tags': [], 'label': 'broccoli', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.39, 0.4776458333333334, 0.49412500000000004, 0.5105833333333334], 'supercategory': 'food'}, {'tags': [], 'label': 'bowl', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.0, 0.02814583333333333, 0.678875, 0.7815], 'supercategory': 'kitchen'}, {'tags': [], 'label': 'orange', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.5878125, 0.08408333333333333, 0.118046875, 0.0969375], 'supercategory': 'food'}, {'tags': [], 'label': 'orange', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.7277812499999999, 0.0811875, 0.090734375, 0.09722916666666667], 'supercategory': 'food'}, {'tags': [], 'label': 'orange', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.60265625, 0.15345833333333334, 0.13128125, 0.14689583333333334], 'supercategory': 'food'}, {'tags': [], 'label': 'orange', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.568828125, 0.0051875, 0.1480625, 0.14806249999999999], 'supercategory': 'food'}]} train {'width': 640, 'height': 426} {'detections': [{'tags': [], 'label': 'giraffe', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.602390625, 0.14091549295774647, 0.335890625, 0.6975586854460094], 'supercategory': 'animal'}, {'tags': [], 'label': 'giraffe', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.082828125, 0.836830985915493, 0.206296875, 0.12955399061032863], 'supercategory': 'animal'}]} train {'width': 640, 'height': 428} {'detections': [{'tags': [], 'label': 'potted plant', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.32009375, 0.07247663551401869, 0.39825, 0.7572897196261682], 'supercategory': 'furniture'}, {'tags': [], 'label': 'vase', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.3711875, 0.36404205607476636, 0.26, 0.45619158878504673], 'supercategory': 'indoor'}]} <p>Let's do this again, so we can demonstrate <code>revert()</code>:</p> In\u00a0[9]: Copied! <pre>data.insert(records)\n</pre> data.insert(records) <pre>Computing cells:   0%|          | 0/30 [00:00&lt;?, ?cells/s]</pre> <pre>Inserting rows into `data`: 0 rows [00:00, ? rows/s]</pre> <pre>Inserted 30 rows with 0 errors.\n</pre> Out[9]: <pre>UpdateStatus(num_rows=30, num_computed_values=30, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>We have now loaded our data twice:</p> In\u00a0[10]: Copied! <pre>data.count()\n</pre> data.count() Out[10]: <pre>60</pre> In\u00a0[11]: Copied! <pre>data.revert()\ndata.count()\n</pre> data.revert() data.count() Out[11]: <pre>30</pre> In\u00a0[12]: Copied! <pre>cl = pxt.Client()\n</pre> cl = pxt.Client() <p>We already have a database <code>tutorials</code>, so now we call <code>get_db()</code> instead of <code>create_db()</code> (in fact, the latter would return with an exception). Likewise, we call <code>get_table()</code> to get a handle to the already present <code>data</code> table:</p> In\u00a0[13]: Copied! <pre>data = cl.get_table('overview.data')\ndata.count()\n</pre> data = cl.get_table('overview.data') data.count() Out[13]: <pre>30</pre> In\u00a0[14]: Copied! <pre>data.where(data.tag == 'test').show(2)\n</pre> data.where(data.tag == 'test').show(2) Out[14]: img tag metadata ground_truth test {'width': 640, 'height': 480} None test {'width': 480, 'height': 640} None <p>Or at data for images that are less than 640 pixels wide:</p> In\u00a0[15]: Copied! <pre>data.where(data.metadata.width &lt; 640).show(2)\n</pre> data.where(data.metadata.width &lt; 640).show(2) Out[15]: img tag metadata ground_truth train {'width': 481, 'height': 640} {'detections': [{'tags': [], 'label': 'umbrella', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.0, 0.0783125, 0.9515176715176715, 0.6724218750000001], 'supercategory': 'accessory'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.3483991683991684, 0.25451562499999997, 0.6457588357588357, 0.726859375], 'supercategory': 'person'}]} train {'width': 381, 'height': 500} {'detections': [{'tags': [], 'label': 'horse', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.42669291338582677, 0.45312, 0.34228346456692915, 0.36886], 'supercategory': 'animal'}, {'tags': [], 'label': 'horse', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.21443569553805775, 0.48988, 0.21971128608923882, 0.31639999999999996], 'supercategory': 'animal'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.5338320209973753, 0.52086, 0.17241469816272964, 0.14608000000000002], 'supercategory': 'person'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.31083989501312337, 0.52264, 0.14937007874015748, 0.12586], 'supercategory': 'person'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.3132283464566929, 0.66842, 0.031338582677165355, 0.06714], 'supercategory': 'person'}, {'tags': [], 'label': 'potted plant', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.5295800524934383, 0.85238, 0.18593175853018373, 0.09445999999999999], 'supercategory': 'furniture'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.7462992125984251, 0.6668, 0.028556430446194228, 0.05486], 'supercategory': 'person'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.5013123359580053, 0.66874, 0.018792650918635172, 0.04682], 'supercategory': 'person'}, {'tags': [], 'label': 'person', 'iscrowd': 0, 'attributes': {}, 'bounding_box': [0.9101312335958005, 0.6668, 0.03884514435695538, 0.01844], 'supercategory': 'person'}]} <p>Pixeltable supports the standard comparison operators (<code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>==</code>) and logical operators (<code>&amp;</code> for <code>and</code>, <code>|</code> for <code>or</code>, <code>~</code> for <code>not</code>). Like in Pandas, logical operators need to be wrapped in parentheses:</p> In\u00a0[16]: Copied! <pre>data.where((data.tag == 'test') &amp; (data.metadata.width &lt; 640)).show(2)\n</pre> data.where((data.tag == 'test') &amp; (data.metadata.width &lt; 640)).show(2) Out[16]: img tag metadata ground_truth test {'width': 480, 'height': 640} None In\u00a0[17]: Copied! <pre>data.select(data.tag, data.metadata).show(2)\n</pre> data.select(data.tag, data.metadata).show(2) Out[17]: tag metadata train {'width': 640, 'height': 480} train {'width': 640, 'height': 426} <p>In general, each element in <code>select()</code> needs to be a Pixeltable expression. In the previous example, the expressions were simple column references, but Pixeltable also supports most standard arithmetic operators as well as a set of type-specific functions (more on those in a bit). For example, to retrieve the total number of pixels per image:</p> In\u00a0[18]: Copied! <pre>data.select(data.tag, data.metadata.width * data.metadata.height).show(2)\n</pre> data.select(data.tag, data.metadata.width * data.metadata.height).show(2) Out[18]: tag col_1 train 307200 train 272640 In\u00a0[19]: Copied! <pre>data.select(data.ground_truth.detections['*'].bounding_box).show(2)\n</pre> data.select(data.ground_truth.detections['*'].bounding_box).show(2) Out[19]: groundtruth_detectionsstar_boundingbox [[0.0016875000000000002, 0.3910208333333333, 0.9556093750000001, 0.5954999999999999], [0.48707812500000003, 0.008979166666666667, 0.49887499999999996, 0.47641666666666665], [0.39, 0.4776458333333334, 0.49412500000000004, 0.5105833333333334], [0.0, 0.02814583333333333, 0.678875, 0.7815], [0.5878125, 0.08408333333333333, 0.118046875, 0.0969375], [0.7277812499999999, 0.0811875, 0.090734375, 0.09722916666666667], [0.60265625, 0.15345833333333334, 0.13128125, 0.14689583333333334], [0.568828125, 0.0051875, 0.1480625, 0.14806249999999999]] [[0.602390625, 0.14091549295774647, 0.335890625, 0.6975586854460094], [0.082828125, 0.836830985915493, 0.206296875, 0.12955399061032863]] <p>The field <code>detections</code> contains a list, and the <code>'*'</code> index indicates that you want all elements in that list. You can also use standard Python list indexing and slicing operations, such as</p> In\u00a0[20]: Copied! <pre>data.select(data.ground_truth.detections[0].bounding_box).show(2)\n</pre> data.select(data.ground_truth.detections[0].bounding_box).show(2) Out[20]: groundtruth_detections0_boundingbox [0.0016875000000000002, 0.3910208333333333, 0.9556093750000001, 0.5954999999999999] [0.602390625, 0.14091549295774647, 0.335890625, 0.6975586854460094] <p>to select only the first bounding box, or</p> In\u00a0[21]: Copied! <pre>data.select(data.ground_truth.detections[::-1].bounding_box).show(2)\n</pre> data.select(data.ground_truth.detections[::-1].bounding_box).show(2) Out[21]: groundtruth_detections1_boundingbox [[0.568828125, 0.0051875, 0.1480625, 0.14806249999999999], [0.60265625, 0.15345833333333334, 0.13128125, 0.14689583333333334], [0.7277812499999999, 0.0811875, 0.090734375, 0.09722916666666667], [0.5878125, 0.08408333333333333, 0.118046875, 0.0969375], [0.0, 0.02814583333333333, 0.678875, 0.7815], [0.39, 0.4776458333333334, 0.49412500000000004, 0.5105833333333334], [0.48707812500000003, 0.008979166666666667, 0.49887499999999996, 0.47641666666666665], [0.0016875000000000002, 0.3910208333333333, 0.9556093750000001, 0.5954999999999999]] [[0.082828125, 0.836830985915493, 0.206296875, 0.12955399061032863], [0.602390625, 0.14091549295774647, 0.335890625, 0.6975586854460094]] <p>to select the bounding boxes in reverse.</p> In\u00a0[22]: Copied! <pre>data.select(data.img.width, data.img.height, data.img.mode).show(2)\n</pre> data.select(data.img.width, data.img.height, data.img.mode).show(2) Out[22]: width height mode 640 480 RGB 640 426 RGB <p>Pixeltable also has a number of built-in functions for images (these are a subset of what is available for <code>PIL.Image.Image</code>):</p> Image function <code>convert()</code> Returns a converted copy of this image <code>crop()</code> Returns a rectangular region from this image <code>effect_spread()</code> Randomly spread pixels in an image <code>entropy()</code> Calculates and returns the entropy for the image <code>filter()</code> Filters this image using the given filter <code>getbands()</code> Returns a tuple containing the name of each band in this image <code>getbbox()</code> Calculates the bounding box of the non-zero regions in the image <code>getchannel()</code> Returns an image containing a single channel of the source image <code>getcolors()</code> Returns a list of colors used in this image <code>getextrema()</code> Gets the minimum and maximum pixel values for each band in the image <code>getpalette()</code> Returns the image palette as a list <code>getpixel()</code> Returns the pixel value at a given position <code>getprojection()</code> Get projection to x and y axes <code>histogram()</code> Returns a histogram for the image <code>point()</code> Maps this image through a lookup table or function <code>quantize()</code> Convert the image to \u2018P\u2019 mode with the specified number of colors <code>reduce()</code> Returns a copy of the image reduced factor times <code>remap_palette()</code> Rewrites the image to reorder the palette <code>resize()</code> Returns a resized copy of this image <code>rotate()</code> Returns a rotated copy of this image <code>transform()</code> Transforms this image <code>transpose()</code> Transpose image (flip or rotate in 90 degree steps) <p>These functions are invoked in the style of method calls and can be chained, as in this example, which rotates the image by 30 degrees and converts it to BW:</p> In\u00a0[23]: Copied! <pre>data.select(data.img.rotate(30).convert('L')).show(2)\n</pre> data.select(data.img.rotate(30).convert('L')).show(2) Out[23]: col_0 In\u00a0[24]: Copied! <pre>sample_img = data.select(data.img).show(1)[0, 0]\nsample_img\n</pre> sample_img = data.select(data.img).show(1)[0, 0] sample_img Out[24]: <p><code>show()</code> returns a result set, which is a two-dimensional structure you can access with standard Python indexing operations (ie, <code>[&lt;row-idx&gt;, &lt;column-idx&gt;]</code>. In this case, we're selecting the first column value of the first row, which is a <code>PIL.Image.Image</code>:</p> In\u00a0[25]: Copied! <pre>type(sample_img)\n</pre> type(sample_img) Out[25]: <pre>PIL.JpegImagePlugin.JpegImageFile</pre> <p>To look for images like this one, use <code>nearest()</code>:</p> In\u00a0[26]: Copied! <pre>data.where(data.img.nearest(sample_img)).select(data.img).show(2)\n</pre> data.where(data.img.nearest(sample_img)).select(data.img).show(2) Out[26]: img <p>We can use the same function to look for images based on text:</p> In\u00a0[27]: Copied! <pre>data.where(data.img.nearest('car')).select(data.img).show(2)\n</pre> data.where(data.img.nearest('car')).select(data.img).show(2) Out[27]: img In\u00a0[28]: Copied! <pre>import torch, torchvision\n\nmodel = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights=\"DEFAULT\")\n_ = model.eval()  # switch to inference mode\n</pre> import torch, torchvision  model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights=\"DEFAULT\") _ = model.eval()  # switch to inference mode <p>Our function converts the image to PyTorch format and obtains a prediction from the model, which is a list of dictionaries with fields <code>boxes</code>, <code>labels</code>, and <code>scores</code> (one per input image). The fields themselves are PyTorch tensors, and we convert them to standard Python lists (so they become JSON-serializable data):</p> In\u00a0[29]: Copied! <pre>@pxt.udf(return_type=pxt.JsonType(), param_types=[pxt.ImageType()])\ndef detect(img):\n    t = torchvision.transforms.ToTensor()(img)\n    t = torchvision.transforms.ConvertImageDtype(torch.float)(t)\n    result = model([t])[0]\n    return {\n        'boxes': result['boxes'].tolist(), 'labels': result['labels'].tolist(), 'scores': result['scores'].tolist()\n    }\n</pre> @pxt.udf(return_type=pxt.JsonType(), param_types=[pxt.ImageType()]) def detect(img):     t = torchvision.transforms.ToTensor()(img)     t = torchvision.transforms.ConvertImageDtype(torch.float)(t)     result = model([t])[0]     return {         'boxes': result['boxes'].tolist(), 'labels': result['labels'].tolist(), 'scores': result['scores'].tolist()     } <p>The <code>pt.function</code> decorator creates a wrapper that tells Pixeltable what arguments the function takes and what it returns. In this case, it takes an image argument and returns a dictionary.</p> <p>We can now use <code>detect</code> in the Pixeltable index operator using standard Python function call syntax:</p> In\u00a0[30]: Copied! <pre>data.select(data.img, detect(data.img)).show(1)\n</pre> data.select(data.img, detect(data.img)).show(1) Out[30]: img col_1 {'boxes': [[310.55047607421875, 0.0, 624.843017578125, 234.52691650390625], [237.1993408203125, 224.08872985839844, 587.0565795898438, 470.91851806640625], [0.0, 29.385292053222656, 426.712158203125, 425.4981994628906], [5.013685703277588, 196.5373992919922, 588.5419921875, 476.083984375], [37.35256576538086, 20.59006118774414, 388.15606689453125, 273.5964660644531], [0.7686876654624939, 22.125137329101562, 633.8622436523438, 476.8524169921875], [150.43922424316406, 1.7851982116699219, 521.2220458984375, 259.53662109375], [327.5017395019531, 415.15777587890625, 424.87408447265625, 480.0], [381.46246337890625, 3.4117469787597656, 461.89776611328125, 80.68553161621094], [384.0293273925781, 231.81298828125, 602.3222045898438, 449.110107421875], [0.0, 112.5062484741211, 239.01593017578125, 304.9220275878906], [329.5346984863281, 0.0, 424.4857482910156, 74.70343017578125], [106.70413970947266, 25.554290771484375, 375.65087890625, 248.9399871826172], [476.35162353515625, 400.2861328125, 637.7496948242188, 478.90008544921875]], 'labels': [51, 56, 51, 51, 51, 67, 51, 56, 55, 56, 54, 53, 54, 51], 'scores': [0.9891068339347839, 0.953942060470581, 0.9483123421669006, 0.9117993712425232, 0.5643739104270935, 0.19624418020248413, 0.1885174959897995, 0.14653879404067993, 0.138069748878479, 0.11395400762557983, 0.10923201590776443, 0.07621481269598007, 0.06613019853830338, 0.05693724378943443]} <p><code>detect</code> returns JSON data, and we can use Pixeltable's JSON functionality to access that as well. For example, if we're only interested in the first detected bounding box and the first label:</p> In\u00a0[31]: Copied! <pre>data.select(detect(data.img).boxes[0], detect(data.img).labels[0]).show(1)\n</pre> data.select(detect(data.img).boxes[0], detect(data.img).labels[0]).show(1) Out[31]: None_boxes0 None_labels0 [310.55047607421875, 0.0, 624.843017578125, 234.52691650390625] 51 <p>When running this query, Pixeltable evalutes <code>detect(data.img)</code> only once per row.</p> In\u00a0[32]: Copied! <pre>data.add_column(detections=detect(data.img))\n</pre> data.add_column(detections=detect(data.img)) <pre>Computing cells:   0%|          | 0/30 [00:00&lt;?, ?cells/s]</pre> <pre>added 30 column values with 0 errors\n</pre> Out[32]: <pre>UpdateStatus(num_rows=30, num_computed_values=30, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p><code>detections</code> is now a column in <code>data</code> which holds the model prediction for the <code>img</code> column. Like any other column, it is persistent. Pixeltables runs the computation  automatically whenever new data is added to the table. Let's see what <code>data</code> looks like now:</p> In\u00a0[33]: Copied! <pre>data.describe()\n</pre> data.describe() Column Name Type Computed With img image tag string metadata json ground_truth json detections json detect(img) <p>In general, the <code>computed_with</code> keyword argument can be any Pixeltable expression. In this example, we're making the first label recorded in <code>detections</code> available as a separate column:</p> In\u00a0[34]: Copied! <pre>data.add_column(first_label=data.detections.labels[0])\ndata.select(data.detections.labels, data.first_label).show(1)\n</pre> data.add_column(first_label=data.detections.labels[0]) data.select(data.detections.labels, data.first_label).show(1) <pre>Computing cells:   0%|          | 0/30 [00:00&lt;?, ?cells/s]</pre> <pre>added 30 column values with 0 errors\n</pre> Out[34]: detections_labels first_label [1, 1, 1, 1, 67, 46, 46, 46, 44, 46, 67, 73, 46, 72, 44, 1, 44, 73, 47, 47, 44, 1, 67, 46, 46, 47, 46, 44, 31, 1, 59, 67] 1 <p>Whether a computed image column is stored is controlled by the <code>stored</code> keyword argument of the <code>Column</code> constructor:</p> <ul> <li>when set to <code>True</code>, the value is stored explicitly</li> <li>when set to <code>False</code>, the value is always recomputed during a query (and never stored)</li> <li>the default is <code>None</code>, which means that the Pixeltable decides (currently that means that the image won't be stored, but in the future it could take resource consumption into account)</li> </ul>"},{"location":"tutorials/image-operations/#image-operations-in-pixeltable","title":"Image Operations in Pixeltable\u00b6","text":""},{"location":"tutorials/image-operations/#data-ingest","title":"Data Ingest\u00b6","text":"<p>In Pixeltable, all data resides in tables, which themselves can be organized into a directory structure.</p> <p>Let's start by creating a client and an <code>overview</code> directory (the <code>ignore_errors</code> argument tells it not to raise an exception if the directory already exists):</p>"},{"location":"tutorials/image-operations/#creating-a-table","title":"Creating a table\u00b6","text":"<p>A table for our sample data requires a column for each top-level field: <code>filepath</code>, <code>tag</code>, <code>metadata</code>, <code>ground_truth</code>.</p> <p>Instead of a file path per image we are going to store the image directly. The table schema is as follows:</p>"},{"location":"tutorials/image-operations/#inserting-data","title":"Inserting data\u00b6","text":""},{"location":"tutorials/image-operations/#versioning-in-pixeltable","title":"Versioning in Pixeltable\u00b6","text":"<p>Pixeltable maintains a version history for data changes to tables (ie, inserting data and adding/dropping columns). The <code>revert()</code> method lets you go back to the preceding version.</p> <p>For our table <code>data</code>, since we don't want duplicates, we revert the last update:</p>"},{"location":"tutorials/image-operations/#data-persistence","title":"Data persistence\u00b6","text":"<p>Unlike \"computational containers\" such as Pandas or Dask DataFrames, tables in Pixeltable are persistent. To illustrate that, let's create a new Pixeltable client and a new handle to the <code>data</code> table:</p>"},{"location":"tutorials/image-operations/#retrieving-data","title":"Retrieving data\u00b6","text":"<p>Pixeltable allows filtering with the <code>where()</code> function.</p> <p>For example, to only look at test data:</p>"},{"location":"tutorials/image-operations/#selecting-output","title":"Selecting output\u00b6","text":"<p>By default, Pixeltable will retrieve all columns of a table. In order to select what you want to retrieve, use the <code>select()</code> function.</p> <p>Let's retrieve columns <code>tag</code> and <code>metadata</code>:</p>"},{"location":"tutorials/image-operations/#operations-on-json-data","title":"Operations on JSON data\u00b6","text":"<p>The previous example illustrates the use of path expressions against JSON-typed data: <code>width</code> is a field in the <code>metadata</code> column, which we can simply access as <code>data.metadata.width</code>.</p> <p>Another example: retrieve only the bounding boxes from the <code>ground_truth</code> column. This will come in handy later when we need to pass those bounding boxes (and not the surrounding dictionary) into a function.</p>"},{"location":"tutorials/image-operations/#operations-on-image-data","title":"Operations on image data\u00b6","text":"<p>Image data has properties <code>width</code>, <code>height</code>, and <code>mode</code>:</p>"},{"location":"tutorials/image-operations/#image-similarity-search","title":"Image similarity search\u00b6","text":"<p>When we created the <code>frame</code> column we specified <code>indexed=True</code>, which creates a vector index of CLIP embeddings for the images in that column. We can take advantage of that with the search function <code>nearest()</code>. First, let's get a sample image from <code>data</code>:</p>"},{"location":"tutorials/image-operations/#user-defined-functions","title":"User-defined functions\u00b6","text":"<p>User-defined functions let you customize Pixeltable's functionality for your own data.</p> <p>In this example, we're going use a <code>torchvision</code> object detection model (Faster R-CNN) against the images in <code>data</code> with a user-defined function:</p>"},{"location":"tutorials/image-operations/#computed-columns","title":"Computed columns\u00b6","text":"<p>Being able to run models against any image stored in Pixeltable is very useful, but the runtime cost of model inference makes it impractical to run it every time we want to do something with the model output. In Pixeltable, we can use computed columns to precompute and cache the output of a function:</p>"},{"location":"tutorials/object-detection-in-videos/","title":"Object Detection in Videos","text":"<p>In this tutorial we'll demonstrate how to use Pixeltable to do frame-by-frame object detection, made simple through Pixeltable's video-related functionality:</p> <ul> <li>automatic frame extraction</li> <li>running complex functions against frames (in this case, an object detection model)</li> <li>reassembling frames back into videos</li> </ul> <p>We'll be working with a single video file (from Pixeltable's test data directory). Let's download that now:</p> In\u00a0[1]: Copied! <pre>import urllib.request\n\ndownload_url = 'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/bangkok.mp4'\nfilename, _ = urllib.request.urlretrieve(download_url)\n</pre> import urllib.request  download_url = 'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/bangkok.mp4' filename, _ = urllib.request.urlretrieve(download_url) <p>Let's also switch to using the full window width, which will make looking at videos later easier.</p> In\u00a0[2]: Copied! <pre>from IPython.display import display, HTML\ndisplay(HTML(\"&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;\"))\n</pre> from IPython.display import display, HTML display(HTML(\"\")) In\u00a0[3]: Copied! <pre>import pixeltable as pxt\n\ncl = pxt.Client()\ncl.create_dir('video_tutorial', ignore_errors=True)\n</pre> import pixeltable as pxt  cl = pxt.Client() cl.create_dir('video_tutorial', ignore_errors=True) <pre>2024-01-02 13:18:33,023 INFO env env.py:191: found store container\n2024-01-02 13:18:33,024 INFO env env.py:214: connecting to NOS\n2024-01-02 13:18:33.046 | INFO     | nos.server:init:131 - Inference server already running (name=nos-inference-service-gpu, image=&lt;Image: 'autonomi/nos:0.0.9-gpu'&gt;, id=87be2b6a5d19).\n2024-01-02 13:18:33,047 INFO env env.py:217: waiting for NOS\n2024-01-02 13:18:33,058 INFO env env.py:238: connecting to OpenAI\n2024-01-02 13:18:33,099 INFO env env.py:180: found database postgresql://postgres:*****@localhost:6543/pixeltable\n</pre> <pre>/home/marcel/pixeltable/pixeltable/exec/expr_eval_node.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n</pre> <p>We create a table for our videos, with a single column:</p> In\u00a0[4]: Copied! <pre>video_path = 'video_tutorial.videos'\nframe_path = 'video_tutorial.frames'\ncl.drop_table(frame_path, ignore_errors=True)\ncl.drop_table(video_path, ignore_errors=True)\nv = cl.create_table(video_path, {'video': pxt.VideoType()})\n</pre> video_path = 'video_tutorial.videos' frame_path = 'video_tutorial.frames' cl.drop_table(frame_path, ignore_errors=True) cl.drop_table(video_path, ignore_errors=True) v = cl.create_table(video_path, {'video': pxt.VideoType()}) <p>In order to interact with the frames, we take advantage of Pixeltable's component view concept: we create a \"view\" of our video table that contains one row for each frame. Pixeltable provides the built-in <code>FrameIterator</code> class for this.</p> In\u00a0[5]: Copied! <pre>from pixeltable.iterators import FrameIterator\nargs = {'video': v.video, 'fps': 0}\nf = cl.create_view(frame_path, v, iterator_class=FrameIterator, iterator_args=args)\n</pre> from pixeltable.iterators import FrameIterator args = {'video': v.video, 'fps': 0} f = cl.create_view(frame_path, v, iterator_class=FrameIterator, iterator_args=args) <pre>created view frames with 0 rows, 0 exceptions\n</pre> <p>The <code>fps</code> parameter determines the frame rate, with <code>0</code> indicating the native frame rate.</p> <p>Running this creates a view with six columns:</p> <ul> <li><code>frame_idx</code>, <code>pos_msec</code>, <code>pos_frame</code> and <code>frame</code> are created by the <code>FrameIterator</code> class.</li> <li><code>pos</code> is a system column in every component view</li> <li><code>video</code> is the column for our base table (all base table columns are visible in the view, to facilitate querying)</li> </ul> <p>Note that you could create additional views on the <code>videos</code> table, each with its own frame rate.</p> In\u00a0[6]: Copied! <pre>f\n</pre> f Out[6]: Column Name Type Computed With pos int frame_idx int pos_msec float pos_frame float frame image video video <p>We now insert a single row containing the name of the video file we just downloaded, which is expanded into 462 frames/rows in the <code>video_data</code> table.</p> <p>In general, <code>insert()</code> takes as its first argument a list of rows, each of which is a dictionary mapping column names to column values (and in this case, we only need to supply data for the <code>video</code> column).</p> In\u00a0[7]: Copied! <pre>v.insert([{'video': filename}])\n</pre> v.insert([{'video': filename}]) <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>inserted 463 rows with 0 errors \n</pre> Out[7]: <pre>UpdateStatus(num_rows=463, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>We loaded a video that shows a busy intersection in Bangkok. Let's look at the first frame:</p> In\u00a0[8]: Copied! <pre>f.where(f.pos == 100).select(f.frame, f.frame.width, f.frame.height).show(1)\n</pre> f.where(f.pos == 100).select(f.frame, f.frame.width, f.frame.height).show(1) Out[8]: frame width height 1280 720 <p>When we created the <code>video_data</code> table with automatic frame extraction, Pixeltable does not physically store the frames. Instead, Pixeltable re-extracts the frames on retrieval using the frame index, which can be done very efficiently and avoids any storage overhead (which would be very substantial for video frames).</p> In\u00a0[9]: Copied! <pre>import torch, torchvision\nfrom torchvision import transforms\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\nmodel = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights=\"DEFAULT\")\n_ = model.eval()  # switch to inference mode\n</pre> import torch, torchvision from torchvision import transforms from torchvision.models.detection.faster_rcnn import FastRCNNPredictor  model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights=\"DEFAULT\") _ = model.eval()  # switch to inference mode <p>Our function converts the image to PyTorch format and obtains a prediction from the model, which is a list of dictionaries with fields <code>boxes</code>, <code>labels</code>, and <code>scores</code> (one per input image). The fields themselves are PyTorch tensors, and we convert them to standard Python lists (so they become JSON-serializable data):</p> In\u00a0[10]: Copied! <pre>@pxt.udf(return_type=pxt.JsonType(), param_types=[pxt.ImageType()])\ndef detect(img):\n    t = transforms.ToTensor()(img)\n    t = transforms.ConvertImageDtype(torch.float)(t)\n    result = model([t])[0]\n    return {\n        'boxes': result['boxes'].tolist(), 'labels': result['labels'].tolist(), 'scores': result['scores'].tolist()\n    }\n</pre> @pxt.udf(return_type=pxt.JsonType(), param_types=[pxt.ImageType()]) def detect(img):     t = transforms.ToTensor()(img)     t = transforms.ConvertImageDtype(torch.float)(t)     result = model([t])[0]     return {         'boxes': result['boxes'].tolist(), 'labels': result['labels'].tolist(), 'scores': result['scores'].tolist()     } <p>We can then use <code>detect()</code> in the Pixeltable index operator using standard Python function call syntax:</p> In\u00a0[11]: Copied! <pre>f.where(f.pos == 0).select(f.frame, detect(f.frame)).show(1)\n</pre> f.where(f.pos == 0).select(f.frame, detect(f.frame)).show(1) Out[11]: frame col_1 {'boxes': [[338.0175476074219, 332.3070373535156, 429.0596618652344, 402.53619384765625], [325.52020263671875, 494.7050476074219, 564.3624877929688, 642.5905151367188], [877.4578857421875, 332.5375061035156, 996.2501220703125, 418.927001953125], [0.0, 563.2777099609375, 96.442138671875, 675.6181030273438], [58.37784194946289, 415.9442138671875, 261.9402160644531, 513.2822875976562], [581.9625854492188, 412.841552734375, 680.5651245117188, 520.540771484375], [352.8522644042969, 317.1103515625, 432.1349792480469, 368.0483093261719], [477.9818115234375, 277.43621826171875, 538.7947998046875, 333.2647705078125], [260.5457763671875, 613.036376953125, 384.6195068359375, 716.1728515625], [817.808349609375, 267.61859130859375, 877.5629272460938, 320.37603759765625], [542.4913940429688, 267.648193359375, 615.8351440429688, 314.6510925292969], [462.1524353027344, 595.5888671875, 600.7080688476562, 708.8528442382812], [832.55419921875, 292.0086669921875, 910.73095703125, 349.8305358886719], [481.79815673828125, 625.18115234375, 530.2610473632812, 698.927978515625], [832.3120727539062, 275.2059020996094, 889.4700317382812, 327.6224365234375], [370.4065246582031, 303.6800537109375, 445.7835998535156, 353.4532775878906], [462.2282409667969, 588.984619140625, 600.685791015625, 704.4878540039062], [565.6113891601562, 227.9348602294922, 600.3528442382812, 253.9390869140625], [800.515869140625, 271.34271240234375, 834.0836181640625, 304.6402282714844], [781.1487426757812, 204.7003936767578, 809.4354858398438, 228.893798828125], [261.4764099121094, 600.704833984375, 390.4063720703125, 706.0755004882812], [514.0208129882812, 606.6480712890625, 582.5101318359375, 681.4806518554688], [787.8399658203125, 200.6817626953125, 821.3042602539062, 227.3369598388672], [312.4491882324219, 494.48516845703125, 568.3816528320312, 666.237060546875], [841.86572265625, 261.2328796386719, 887.4227905273438, 307.7901611328125], [416.17559814453125, 280.3645935058594, 452.0413818359375, 320.44171142578125], [637.2534790039062, 212.73159790039062, 661.20361328125, 236.2710418701172], [543.6298828125, 556.77490234375, 592.8339233398438, 609.9484252929688], [1051.6064453125, 370.0489807128906, 1108.3529052734375, 410.62872314453125], [571.7589721679688, 221.79025268554688, 608.386962890625, 249.79959106445312], [553.1995849609375, 566.9710693359375, 601.721923828125, 633.8585815429688], [497.1732177734375, 237.0926513671875, 522.0635986328125, 260.05450439453125], [783.3855590820312, 172.9273681640625, 803.7145385742188, 188.10610961914062], [480.04833984375, 626.2274780273438, 531.7449951171875, 699.1278076171875], [364.04345703125, 282.7181396484375, 397.26617431640625, 321.2613525390625], [587.1902465820312, 208.8715362548828, 615.29931640625, 234.7401885986328], [582.338134765625, 406.96722412109375, 679.001708984375, 521.2233276367188], [783.3407592773438, 257.3707275390625, 812.0374145507812, 292.5958251953125], [481.3855285644531, 267.3361511230469, 544.1088256835938, 323.3392028808594], [543.6251220703125, 597.193115234375, 597.8975830078125, 675.50390625], [56.22223663330078, 414.9085693359375, 262.7411804199219, 513.6013793945312], [787.81494140625, 262.3849182128906, 823.2059936523438, 300.8241271972656], [43.360469818115234, 445.6544494628906, 109.14201354980469, 505.59002685546875], [644.1192016601562, 156.5720672607422, 659.0614013671875, 174.76470947265625], [4.256011486053467, 565.12939453125, 93.84329223632812, 669.02001953125], [565.5870971679688, 227.57872009277344, 600.1443481445312, 254.06661987304688], [645.0853271484375, 137.42784118652344, 659.7764892578125, 154.71595764160156], [781.210693359375, 204.54345703125, 809.305419921875, 228.88009643554688], [497.0690612792969, 236.7109375, 521.9780883789062, 260.2634582519531], [1051.4478759765625, 370.7694091796875, 1107.5220947265625, 409.7809143066406], [545.8430786132812, 595.2823486328125, 597.3834228515625, 674.5313110351562], [375.0856018066406, 275.3240051269531, 404.3190002441406, 309.7868957519531], [210.4198760986328, 305.87103271484375, 237.21241760253906, 349.9939880371094], [375.1878662109375, 275.2144470214844, 404.1910095214844, 309.80975341796875], [787.87109375, 200.51022338867188, 821.1494750976562, 227.3304901123047], [543.3758544921875, 556.5906982421875, 593.2091064453125, 609.5620727539062], [364.1552734375, 282.5020751953125, 397.0612487792969, 321.302001953125], [552.5046997070312, 264.0439758300781, 619.2615356445312, 314.5805969238281], [464.40216064453125, 595.2394409179688, 575.16845703125, 709.7114868164062], [1217.9681396484375, 259.7020263671875, 1269.49951171875, 315.4113464355469], [698.3718872070312, 195.67831420898438, 726.0489501953125, 226.09629821777344], [627.2578125, 210.55836486816406, 653.75634765625, 236.50982666015625], [707.27783203125, 194.48382568359375, 729.6455078125, 219.4149627685547], [459.40093994140625, 584.2823486328125, 603.3065185546875, 704.3050537109375], [480.57855224609375, 625.1348266601562, 531.4030151367188, 698.1009521484375], [353.0716857910156, 289.2542724609375, 385.9111328125, 326.82098388671875], [571.6904907226562, 221.462158203125, 608.2069091796875, 249.91754150390625], [553.1577758789062, 567.327392578125, 601.8734130859375, 633.2405395507812], [507.7207336425781, 607.8046875, 585.56884765625, 682.4329833984375], [353.0852355957031, 288.9319152832031, 385.69024658203125, 326.877197265625], [552.5414428710938, 568.8325805664062, 601.7385864257812, 634.880615234375], [783.5690307617188, 168.09310913085938, 804.8557739257812, 185.38084411621094], [828.9864501953125, 205.8993377685547, 847.8067626953125, 228.95172119140625], [873.7220458984375, 330.4421081542969, 995.7734985351562, 419.1416015625], [783.3650512695312, 172.91421508789062, 803.64892578125, 188.12704467773438]], 'labels': [3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 8, 3, 3, 3, 1, 3, 3, 1, 3, 3, 4, 3, 3, 8, 3, 8, 4, 8, 3, 3, 10, 8, 8, 10, 8, 8, 4, 1, 3, 1, 1, 8, 3, 1, 8, 1, 1, 3, 3, 3, 8, 3, 3, 8, 3, 4, 1, 4, 10, 3, 8, 8], 'scores': [0.9825783967971802, 0.979798436164856, 0.9286074638366699, 0.8872904181480408, 0.8645421862602234, 0.8518538475036621, 0.7539889216423035, 0.7321205735206604, 0.6595825552940369, 0.5377895832061768, 0.49035799503326416, 0.4086756110191345, 0.4038461446762085, 0.36029407382011414, 0.3227679133415222, 0.2956126034259796, 0.28263381123542786, 0.26782479882240295, 0.26622769236564636, 0.23562747240066528, 0.21421395242214203, 0.21407191455364227, 0.2092221975326538, 0.20437131822109222, 0.19513581693172455, 0.1920263022184372, 0.18700462579727173, 0.1868266612291336, 0.1719055026769638, 0.16140103340148926, 0.16112016141414642, 0.15471981465816498, 0.14830312132835388, 0.1457282304763794, 0.13231085240840912, 0.13104577362537384, 0.12564292550086975, 0.12498652935028076, 0.12427442520856857, 0.11434605717658997, 0.11424056440591812, 0.11169431358575821, 0.10880594700574875, 0.1077541634440422, 0.10670698434114456, 0.10328461974859238, 0.09854447096586227, 0.09559914469718933, 0.09531375020742416, 0.09462083131074905, 0.09369251132011414, 0.09344688802957535, 0.09314777702093124, 0.08740679919719696, 0.0869702696800232, 0.08424339443445206, 0.08313509076833725, 0.0776112750172615, 0.07742375135421753, 0.07416439801454544, 0.07387608289718628, 0.073675237596035, 0.07232116907835007, 0.0687900111079216, 0.0672314390540123, 0.06691015511751175, 0.06409753113985062, 0.06371359527111053, 0.06175009161233902, 0.06163323298096657, 0.060352448374032974, 0.05640240013599396, 0.055134207010269165, 0.05204525589942932, 0.050575047731399536]} <p>This works as expected, and we now add the detections as a computed column <code>detections</code> to the table.</p> <p>Running model inference is generally an expensive operation; adding it as a computed column makes sure it only runs once, at the time the row is inserted. After that, the result is available as part of the stored table data.</p> <p>Note that for computed columns of any type other than <code>image</code>, the computed values are always stored (ie, <code>stored=True</code>).</p> In\u00a0[12]: Copied! <pre>f.add_column(detections=detect(f.frame))\n</pre> f.add_column(detections=detect(f.frame)) <pre>Computing cells:   0%|          | 0/462 [00:00&lt;?, ?cells/s]</pre> <pre>added 462 column values with 0 errors\n</pre> Out[12]: <pre>UpdateStatus(num_rows=462, num_computed_values=462, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>We can create a simple function <code>draw_boxes()</code> to visualize detections:</p> In\u00a0[13]: Copied! <pre>import PIL.ImageDraw\n\n@pxt.udf(return_type=pxt.ImageType(), param_types=[pxt.ImageType(), pxt.JsonType()])\ndef draw_boxes(img, boxes):\n    result = img.copy()\n    d = PIL.ImageDraw.Draw(result)\n    for box in boxes:\n        d.rectangle(box, width=3)\n    return result\n</pre> import PIL.ImageDraw  @pxt.udf(return_type=pxt.ImageType(), param_types=[pxt.ImageType(), pxt.JsonType()]) def draw_boxes(img, boxes):     result = img.copy()     d = PIL.ImageDraw.Draw(result)     for box in boxes:         d.rectangle(box, width=3)     return result <p>This function takes two arguments:</p> <ul> <li><code>img</code> has type <code>image</code> and receives an instance of <code>PIL.Image.Image</code></li> <li><code>boxes</code> has type <code>json</code> and receives a JSON-serializable structure, in this case a list of 4-element lists of floats</li> </ul> <p>When we \"call\" this function, we need to pass in the frame and the bounding boxes identified in that frame. The latter can be selected with the JSON path expression <code>t.detections.boxes</code>:</p> In\u00a0[14]: Copied! <pre>f.where(f.frame_idx == 0).select(f.frame, draw_boxes(f.frame, f.detections.boxes)).show(1)\n</pre> f.where(f.frame_idx == 0).select(f.frame, draw_boxes(f.frame, f.detections.boxes)).show(1) Out[14]: frame col_1 <p>Looking at individual frames gives us some idea of how well our detection algorithm works, but it would be more instructive to turn the visualization output back into a video.</p> <p>We do that with the built-in function <code>make_video()</code>, which is an aggregation function that takes a frame index (actually: any expression that can be used to order the frames; a timestamp would also work) and an image, and then assembles the sequence of images into a video:</p> In\u00a0[15]: Copied! <pre>f.select(pxt.make_video(f.pos, draw_boxes(f.frame, f.detections.boxes))).group_by(v).show(1)\n</pre> f.select(pxt.make_video(f.pos, draw_boxes(f.frame, f.detections.boxes))).group_by(v).show(1) Out[15]: col_0 In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/object-detection-in-videos/#object-detection-in-videos","title":"Object Detection in Videos\u00b6","text":""},{"location":"tutorials/object-detection-in-videos/#creating-a-tutorial-directory-and-table","title":"Creating a tutorial directory and table\u00b6","text":"<p>In Pixeltable, all data resides in tables, which themselves can be organized into a directory structure.</p> <p>Let's start by creating a client and a <code>video_tutorial</code> directory:</p>"},{"location":"tutorials/object-detection-in-videos/#object-detection-as-a-user-defined-function","title":"Object Detection as a user-defined function\u00b6","text":"<p>User-defined functions let you customize Pixeltable's functionality for your own data.</p> <p>In this example, we're going use a <code>torchvision</code> object detection model (Faster R-CNN):</p>"},{"location":"tutorials/openai_demo/","title":"Using the OpenAI API with Pixeltable","text":"<p>PixelTable helps users unify data and computation into a table interface. This notebook shows how we can use the OpenAI API via pixeltable. We will keep all artifacts within the <code>demos</code> directory.</p> In\u00a0[1]: Copied! <pre>import pixeltable as pxt\ncl = pxt.Client()\ncl.create_dir('demos', ignore_errors=True)\npath = 'demos.chat_completions_demo'\n</pre> import pixeltable as pxt cl = pxt.Client() cl.create_dir('demos', ignore_errors=True) path = 'demos.chat_completions_demo' <pre>2024-01-29 14:50:16,598 INFO pixeltable env.py:188: found database postgresql://postgres:@/pixeltable?host=/run/user/1000/python_PostgresServer/8fd7da6a31\n2024-01-29 14:50:16,692 INFO pixeltable env.py:199: connecting to NOS\n</pre> <pre>/home/marcel/pixeltable/pixeltable/exec/expr_eval_node.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n</pre> <pre>2024-01-29 14:50:16.714 | INFO     | nos.server:init:131 - Inference server already running (name=nos-inference-service-gpu, image=&lt;Image: 'autonomi/nos:0.0.9-gpu'&gt;, id=d4255c36b739).\n2024-01-29 14:50:16,715 INFO pixeltable env.py:202: waiting for NOS\n2024-01-29 14:50:16,727 INFO pixeltable env.py:223: connecting to OpenAI\n</pre> In\u00a0[2]: Copied! <pre>if path in cl.list_tables():\n    cl.drop_table(path)\n\nt = cl.create_table(path, {'id': pxt.IntType(), 'input': pxt.StringType()})\n</pre> if path in cl.list_tables():     cl.drop_table(path)  t = cl.create_table(path, {'id': pxt.IntType(), 'input': pxt.StringType()}) In\u00a0[3]: Copied! <pre># text from https://en.wikipedia.org/wiki/Global_financial_crisis_in_September_2008\nwikipedia_text = '''On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers.\nThe significance of the Lehman Brothers bankruptcy is disputed with some assigning it a pivotal role in the unfolding of subsequent events.\nThe principals involved, Ben Bernanke and Henry Paulson, dispute this view, citing a volume of toxic assets at Lehman which made a rescue impossible.[16][17] Immediately following the bankruptcy, JPMorgan Chase provided the broker dealer unit of Lehman Brothers with $138 billion to \"settle securities transactions with customers of Lehman and its clearance parties\" according to a statement made in a New York City Bankruptcy court filing.[18]\nThe same day, the sale of Merrill Lynch to Bank of America was announced.[19] The beginning of the week was marked by extreme instability in global stock markets, with dramatic drops in market values on Monday, September 15, and Wednesday, September 17.\nOn September 16, the large insurer American International Group (AIG), a significant participant in the credit default swaps markets, suffered a liquidity crisis following the downgrade of its credit rating.\nThe Federal Reserve, at AIG's request, and after AIG had shown that it could not find lenders willing to save it from insolvency, created a credit facility for up to US$85 billion in exchange for a 79.9% equity interest, and the right to suspend dividends to previously issued common and preferred stock.[20]'''\n\nsample_inputs = wikipedia_text.split('\\n')\n</pre> # text from https://en.wikipedia.org/wiki/Global_financial_crisis_in_September_2008 wikipedia_text = '''On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. The significance of the Lehman Brothers bankruptcy is disputed with some assigning it a pivotal role in the unfolding of subsequent events. The principals involved, Ben Bernanke and Henry Paulson, dispute this view, citing a volume of toxic assets at Lehman which made a rescue impossible.[16][17] Immediately following the bankruptcy, JPMorgan Chase provided the broker dealer unit of Lehman Brothers with $138 billion to \"settle securities transactions with customers of Lehman and its clearance parties\" according to a statement made in a New York City Bankruptcy court filing.[18] The same day, the sale of Merrill Lynch to Bank of America was announced.[19] The beginning of the week was marked by extreme instability in global stock markets, with dramatic drops in market values on Monday, September 15, and Wednesday, September 17. On September 16, the large insurer American International Group (AIG), a significant participant in the credit default swaps markets, suffered a liquidity crisis following the downgrade of its credit rating. The Federal Reserve, at AIG's request, and after AIG had shown that it could not find lenders willing to save it from insolvency, created a credit facility for up to US$85 billion in exchange for a 79.9% equity interest, and the right to suspend dividends to previously issued common and preferred stock.[20]'''  sample_inputs = wikipedia_text.split('\\n') In\u00a0[4]: Copied! <pre># example row inserted, persisted to table.\nt.insert([{'id': 0, 'input': sample_inputs[0]}])\nt.show()\n</pre> # example row inserted, persisted to table. t.insert([{'id': 0, 'input': sample_inputs[0]}]) t.show() <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>inserted 1 row with 0 errors \n</pre> Out[4]: id input 0 On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. In\u00a0[5]: Copied! <pre>prompt = \"For the following sentence, extract all company names from the text.\"\n\nmsgs = [\n    { \"role\": \"system\", \"content\": prompt },\n    { \"role\": \"user\", \"content\": t.input }\n]\n\nt.add_column(input_msgs=msgs)\n</pre> prompt = \"For the following sentence, extract all company names from the text.\"  msgs = [     { \"role\": \"system\", \"content\": prompt },     { \"role\": \"user\", \"content\": t.input } ]  t.add_column(input_msgs=msgs) <pre>Computing cells:   0%|          | 0/1 [00:00&lt;?, ?cells/s]</pre> <pre>added 1 column values with 0 errors\n</pre> Out[5]: <pre>UpdateStatus(num_rows=1, num_computed_values=1, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>Unlike the values of the<code>input</code> column, which users provide, the <code>t.input_msgs</code> column is computed automatically from the <code>t.input</code> column values:</p> In\u00a0[6]: Copied! <pre>t.show()\n</pre> t.show() Out[6]: id input input_msgs 0 On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. [{'role': 'system', 'content': 'For the following sentence, extract all company names from the text.'}, {'role': 'user', 'content': 'On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers.'}] <p>In Pixeltable, OpenAI API calls are exposed as Pixeltable functions, which can be used to create computed columns.</p> <p>For the following command to work, you must have set <code>os.environ['OPENAI_API_KEY']</code>.</p> In\u00a0[7]: Copied! <pre>from pixeltable.functions.openai import chat_completions\nt['chat_output'] = chat_completions(model='gpt-3.5-turbo', messages=t.input_msgs)\nt.show()\n</pre> from pixeltable.functions.openai import chat_completions t['chat_output'] = chat_completions(model='gpt-3.5-turbo', messages=t.input_msgs) t.show() <pre>Computing cells:   0%|          | 0/1 [00:00&lt;?, ?cells/s]</pre> <pre>added 1 column values with 0 errors\n</pre> Out[7]: id input input_msgs chat_output 0 On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. [{'role': 'system', 'content': 'For the following sentence, extract all company names from the text.'}, {'role': 'user', 'content': 'On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers.'}] {'id': 'chatcmpl-8mUkDEuZVPzk6k4veHCYEHSrpLvTM', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 65, 'prompt_tokens': 61, 'completion_tokens': 4}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Lehman Brothers', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568617, 'system_fingerprint': None} <p>The result objects of the OpenAI API calls are generally complex JSON structures, which require some navigation to extract the response. We can express this as JSON path expressions and create another computed column:</p> In\u00a0[8]: Copied! <pre>t['response'] = t.chat_output.choices[0].message.content\nt.show()\n</pre> t['response'] = t.chat_output.choices[0].message.content t.show() <pre>Computing cells:   0%|          | 0/1 [00:00&lt;?, ?cells/s]</pre> <pre>added 1 column values with 0 errors\n</pre> Out[8]: id input input_msgs chat_output response 0 On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. [{'role': 'system', 'content': 'For the following sentence, extract all company names from the text.'}, {'role': 'user', 'content': 'On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers.'}] {'id': 'chatcmpl-8mUkDEuZVPzk6k4veHCYEHSrpLvTM', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 65, 'prompt_tokens': 61, 'completion_tokens': 4}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Lehman Brothers', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568617, 'system_fingerprint': None} Lehman Brothers <p>Let's run a query to look only at the input and output:</p> In\u00a0[9]: Copied! <pre>t.select(t.input, t.response).show()\n</pre> t.select(t.input, t.response).show() Out[9]: input response On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. Lehman Brothers <p>Once we have defined these computed columns, much like with a spreadsheet, newly inserted <code>t.input</code> values trigger computation of all derived columns, such as <code>t.response</code>:</p> In\u00a0[10]: Copied! <pre>t.insert([{'id': i, 'input': sample_inputs[i]} for i in range(1, len(sample_inputs))])\n</pre> t.insert([{'id': i, 'input': sample_inputs[i]} for i in range(1, len(sample_inputs))]) <pre>Computing cells:   0%|          | 0/15 [00:00&lt;?, ?cells/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>inserted 5 rows with 0 errors \n</pre> Out[10]: <pre>UpdateStatus(num_rows=5, num_computed_values=15, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> In\u00a0[11]: Copied! <pre>t.select(t.input, t.response).show()\n</pre> t.select(t.input, t.response).show() Out[11]: input response On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. Lehman Brothers The significance of the Lehman Brothers bankruptcy is disputed with some assigning it a pivotal role in the unfolding of subsequent events. Lehman Brothers The principals involved, Ben Bernanke and Henry Paulson, dispute this view, citing a volume of toxic assets at Lehman which made a rescue impossible.[16][17] Immediately following the bankruptcy, JPMorgan Chase provided the broker dealer unit of Lehman Brothers with $138 billion to \"settle securities transactions with customers of Lehman and its clearance parties\" according to a statement made in a New York City Bankruptcy court filing.[18] Lehman Brothers, JPMorgan Chase The same day, the sale of Merrill Lynch to Bank of America was announced.[19] The beginning of the week was marked by extreme instability in global stock markets, with dramatic drops in market values on Monday, September 15, and Wednesday, September 17. Merrill Lynch, Bank of America On September 16, the large insurer American International Group (AIG), a significant participant in the credit default swaps markets, suffered a liquidity crisis following the downgrade of its credit rating. American International Group (AIG) The Federal Reserve, at AIG's request, and after AIG had shown that it could not find lenders willing to save it from insolvency, created a credit facility for up to US$85 billion in exchange for a 79.9% equity interest, and the right to suspend dividends to previously issued common and preferred stock.[20] AIG, Federal Reserve In\u00a0[12]: Copied! <pre>t['ground_truth'] = pxt.StringType(nullable=True)\n\nground_truth = [\n    'Lehman Brothers',\n    'Lehman Brothers',\n    'JP Morgan Chase, Lehman Brothers',\n    'Merill Lynch, Bank of America',\n    'American International Group',\n    'American International Group',\n]\n\nfor i, gt in enumerate(ground_truth):\n    t.update({'ground_truth': gt}, where=(t['id'] == i))\n</pre> t['ground_truth'] = pxt.StringType(nullable=True)  ground_truth = [     'Lehman Brothers',     'Lehman Brothers',     'JP Morgan Chase, Lehman Brothers',     'Merill Lynch, Bank of America',     'American International Group',     'American International Group', ]  for i, gt in enumerate(ground_truth):     t.update({'ground_truth': gt}, where=(t['id'] == i)) <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <pre>Inserting rows into table: 0rows [00:00, ?rows/s]</pre> <p>And this is what we have so far:</p> In\u00a0[13]: Copied! <pre>t.select(t.input, t.response, t.ground_truth).show()\n</pre> t.select(t.input, t.response, t.ground_truth).show() Out[13]: input response ground_truth On Sunday, September 14, it was announced that Lehman Brothers would file for bankruptcy after the Federal Reserve Bank declined to participate in creating a financial support facility for Lehman Brothers. Lehman Brothers Lehman Brothers The significance of the Lehman Brothers bankruptcy is disputed with some assigning it a pivotal role in the unfolding of subsequent events. Lehman Brothers Lehman Brothers The principals involved, Ben Bernanke and Henry Paulson, dispute this view, citing a volume of toxic assets at Lehman which made a rescue impossible.[16][17] Immediately following the bankruptcy, JPMorgan Chase provided the broker dealer unit of Lehman Brothers with $138 billion to \"settle securities transactions with customers of Lehman and its clearance parties\" according to a statement made in a New York City Bankruptcy court filing.[18] Lehman Brothers, JPMorgan Chase JP Morgan Chase, Lehman Brothers The same day, the sale of Merrill Lynch to Bank of America was announced.[19] The beginning of the week was marked by extreme instability in global stock markets, with dramatic drops in market values on Monday, September 15, and Wednesday, September 17. Merrill Lynch, Bank of America Merill Lynch, Bank of America On September 16, the large insurer American International Group (AIG), a significant participant in the credit default swaps markets, suffered a liquidity crisis following the downgrade of its credit rating. American International Group (AIG) American International Group The Federal Reserve, at AIG's request, and after AIG had shown that it could not find lenders willing to save it from insolvency, created a credit facility for up to US$85 billion in exchange for a 79.9% equity interest, and the right to suspend dividends to previously issued common and preferred stock.[20] AIG, Federal Reserve American International Group In\u00a0[14]: Copied! <pre>eval_prompt = '''\nCompare the following listA and listB of entities, check if they contains the same entities.\nReturn a json object with the following format:\n{\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise}\n'''\n\nt.add_column(\n    eval_prompt=[\n        { \"role\": \"system\", \"content\": eval_prompt },\n        {\n            \"role\": \"user\",\n            \"content\": pxt.functions.str_format(\n                'listA: \"{0}\" \\n listB: \"{1}\"', t.response, t.ground_truth)\n        }])\n</pre> eval_prompt = ''' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '''  t.add_column(     eval_prompt=[         { \"role\": \"system\", \"content\": eval_prompt },         {             \"role\": \"user\",             \"content\": pxt.functions.str_format(                 'listA: \"{0}\" \\n listB: \"{1}\"', t.response, t.ground_truth)         }]) <pre>Computing cells:   0%|          | 0/6 [00:00&lt;?, ?cells/s]</pre> <pre>added 6 column values with 0 errors\n</pre> Out[14]: <pre>UpdateStatus(num_rows=6, num_computed_values=6, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>The function <code>str_format()</code> is similar to an f-string, but allows values to come from any table column.</p> In\u00a0[15]: Copied! <pre>t.select(t.eval_prompt).show()\n</pre> t.select(t.eval_prompt).show() Out[15]: eval_prompt [{'role': 'system', 'content': ' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '}, {'role': 'user', 'content': 'listA: \"Lehman Brothers\"   listB: \"Lehman Brothers\"'}] [{'role': 'system', 'content': ' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '}, {'role': 'user', 'content': 'listA: \"Lehman Brothers\"   listB: \"Lehman Brothers\"'}] [{'role': 'system', 'content': ' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '}, {'role': 'user', 'content': 'listA: \"Lehman Brothers, JPMorgan Chase\"   listB: \"JP Morgan Chase, Lehman Brothers\"'}] [{'role': 'system', 'content': ' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '}, {'role': 'user', 'content': 'listA: \"Merrill Lynch, Bank of America\"   listB: \"Merill Lynch, Bank of America\"'}] [{'role': 'system', 'content': ' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '}, {'role': 'user', 'content': 'listA: \"American International Group (AIG)\"   listB: \"American International Group\"'}] [{'role': 'system', 'content': ' Compare the following listA and listB of entities, check if they contains the same entities. Return a json object with the following format: {\"reasoning\": explaining your reasoning, \"decision\": 1 if the lists matched, 0 otherwise} '}, {'role': 'user', 'content': 'listA: \"AIG, Federal Reserve\"   listB: \"American International Group\"'}] <p>The actual evaluation happens in another computed column:</p> In\u00a0[16]: Copied! <pre>t['eval'] = chat_completions(model='gpt-3.5-turbo', messages=t.eval_prompt)\nt['eval_output'] = t.eval.choices[0].message.content\n</pre> t['eval'] = chat_completions(model='gpt-3.5-turbo', messages=t.eval_prompt) t['eval_output'] = t.eval.choices[0].message.content <pre>Computing cells:   0%|          | 0/6 [00:00&lt;?, ?cells/s]</pre> <pre>added 6 column values with 0 errors\n</pre> <pre>Computing cells:   0%|          | 0/6 [00:00&lt;?, ?cells/s]</pre> <pre>added 6 column values with 0 errors\n</pre> <p>Let's take a look:</p> In\u00a0[17]: Copied! <pre>t.select(t.eval, t.eval_output).show()\n</pre> t.select(t.eval, t.eval_output).show() Out[17]: eval eval_output {'id': 'chatcmpl-8mUkH5nobeETZqebvgcqY0X8N5CiX', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 111, 'prompt_tokens': 81, 'completion_tokens': 30}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"reasoning\": \"The entities in listA and listB are the same: \\'Lehman Brothers\\'.\", \"decision\": 1}', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568621, 'system_fingerprint': None} {\"reasoning\": \"The entities in listA and listB are the same: 'Lehman Brothers'.\", \"decision\": 1} {'id': 'chatcmpl-8mUkJkp2BuXPxOHLCFeqMLU8R5WCL', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 108, 'prompt_tokens': 81, 'completion_tokens': 27}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"reasoning\": \"The reasoning is that both lists have the same entity \\'Lehman Brothers\\'\", \"decision\": 1}', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568623, 'system_fingerprint': None} {\"reasoning\": \"The reasoning is that both lists have the same entity 'Lehman Brothers'\", \"decision\": 1} {'id': 'chatcmpl-8mUkLgv9bFjgw9fOqOkjTxtelPzVX', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 128, 'prompt_tokens': 89, 'completion_tokens': 39}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"reasoning\": \"The order of the entities in the lists does not matter. Therefore, we can simply compare the entities in the lists without considering their order.\", \"decision\": 1}', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568625, 'system_fingerprint': None} {\"reasoning\": \"The order of the entities in the lists does not matter. Therefore, we can simply compare the entities in the lists without considering their order.\", \"decision\": 1} {'id': 'chatcmpl-8mUkM8A1x7oBowCe9svTy06CnB9iP', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 175, 'prompt_tokens': 88, 'completion_tokens': 87}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"reasoning\": \"Based on the given lists, both listA and listB contain the same entities, which are \\'Merrill Lynch\\' and \\'Bank of America\\'. The only difference is a minor spelling mistake in listB where \\'Merrill\\' is misspelled as \\'Merill\\'. Since the entities are the same despite the spelling difference, the lists can be considered as matched.\", \"decision\": 1}', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568626, 'system_fingerprint': None} {\"reasoning\": \"Based on the given lists, both listA and listB contain the same entities, which are 'Merrill Lynch' and 'Bank of America'. The only difference is a minor spelling mistake in listB where 'Merrill' is misspelled as 'Merill'. Since the entities are the same despite the spelling difference, the lists can be considered as matched.\", \"decision\": 1} {'id': 'chatcmpl-8mUkQgLIAZBHMFQuCNwyyWbg3A4nb', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 144, 'prompt_tokens': 82, 'completion_tokens': 62}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"reasoning\": \"The two lists contain the same entity, \\'American International Group\\'. The only difference is that listA includes the abbreviation \\'AIG\\' while listB does not. However, since the core entity is the same, we can consider them as a match.\", \"decision\": 1}', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568630, 'system_fingerprint': None} {\"reasoning\": \"The two lists contain the same entity, 'American International Group'. The only difference is that listA includes the abbreviation 'AIG' while listB does not. However, since the core entity is the same, we can consider them as a match.\", \"decision\": 1} {'id': 'chatcmpl-8mUkTHsy42wGDVXB5xcdq3z4fd5Mk', 'model': 'gpt-3.5-turbo-0613', 'usage': {'total_tokens': 129, 'prompt_tokens': 81, 'completion_tokens': 48}, 'object': 'chat.completion', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"reasoning\": \"The entities in listA are AIG and Federal Reserve. The entity in listB is American International Group. Since American International Group is the same as AIG, the lists match.\", \"decision\": 1}', 'tool_calls': None, 'function_call': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1706568633, 'system_fingerprint': None} {\"reasoning\": \"The entities in listA are AIG and Federal Reserve. The entity in listB is American International Group. Since American International Group is the same as AIG, the lists match.\", \"decision\": 1} In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/openai_demo/#using-the-openai-api-with-pixeltable","title":"Using the OpenAI API with Pixeltable\u00b6","text":""},{"location":"tutorials/openai_demo/#creating-a-table-with-inputs","title":"Creating a table with inputs\u00b6","text":""},{"location":"tutorials/openai_demo/#making-openai-api-calls","title":"Making OpenAI API calls\u00b6","text":"<p>Calling OpenAI API endpoints involves constructing a message object, which we express in Pixeltable by adding a new computed column,i.e., a column that represents a computation.</p>"},{"location":"tutorials/openai_demo/#adding-ground-truth-data","title":"Adding ground truth data\u00b6","text":"<p>Computed table columns are stored and persisted, avoiding repeated computation. Pixeltable can be used to conduct experiments, for example to compare prompt variations:</p> <p>We'll start by creating our ground-truth data manually:</p>"},{"location":"tutorials/openai_demo/#evaluation","title":"Evaluation\u00b6","text":"<p>Now that we have some ground truth available, we can carry out basic evaluations of the GPT outputs, in this case by asking ChatGPT to decide whether the two are equivalent.</p> <p>To start with, we'll create an evaluation prompt:</p>"},{"location":"tutorials/pixeltable-basics/","title":"Pixeltable Basics","text":"In\u00a0[\u00a0]: Copied! <pre>%pip install pixeltable torch transformers openai\n</pre> %pip install pixeltable torch transformers openai In\u00a0[2]: Copied! <pre>import pixeltable as pxt\ncl = pxt.Client()\n</pre> import pixeltable as pxt cl = pxt.Client() <pre>Connected to Pixeltable database at: postgresql://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\n</pre> <p>Next we create a namespace (if it doesn't already exist) along with our new table, <code>demo.first</code>. The table will initially have just a single column to hold our input images, which we'll call <code>input_image</code>. We also need to specify a type for the column: <code>pxt.ImageType()</code>.</p> In\u00a0[3]: Copied! <pre># Create the namespace `demo` (if it doesn't already exist)\ncl.create_dir('demo', ignore_errors=True)\n\n# Create the table `demo.first` with a single column `input_image`\nt = cl.create_table('demo.first', {'input_image': pxt.ImageType()})\n</pre> # Create the namespace `demo` (if it doesn't already exist) cl.create_dir('demo', ignore_errors=True)  # Create the table `demo.first` with a single column `input_image` t = cl.create_table('demo.first', {'input_image': pxt.ImageType()}) <pre>Created directory `demo`.\nCreated table `first`.\n</pre> <p>We can use <code>t.describe()</code> to examine the table schema. We see that it now contains a single column, as expected:</p> In\u00a0[4]: Copied! <pre>t.describe()\n</pre> t.describe() Column Name Type Computed With input_image image <p>The new table is initially empty, with no rows:</p> In\u00a0[5]: Copied! <pre>t.count()\n</pre> t.count() Out[5]: <pre>0</pre> <p>Now let's put an image into it! We can add images simply by giving Pixeltable their URLs. The example images in this demo come from the COCO dataset, and we'll be referencing copies of them in the Pixeltable github repo. But in practice, the images can come from anywhere: an S3 bucket, say, or the local file system.</p> <p>When we add the image, we see that Pixeltable gives us some useful status updates indicating that the operation was successful.</p> In\u00a0[6]: Copied! <pre>t.insert(input_image='https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000009.jpg')\n</pre> t.insert(input_image='https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000009.jpg') <pre>Inserting rows into `first`: 1 rows [00:00, 144.95 rows/s]\nInserted 1 row with 0 errors.\n</pre> Out[6]: <pre>UpdateStatus(num_rows=1, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>We can use <code>t.show()</code> to examine the contents of the table.</p> In\u00a0[7]: Copied! <pre>t.show()\n</pre> t.show() Out[7]: input_image In\u00a0[8]: Copied! <pre>from pixeltable.functions import huggingface\nt['detect'] = huggingface.detr_for_object_detection(t.input_image, model_id='facebook/detr-resnet-50')\n</pre> from pixeltable.functions import huggingface t['detect'] = huggingface.detr_for_object_detection(t.input_image, model_id='facebook/detr-resnet-50') <pre>Added column `detect` to table `first`.\nComputing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:05&lt;00:00,  5.48s/ cells]\nAdded 1 column value with 0 errors.\n</pre> <p>Let's examine the results.</p> In\u00a0[9]: Copied! <pre>t.show()\n</pre> t.show() Out[9]: input_image detect {'boxes': [[0.5802387595176697, 0.08485905826091766, 0.7063707709312439, 0.18905319273471832], [0.7233275175094604, 0.08670079708099365, 0.8174974918365479, 0.18644198775291443], [0.0006367266178131104, 0.027185142040252686, 0.6707271337509155, 0.8104317784309387], [-1.1205673217773438e-05, 0.39773815870285034, 0.9554940462112427, 0.9870153069496155], [0.5725255608558655, 0.0005173087120056152, 0.7135650515556335, 0.14135970175266266], [0.40589094161987305, 0.48307526111602783, 0.8861547708511353, 0.9869147539138794], [0.6049936413764954, 0.14735108613967896, 0.7330133318901062, 0.2990023195743561], [0.48979803919792175, 0.0009566247463226318, 0.9874167442321777, 0.5126445293426514]], 'labels': [55, 55, 51, 51, 55, 56, 55, 51], 'scores': [0.9640840291976929, 0.9740563035011292, 0.9654219150543213, 0.9887107014656067, 0.9860836863517761, 0.9976664781570435, 0.9637528657913208, 0.9985143542289734], 'label_text': ['orange', 'orange', 'bowl', 'bowl', 'orange', 'broccoli', 'orange', 'bowl']} <p>We see that the model returned a JSON struct containing a lot of information. In particular, it has the following fields:</p> <ul> <li><code>label_text</code>: Descriptions of the objects detected</li> <li><code>boxes</code>: Bounding boxes for each detected object</li> <li><code>scores</code>: Confidence scores for each detection</li> <li><code>labels</code>: The DETR model's internal IDs for the detected objects</li> </ul> <p>Perhaps this is more than we need, and all we really want are the text labels. We could add another computed column to extract <code>label_text</code> from the JSON struct:</p> In\u00a0[10]: Copied! <pre>t['detect_text'] = t.detect.label_text\nt.show()\n</pre> t['detect_text'] = t.detect.label_text t.show() <pre>Added column `detect_text` to table `first`.\nComputing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 246.25 cells/s]\nAdded 1 column value with 0 errors.\n</pre> Out[10]: input_image detect detect_text {'boxes': [[0.5802387595176697, 0.08485905826091766, 0.7063707709312439, 0.18905319273471832], [0.7233275175094604, 0.08670079708099365, 0.8174974918365479, 0.18644198775291443], [0.0006367266178131104, 0.027185142040252686, 0.6707271337509155, 0.8104317784309387], [-1.1205673217773438e-05, 0.39773815870285034, 0.9554940462112427, 0.9870153069496155], [0.5725255608558655, 0.0005173087120056152, 0.7135650515556335, 0.14135970175266266], [0.40589094161987305, 0.48307526111602783, 0.8861547708511353, 0.9869147539138794], [0.6049936413764954, 0.14735108613967896, 0.7330133318901062, 0.2990023195743561], [0.48979803919792175, 0.0009566247463226318, 0.9874167442321777, 0.5126445293426514]], 'labels': [55, 55, 51, 51, 55, 56, 55, 51], 'scores': [0.9640840291976929, 0.9740563035011292, 0.9654219150543213, 0.9887107014656067, 0.9860836863517761, 0.9976664781570435, 0.9637528657913208, 0.9985143542289734], 'label_text': ['orange', 'orange', 'bowl', 'bowl', 'orange', 'broccoli', 'orange', 'bowl']} [orange, orange, bowl, bowl, orange, broccoli, orange, bowl] <p>If we inspect the table schema now, we see how Pixeltable distinguishes between ordinary and computed columns.</p> In\u00a0[11]: Copied! <pre>t.describe()\n</pre> t.describe() Column Name Type Computed With input_image image detect json huggingface.detr_for_object_detection(input_image, model_id='facebook/detr-resnet-50') detect_text json detect.label_text <p>Now let's add some more images to our table. This demonstrates another important feature of computed columns: by default, they update incrementally any time new data becomes available upstream. In this case, Pixeltable will run the ResNet-50 model against each new image that is added, then extract the labels into the <code>detect_text</code> column. Pixeltable will orchestrate the execution of any sequence (or DAG) of computed columns.</p> <p>Note how we can pass multiple rows to <code>t.insert</code> with a single statement, which will insert them more efficiently.</p> In\u00a0[12]: Copied! <pre>more_images = [\n    'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000025.jpg',\n    'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000030.jpg',\n    'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000034.jpg',\n    'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000042.jpg',\n    'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000061.jpg'\n]\nt.insert({'input_image': image} for image in more_images)\n</pre> more_images = [     'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000025.jpg',     'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000030.jpg',     'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000034.jpg',     'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000042.jpg',     'https://raw.github.com/pixeltable/pixeltable/master/docs/source/data/images/000000000061.jpg' ] t.insert({'input_image': image} for image in more_images) <pre>Computing cells:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 5/10 [00:10&lt;00:10,  2.07s/ cells]\nInserting rows into `first`: 5 rows [00:00, 1580.73 rows/s]\nComputing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&lt;00:00,  1.04s/ cells]\nInserted 5 rows with 0 errors.\n</pre> Out[12]: <pre>UpdateStatus(num_rows=5, num_computed_values=10, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>Let's see what the model came up with. We'll use <code>t.select</code> to suppress the display of the <code>detect</code> column, since right now we're only interested in the text labels.</p> In\u00a0[13]: Copied! <pre>t.select(t.input_image, t.detect_text).show()\n</pre> t.select(t.input_image, t.detect_text).show() Out[13]: input_image detect_text [orange, orange, bowl, bowl, orange, broccoli, orange, bowl] [giraffe, giraffe] [vase, potted plant] [zebra] [dog, dog] [person, person, bench, person, elephant, elephant, person] In\u00a0[14]: Copied! <pre># Clear all variables in the notebook\n%reset -f\n\n# Instantiate a new client object\nimport pixeltable as pxt\ncl = pxt.Client()\nt = cl.get_table('demo.first')\n\n# Display just the first two rows, to avoid cluttering the tutorial\nt.select(t.input_image, t.detect_text).show(2)\n</pre> # Clear all variables in the notebook %reset -f  # Instantiate a new client object import pixeltable as pxt cl = pxt.Client() t = cl.get_table('demo.first')  # Display just the first two rows, to avoid cluttering the tutorial t.select(t.input_image, t.detect_text).show(2) Out[14]: input_image detect_text [orange, orange, bowl, bowl, orange, broccoli, orange, bowl] [giraffe, giraffe] In\u00a0[\u00a0]: Copied! <pre>os.environ['OPENAI_API_KEY'] = my_api_key\n</pre> os.environ['OPENAI_API_KEY'] = my_api_key <p>Now we can connect to OpenAI through Pixeltable.</p> In\u00a0[2]: Copied! <pre>from pixeltable.functions import openai\nt['vision'] = openai.vision(prompt=\"Describe what's in this image.\", image=t.input_image)\n</pre> from pixeltable.functions import openai t['vision'] = openai.vision(prompt=\"Describe what's in this image.\", image=t.input_image) <pre>Computing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [01:08&lt;00:00, 11.46s/ cells]\nAdded 6 column values with 0 errors.\n</pre> <p>Let's see how GPT-4's responses compare to the traditional discriminative (DETR) model.</p> In\u00a0[3]: Copied! <pre>t.select(t.input_image, t.detect_text, t.vision).show()\n</pre> t.select(t.input_image, t.detect_text, t.vision).show() Out[3]: input_image detect_text vision [giraffe, giraffe] The image features two giraffes in what appears to be a natural habitat enclosure, likely in a zoo or wildlife park. The closest giraffe is standing upright and seems to be either feeding on leaves from a tree or possibly using its long neck to reach for something higher up. The distinct pattern of spots and the elongated neck immediately identify these animals as giraffes. In the background, trees and foliage suggesting a well-vegetated area can be seen, creating a serene environment. There's no visible fencing immediately around the giraffes, which gives the scene a more natural look, although safety measures are likely in place but not captured in the photo. [orange, orange, bowl, bowl, orange, broccoli, orange, bowl] The image depicts a colorful segmented lunch container filled with an assortment of foods. \\n\\nTop left compartment: It has a section with what looks like a piece of bread with butter on it and some almonds. \\n\\nTop right compartment: This section contains what appears to be canned or fresh pineapple chunks.\\n\\nBottom left compartment: This portion of the lunch box seems to contain some form of meatball or veggie ball alongside what could be a serving of condiment or dip, likely tomato-based given its color. \\n\\nBottom right compartment: There's a portion of steamed or blanched green vegetable, which looks like broccoli.\\n\\nForeground/bottom of the image: It features what seem to be chocolate chip cookies, suggesting a dessert option included in the meal.\\n\\nOverall, the lunch box seems to offer a balanced meal with components from various food groups, suggesting an emphasis on nutrition. The vibrant colors of the containers add a playful and inviting touch to the presentation of the food. [vase, potted plant] This is an image of a bouquet of flowers arranged in a white, decorative vase. The vase is placed on a white surface, which appears to be a ledge or railing, given the cast shadows suggesting outdoor lighting. The flowers within the vase are a mix of colors, primarily white with some deep pink or red accents, and there are a variety of blooms and foliage types contributing to the overall arrangement. The background of the image is out of focus, but it shows a bright, sunny day with greenery that hints at a garden or lawn setting. [zebra] In the image, there is a zebra grazing on grass. The zebra is depicted from a side angle, allowing for a clear view of its distinctive black-and-white striped pattern, which covers its body, legs, and head. The mane stands erect along the neck, and the animal is shown in a green field under bright sunlight, which casts shadows on the ground. The zebra appears to be in a peaceful setting, perhaps in a natural reserve or a wildlife park. [dog, dog] This image shows a small tan or light brown curly-furred dog sleeping or resting on a wire shoe rack. The dog appears to be very comfortable nestled among various shoes, including sandals, sneakers, and possibly a garden shoe. The presence of a sports racket cover with the label \"Rucanor\" indicates that someone in the household may play racket sports. The shoe rack is situated in a space with a terracotta tiled floor, suggesting an indoor location, such as a mudroom, garage, or entryway to a home. The blue item in the top right corner is not fully visible, so it's difficult to identify what it is; it could be a piece of equipment or decoration. Overall, the scene depicts a cozy and somewhat amusing moment with the dog finding an unconventional spot to relax among the footwear. [person, person, bench, person, elephant, elephant, person] In the image, there are two elephants with riders on their backs. The elephants are adorned with what appears to be riding gear, including seats for the riders. They are walking through a dense jungle environment, with thick green foliage surrounding them. The setting is lush and verdant, suggesting a tropical or subtropical climate. It looks like a scene commonly associated with elephant trekking or safari experiences offered in certain regions where elephants are part of the local fauna and tourism activities. <p>In addition to adapters for local models and inference APIs, Pixeltable can of course do a range of more basic image operations. These image operations can be seamlessly chained with API calls, and Pixeltable will keep track of the sequence of operations, constructing new images and caching when necessary to keep things running smoothly. Just for fun (and to demonstrate the power of computed columns), let's see what OpenAI thinks of our sample images when we rotate them by 180 degrees.</p> In\u00a0[4]: Copied! <pre>t['rot_image'] = t.input_image.rotate(180)\nt['rot_vision'] = openai.vision(prompt=\"Describe what's in this image.\", image=t.rot_image)\n</pre> t['rot_image'] = t.input_image.rotate(180) t['rot_vision'] = openai.vision(prompt=\"Describe what's in this image.\", image=t.rot_image) <pre>Computing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [01:04&lt;00:00, 10.71s/ cells]\nAdded 6 column values with 0 errors.\n</pre> In\u00a0[5]: Copied! <pre>t.select(t.rot_image, t.rot_vision).show()\n</pre> t.select(t.rot_image, t.rot_vision).show() Out[5]: rot_image rot_vision This image appears to be rotated upside down. It shows a giraffe reaching down, likely to feed on some vegetation. You can see the distinctive brown and white patterned coat of the giraffe, its long neck, and the surrounding environment which includes trees and shrubs. The viewpoint makes it seem as though the giraffe is defying gravity, but in reality, the image is just flipped, which creates a playful perspective. The image shows a colorful meal arranged in a sectional container. Each section is a different vibrant color, making it visually appealing, particularly for a child or someone who enjoys playful presentations.\\n\\nIn the top section, which is yellow, there appears to be some curly, dark green leafy vegetables, which could be kale or a similar type of greens. Next to them, there are two brown baked items that could be some sort of muffin or meatless patties.\\n\\nThe middle section, which is pink, contains a handful of almonds, and adjacent to that appears to be some dried fruit, possibly apple chips, considering their shape and color.\\n\\nIn the bottom section, which is a purplish pink, there are some chunks of fresh fruit, likely pineapple, and some white bread with a spread that could be butter or margarine.\\n\\nOverall, the arrangement looks like a balanced meal with a focus on plant-based foods, suitable for a packed lunch or a snack box with diverse tastes and textures. This image features a bouquet of flowers hanging upside down from what appears to be the underside of a white ledge or shelf. The bouquet includes a variety of flowers in different colors\u2014including white and pink\u2014 intermixed with some greenery. The background is diffused with natural light, likely depicting an outdoor setting, with more greenery and what might be a tree seen blurred in the distance. This upside-down hanging of flowers could be a part of a decorative arrangement or a method for drying flowers. The image shows a zebra lying on its back on a grassy ground. The zebra's legs are in the air and its head is turned to one side, looking towards the camera. The zebra's distinctive black and white striped pattern is clearly visible against the green background of the grass. It appears to be a sunny day, and the zebra seems relaxed in this unusual, playful, or resting position. This image shows a small part of a dog's body, likely the head or neck area, peeking through a white wire rack or shelving unit. The dog appears to have curly fur, possibly indicating that it's a poodle or a poodle mix. On the wire rack above the dog, there are various pairs of shoes, including what appears to be sneakers, sandals, and flip-flops. One of the flip-flops has a red strap with cartoon decorations on it. The background suggests an indoor setting with a tiled floor. The image shows an upside-down view of a dense forest area. There's lush green foliage throughout, and it appears to be a tropical or subtropical environment given the density and type of vegetation. The foliage is thick enough that the forest floor or sky is not visible. In the middle of the image, there is a clearing where a part of a vehicle is showing through the greenery. The upside-down presentation of the image gives it an unusual and disorienting effect. In\u00a0[6]: Copied! <pre>@pxt.udf\ndef detect_top(detect: dict) -&gt; str:\n    scores = detect['scores']\n    label_text = detect['label_text']\n    # Get the index of the object with the highest confidence\n    i = scores.index(max(scores))\n    # Return the corresponding label\n    return label_text[i]\n</pre> @pxt.udf def detect_top(detect: dict) -&gt; str:     scores = detect['scores']     label_text = detect['label_text']     # Get the index of the object with the highest confidence     i = scores.index(max(scores))     # Return the corresponding label     return label_text[i] In\u00a0[7]: Copied! <pre>t['top'] = detect_top(t.detect)\n</pre> t['top'] = detect_top(t.detect) <pre>Computing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 680.27 cells/s]\nAdded 6 column values with 0 errors.\n</pre> In\u00a0[8]: Copied! <pre>t.select(t.detect_text, t.top).show()\n</pre> t.select(t.detect_text, t.top).show() Out[8]: detect_text top [orange, orange, bowl, bowl, orange, broccoli, orange, bowl] bowl [vase, potted plant] vase [zebra] zebra [giraffe, giraffe] giraffe [dog, dog] dog [person, person, bench, person, elephant, elephant, person] elephant <p>Congratulations! You've reached the end of the tutorial. Hopefully, this gives a good overview of the capabilities of Pixeltable, but there's much more to explore. As a next step, you might check out one of the other tutorials, depending on your interests:</p> <ul> <li>Image Operations in Pixeltable</li> <li>RAG Operations in Pixeltable</li> <li>Object Detection in Videos</li> </ul>"},{"location":"tutorials/pixeltable-basics/#pixeltable-basics","title":"Pixeltable Basics\u00b6","text":"<p>Welcome to Pixeltable! In this tutorial, we'll survey how to create tables, populate them with data, and enhance them with built-in and user-defined transformations and AI operations.</p>"},{"location":"tutorials/pixeltable-basics/#install-python-packages","title":"Install Python Packages\u00b6","text":"<p>First run the following command to install Pixeltable and related libraries needed for this tutorial.</p>"},{"location":"tutorials/pixeltable-basics/#creating-a-table","title":"Creating a Table\u00b6","text":"<p>In this tutorial, we'll create a table with some sample images and apply various operations to them. The first thing to do is to instantiate a Pixeltable client.</p>"},{"location":"tutorials/pixeltable-basics/#adding-computed-columns","title":"Adding Computed Columns\u00b6","text":"<p>Great! Now we have a table containing some data. Let's add an object detection model to our workflow. Specifically, we're going to use the ResNet-50 object detection model, which runs using the Huggingface DETR (\"DEtection TRansformer\") model class. Pixeltable contains a built-in adapter for this model family, so all we have to do is call the <code>detr_for_object_detection</code> Pixeltable function. A nice thing about the Huggingface models is that they run locally, so you don't need an account with a service provider in order to use them.</p> <p>This is our first example of a computed column, a key concept in Pixeltable. Recall that when we created the <code>input_image</code> column, we specified a type, <code>ImageType</code>, indicating our intent to populate it with data in the future. When we create a computed column, we instead specify a function that operates on other columns of the table. By default, when we add the new computed column, Pixeltable immediately evaluates it against all existing data in the table - in this case, by calling the <code>detr_for_object_detection</code> function on the image.</p> <p>Depending on your setup, it may take a minute for the function to execute. In the background, Pixeltable is downloading the model from Huggingface (if necessary), instantiating it, and caching it for later use.</p>"},{"location":"tutorials/pixeltable-basics/#pixeltable-is-persistent","title":"Pixeltable Is Persistent\u00b6","text":"<p>An important feature of Pixeltable is that everything is persistent. Unlike in-memory Python libraries such as Pandas, Pixeltable is a database: all your data, transformations, and computed columns are stored and preserved between sessions. To see this, let's clear all the variables in our notebook and start fresh with a new client.</p>"},{"location":"tutorials/pixeltable-basics/#gpt-4-vision","title":"GPT-4 Vision\u00b6","text":"<p>For comparison, let's try running our examples through a generative model, Open AI's GPT-4 Vision. For this section, you'll need an OpenAI account with an API key. You can use the following command to add your API key to the environment (replace the string <code>my_api_key</code> with your API key).</p>"},{"location":"tutorials/pixeltable-basics/#udfs-enhancing-pixeltables-capabilities","title":"UDFs: Enhancing Pixeltable's Capabilities\u00b6","text":"<p>Another important principle of Pixeltable is that, although Pixeltable has a built-in library of useful operations and adapters, it will never prescribe a particular way of doing things. Pixeltable is built from the ground up to be extensible.</p> <p>Let's take a specific example. Recall our use of the ResNet-50 detection model, in which the <code>detect</code> column contains a JSON blob with bounding boxes, scores, and labels. Suppose we want to create a column containing the single label with the highest confidence score. There's no built-in Pixeltable function to do this, but it's easy to write our own. In fact, all we have to do is write a Python function that does the thing we want, and stamp it with the <code>@pxt.udf</code> decorator.</p>"},{"location":"tutorials/rag-demo/","title":"RAG Operations in Pixeltable","text":"In\u00a0[1]: Copied! <pre>import pixeltable as pxt\ncl = pxt.Client()\n</pre> import pixeltable as pxt cl = pxt.Client() <pre>2024-03-21 21:58:16,331 INFO pixeltable env.py:210: creating database at postgresql://postgres:@/pixeltable?host=/Users/asiegel/.pixeltable/pgdata\n</pre> <p>The next few commands create a Pixeltable workspace <code>rag_demo</code> (if it doesn't already exist) and set up the table structure for our new workflow.</p> In\u00a0[2]: Copied! <pre># Create the Pixeltable workspace\ncl.create_dir('rag_demo', ignore_errors=True)\n\n# Clean the database to ensure we're using fresh table instances\n# (in case this demo has been run before)\ncl.drop_table('rag_demo.short_char_chunks', ignore_errors=True)\ncl.drop_table('rag_demo.short_chunks', ignore_errors=True)\ncl.drop_table('rag_demo.chunks', ignore_errors=True)\ncl.drop_table('rag_demo.sentences', ignore_errors=True)\ncl.drop_table('rag_demo.docs', ignore_errors=True)\n</pre> # Create the Pixeltable workspace cl.create_dir('rag_demo', ignore_errors=True)  # Clean the database to ensure we're using fresh table instances # (in case this demo has been run before) cl.drop_table('rag_demo.short_char_chunks', ignore_errors=True) cl.drop_table('rag_demo.short_chunks', ignore_errors=True) cl.drop_table('rag_demo.chunks', ignore_errors=True) cl.drop_table('rag_demo.sentences', ignore_errors=True) cl.drop_table('rag_demo.docs', ignore_errors=True) <pre>Created directory `rag_demo`.\n</pre> In\u00a0[3]: Copied! <pre>docs = cl.create_table('rag_demo.docs', {'source_doc': pxt.DocumentType()})\n</pre> docs = cl.create_table('rag_demo.docs', {'source_doc': pxt.DocumentType()}) <pre>Created table `docs`.\n</pre> <p>If we take a peek at the <code>docs</code> table, we see its very simple structure.</p> In\u00a0[4]: Copied! <pre>docs\n</pre> docs Out[4]: Column Name Type Computed With source_doc document <p>Next we create a view to represent chunks of our HTML documents. A Pixeltable view is a virtual table, which is dynamically derived from a source table by applying a transformation and/or selecting a subset of data. In this case, our view represents a one-to-many transformation from source documents into individual sentences. This is achieved using Pixeltable's built-in <code>DocumentSplitter</code> class.</p> <p>Note that the <code>docs</code> table is currently empty, so creating this view doesn't actually do anything yet: it simply defines an operation that we want Pixeltable to execute when it sees new data.</p> In\u00a0[4]: Copied! <pre>from pixeltable.iterators.document import DocumentSplitter\n\nsentences = cl.create_view(\n    'rag_demo.sentences',  # Name of the view\n    docs,  # Table from which the view is derived\n    iterator_class=DocumentSplitter,\n    iterator_args={\n        'document': docs.source_doc,\n        'separators': 'sentence',  # Chunk docs into sentences\n        'metadata': 'title,headings,sourceline',\n    })\n</pre> from pixeltable.iterators.document import DocumentSplitter  sentences = cl.create_view(     'rag_demo.sentences',  # Name of the view     docs,  # Table from which the view is derived     iterator_class=DocumentSplitter,     iterator_args={         'document': docs.source_doc,         'separators': 'sentence',  # Chunk docs into sentences         'metadata': 'title,headings,sourceline',     }) <pre>Created view `sentences` with 0 rows, 0 exceptions.\n</pre> <p>Let's take a peek at the new <code>sentences</code> view. Run the following command:</p> In\u00a0[5]: Copied! <pre>sentences\n</pre> sentences Out[5]: Column Name Type Computed With pos int text string title string headings json sourceline int source_doc document <p>We see that <code>sentences</code> inherits the <code>source_doc</code> column from <code>docs</code>, together with some new fields:</p> <ul> <li><code>pos</code>: The position in the source document where the sentence appears.</li> <li><code>text</code>: The text of the sentence.</li> <li><code>title</code>, <code>headings</code>, and <code>sourceline</code>: The metadata we requested when we set up the view.</li> </ul> <p>Ok, now it's time to insert some data into our workflow. A document in Pixeltable is just a URL; the following command inserts a single row into the <code>docs</code> table with the <code>source_doc</code> field set to the specified URL:</p> In\u00a0[6]: Copied! <pre>docs.insert(source_doc='https://en.wikipedia.org/wiki/Marc_Chagall')\n</pre> docs.insert(source_doc='https://en.wikipedia.org/wiki/Marc_Chagall') <pre>Inserting rows into `docs`: 1 rows [00:00, 182.72 rows/s]\nInserting rows into `sentences`: 1465 rows [00:00, 3008.51 rows/s]</pre> <pre>Inserted 1466 rows with 0 errors.\n</pre> <pre>\n</pre> Out[6]: <pre>UpdateStatus(num_rows=1466, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>We can see that two things happened. First, a single row was inserted into <code>docs</code>, containing the URL representing our source document. Then, the view <code>sentences</code> was incrementally updated by applying the <code>DocumentSplitter</code> according to the definition of the view. This illustrates an important principle in Pixeltable: by default, anytime Pixeltable sees new data, the update is incrementally propagated to any downstream views or computed columns.</p> <p>We can see the effect of the insertion with the <code>select</code> command. There's a single row in <code>docs</code>:</p> In\u00a0[7]: Copied! <pre>docs.select(docs.source_doc.fileurl).show()\n</pre> docs.select(docs.source_doc.fileurl).show() Out[7]: source_doc_fileurl https://en.wikipedia.org/wiki/Marc_Chagall <p>And here are the first 20 rows in <code>sentences</code>. The content of the article is broken into individual sentences, as expected.</p> In\u00a0[8]: Copied! <pre>sentences.select(sentences.text, sentences.headings).show(20)\n</pre> sentences.select(sentences.text, sentences.headings).show(20) Out[8]: text headings Marc Chagall - Wikipedia Jump to content Search Search {} Marc Chagall 81 languages Afrikaans Alemannisch \u0627\u0644\u0639\u0631\u0628\u064a\u0629 {'1': 'Marc Chagall'} Aragon\u00e9s \u0531\u0580\u0565\u0582\u0574\u057f\u0561\u0570\u0561\u0575\u0565\u0580\u0567\u0576 Asturianu Az\u0259rbaycanca \u09ac\u09be\u0982\u09b2\u09be \u0411\u0430\u0448\u04a1\u043e\u0440\u0442\u0441\u0430 \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f (\u0442\u0430\u0440\u0430\u0448\u043a\u0435\u0432\u0456\u0446\u0430) \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 Catal\u00e0 \u010ce\u0161tina Cymraeg Dansk Deutsch Eesti \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Espa\u00f1ol Esperanto Euskara \u0641\u0627\u0631\u0633\u06cc Fran\u00e7ais Galego \ud55c\uad6d\uc5b4 \u0540\u0561\u0575\u0565\u0580\u0565\u0576 \u0939\u093f\u0928\u094d\u0926\u0940 {'1': 'Marc Chagall'} Hrvatski Ido Bahasa Indonesia Interlingua Italiano \u05e2\u05d1\u05e8\u05d9\u05ea Jawa \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 Kiswahili Latina Latvie\u0161u L\u00ebtzebuergesch Lietuvi\u0173 Magyar \u041c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438 Malagasy \u0645\u0635\u0631\u0649 Nederlands Nedersaksies \u65e5\u672c\u8a9e Norsk bokm\u00e5l Norsk nynorsk Occitan O\u02bbzbekcha / \u045e\u0437\u0431\u0435\u043a\u0447\u0430 \u067e\u0646\u062c\u0627\u0628\u06cc Picard Piemont\u00e8is Plattd\u00fc\u00fctsch Polski Portugu\u00eas Rom\u00e2n\u0103 Runa Simi \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Scots Shqip Sicilianu Simple English Sloven\u010dina Sloven\u0161\u010dina \u06a9\u0648\u0631\u062f\u06cc \u0421\u0440\u043f\u0441\u043a\u0438 / srpski Srpskohrvatski / \u0441\u0440\u043f\u0441\u043a\u043e\u0445\u0440\u0432\u0430\u0442\u0441\u043a\u0438 Suomi Svenska \u0e44\u0e17\u0e22 {'1': 'Marc Chagall'} T\u00fcrk\u00e7e \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 Ti\u1ebfng Vi\u1ec7t Winaray \u5434\u8bed \u05d9\u05d9\u05b4\u05d3\u05d9\u05e9 {'1': 'Marc Chagall'} \u7cb5\u8a9e \u4e2d\u6587 Edit links From Wikipedia, the free encyclopedia Russian-French artist (1887\u20131985) \"Chagall\" redirects here. {'1': 'Marc Chagall'} For other uses, see Chagall (disambiguation) . {'1': 'Marc Chagall'} Marc Chagall Chagall, c. 1920 {'1': 'Marc Chagall'} Born Moishe Shagal ( 1887-07-06 ) 6 July 1887 (N.S.) Liozna , Vitebsk Governorate , Russian Empire {'1': 'Marc Chagall'} [1] Died 28 March 1985 (1985-03-28) (aged\u00a097) {'1': 'Marc Chagall'} Saint-Paul-de-Vence , France Nationality Russian, later French {'1': 'Marc Chagall'} [2] Known\u00a0for Painting stained glass Notable work See list of artworks by Marc Chagall Movement Cubism Expressionism School of Paris Spouses Bella Rosenfeld \u200b \u200b ( m. 1915; died\u00a01944) {'1': 'Marc Chagall'} \u200b Valentina (Vava) Brodsky \u200b \u200b ( m. 1952) {'1': 'Marc Chagall'} \u200b {'1': 'Marc Chagall'} [3] Children 2 {'1': 'Marc Chagall'} [4] {'1': 'Marc Chagall'} Marc Chagall [a] (born Moishe Shagal ; 6 July\u00a0[ O.S. 24 June]\u00a01887 \u2013 28 March 1985) was a Russian-French artist. {'1': 'Marc Chagall'} [b] An early modernist , he was associated with the \u00c9cole de Paris as well as several major artistic styles and created works in a wide range of artistic formats, including painting, drawings, book illustrations, stained glass , stage sets, ceramics, tapestries and fine art prints. {'1': 'Marc Chagall'} Chagall was born in 1887, into a Jewish family near Vitebsk , today in Belarus , but at that time in the Pale of Settlement of the Russian Empire. {'1': 'Marc Chagall'} Before World War I , he travelled between Saint Petersburg , Paris , and Berlin . {'1': 'Marc Chagall'} <p>Of course, chunking into sentences isn't the only way to split a document. Perhaps we want to experiment with different chunking methodologies, in order to see which one performs best in a particular application. Pixeltable makes it easy to do this, by creating several views of the same source table. Here are a few examples. Notice that as each new view is created, it is initially populated from the data already in <code>docs</code>.</p> In\u00a0[9]: Copied! <pre>chunks = cl.create_view(\n    'rag_demo.chunks', docs, iterator_class=DocumentSplitter,\n    iterator_args={\n        'document': docs.source_doc,\n        'separators': 'paragraph,token_limit',\n        'limit': 2048,\n        'overlap': 0,\n        'metadata': 'title,headings,sourceline',\n    })\n</pre> chunks = cl.create_view(     'rag_demo.chunks', docs, iterator_class=DocumentSplitter,     iterator_args={         'document': docs.source_doc,         'separators': 'paragraph,token_limit',         'limit': 2048,         'overlap': 0,         'metadata': 'title,headings,sourceline',     }) <pre>Inserting rows into `chunks`: 205 rows [00:00, 8721.47 rows/s]</pre> <pre>Created view `chunks` with 205 rows, 0 exceptions.\n</pre> <pre>\n</pre> In\u00a0[10]: Copied! <pre>short_chunks = cl.create_view(\n    'rag_demo.short_chunks', docs, iterator_class=DocumentSplitter,\n    iterator_args={\n        'document': docs.source_doc,\n        'separators': 'paragraph,token_limit',\n        'limit': 72,\n        'overlap': 0,\n        'metadata': 'title,headings,sourceline',\n    })\n</pre> short_chunks = cl.create_view(     'rag_demo.short_chunks', docs, iterator_class=DocumentSplitter,     iterator_args={         'document': docs.source_doc,         'separators': 'paragraph,token_limit',         'limit': 72,         'overlap': 0,         'metadata': 'title,headings,sourceline',     }) <pre>Inserting rows into `short_chunks`: 527 rows [00:00, 10806.26 rows/s]</pre> <pre>Created view `short_chunks` with 527 rows, 0 exceptions.\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>short_char_chunks = cl.create_view(\n    'rag_demo.short_char_chunks', docs, iterator_class=DocumentSplitter,\n    iterator_args={\n        'document': docs.source_doc,\n        'separators': 'paragraph,char_limit',\n        'limit': 72,\n        'overlap': 0,\n        'metadata': 'title,headings,sourceline',\n    })\n</pre> short_char_chunks = cl.create_view(     'rag_demo.short_char_chunks', docs, iterator_class=DocumentSplitter,     iterator_args={         'document': docs.source_doc,         'separators': 'paragraph,char_limit',         'limit': 72,         'overlap': 0,         'metadata': 'title,headings,sourceline',     }) <pre>Inserting rows into `short_char_chunks`: 1759 rows [00:00, 9943.34 rows/s]</pre> <pre>Created view `short_char_chunks` with 1759 rows, 0 exceptions.\n</pre> <pre>\n</pre> In\u00a0[22]: Copied! <pre>chunks.select(chunks.text, chunks.headings).show(20)\n</pre> chunks.select(chunks.text, chunks.headings).show(20) Out[22]: text headings Marc Chagall 81 languages Afrikaans Alemannisch \u0627\u0644\u0639\u0631\u0628\u064a\u0629 Aragon\u00e9s \u0531\u0580\u0565\u0582\u0574\u057f\u0561\u0570\u0561\u0575\u0565\u0580\u0567\u0576 Asturianu Az\u0259rbaycanca \u09ac\u09be\u0982\u09b2\u09be \u0411\u0430\u0448\u04a1\u043e\u0440\u0442\u0441\u0430 \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f (\u0442\u0430\u0440\u0430\u0448\u043a\u0435\u0432\u0456\u0446\u0430) \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 Catal\u00e0 \u010ce\u0161tina Cymraeg Dansk Deutsch Eesti \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Espa\u00f1ol Esperanto Euskara \u0641\u0627\u0631\u0633\u06cc Fran\u00e7ais Galego \ud55c\uad6d\uc5b4 \u0540\u0561\u0575\u0565\u0580\u0565\u0576 \u0939\u093f\u0928\u094d\u0926\u0940 Hrvatski Ido Bahasa Indonesia Interlingua Italiano \u05e2\u05d1\u05e8\u05d9\u05ea Jawa \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 Kiswahili Latina Latvie\u0161u L\u00ebtzebuergesch Lietuvi\u0173 Magyar \u041c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438 Malagasy \u0645\u0635\u0631\u0649 Nederlands Nedersaksies \u65e5\u672c\u8a9e Norsk bokm\u00e5l Norsk nynorsk Occitan O\u02bbzbekcha / \u045e\u0437\u0431\u0435\u043a\u0447\u0430 \u067e\u0646\u062c\u0627\u0628\u06cc Picard Piemont\u00e8is Plattd\u00fc\u00fctsch Polski Portugu\u00eas Rom\u00e2n\u0103 Runa Simi \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Scots Shqip Sicilianu Simple English Sloven\u010dina Sloven\u0161\u010dina \u06a9\u0648\u0631\u062f\u06cc \u0421\u0440\u043f\u0441\u043a\u0438 / srpski Srpskohrvatski / \u0441\u0440\u043f\u0441\u043a\u043e\u0445\u0440\u0432\u0430\u0442\u0441\u043a\u0438 Suomi Svenska \u0e44\u0e17\u0e22 T\u00fcrk\u00e7e \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 Ti\u1ebfng Vi\u1ec7t Winaray \u5434\u8bed \u05d9\u05d9\u05b4\u05d3\u05d9\u05e9 \u7cb5\u8a9e \u4e2d\u6587 Edit links From Wikipedia, the free encyclopedia Russian-French artist (1887\u20131985) \"Chagall\" redirects here. For other uses, see Chagall (disambiguation) . {'1': 'Marc Chagall'} Marc Chagall Chagall, c. 1920 Born Moishe Shagal ( 1887-07-06 ) 6 July 1887 (N.S.) Liozna , Vitebsk Governorate , Russian Empire [1] Died 28 March 1985 (1985-03-28) (aged\u00a097) Saint-Paul-de-Vence , France Nationality Russian, later French [2] Known\u00a0for Painting stained glass Notable work See list of artworks by Marc Chagall Movement Cubism Expressionism School of Paris Spouses Bella Rosenfeld \u200b \u200b ( m. 1915; died\u00a01944) \u200b Valentina (Vava) Brodsky \u200b \u200b ( m. 1952) \u200b [3] Children 2 [4] {'1': 'Marc Chagall'} Marc Chagall [a] (born Moishe Shagal ; 6 July\u00a0[ O.S. 24 June]\u00a01887 \u2013 28 March 1985) was a Russian-French artist. [b] An early modernist , he was associated with the \u00c9cole de Paris as well as several major artistic styles and created works in a wide range of artistic formats, including painting, drawings, book illustrations, stained glass , stage sets, ceramics, tapestries and fine art prints. {'1': 'Marc Chagall'} Chagall was born in 1887, into a Jewish family near Vitebsk , today in Belarus , but at that time in the Pale of Settlement of the Russian Empire. Before World War I , he travelled between Saint Petersburg , Paris , and Berlin . During that period, he created his own mixture and style of modern art, based on his ideas of Eastern European and Jewish folklore. He spent the wartime years in his native Belarus, becoming one of the country's most distinguished artists and a member of the modernist avant-garde , founding the Vitebsk Arts College . He later worked in and near Moscow in difficult conditions during hard times in Russia following the Bolshevik Revolution , before leaving again for Paris in 1923. During World War II , he escaped occupied France to the United States, where he lived in New York City for seven years before returning to France in 1948. {'1': 'Marc Chagall'} Art critic Robert Hughes referred to Chagall as \"the quintessential Jewish artist of the twentieth century\". According to art historian Michael J. Lewis, Chagall was considered to be \"the last survivor of the first generation of European modernists\". For decades, he \"had also been respected as the world's pre-eminent Jewish artist\". [15] Using the medium of stained glass, he produced windows for the cathedrals of Reims and Metz as well as the Fraum\u00fcnster in Z\u00fcrich , windows for the UN and the Art Institute of Chicago and the Jerusalem Windows in Israel. He also did large-scale paintings, including part of the ceiling of the Paris Op\u00e9ra . He experienced modernism's \"golden age\" in Paris, where \"he synthesized the art forms of Cubism , Symbolism , and Fauvism , and the influence of Fauvism gave rise to Surrealism \". Yet throughout these phases of his style \"he remained most emphatically a Jewish artist, whose work was one long dreamy reverie of life in his native village of Vitebsk.\" [16] \"When Matisse dies\", Pablo Picasso remarked in the 1950s, \"Chagall will be the only painter left who understands what colour really is\". [17] {'1': 'Marc Chagall'} Early life and education [ edit ] {'1': 'Marc Chagall', '2': 'Early life and education[edit]'} Early life [ edit ] Marc Chagall's childhood home in Vitebsk , Belarus. Currently site of the Marc Chagall Museum . Marc Chagall, 1912, The Spoonful of Milk (La Cuiller\u00e9e de lait) , gouache on paper {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} Marc Chagall was born Moishe Shagal in 1887, into a Jewish family in Liozna , [1] near the city of Vitebsk , Belarus, then part of the Russian Empire . [c] [18] At the time of his birth, Vitebsk's population was about 66,000. Half of the population was Jewish. [16] A picturesque city of churches and synagogues, it was called \"Russian Toledo \" by artist Ilya Repin , after the cosmopolitan city of the former Spanish Empire . [19] Because the city was built mostly of wood, little of it survived years of occupation and destruction during World War II. {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} Years later, at the age of 57, while living in the United States, Chagall confirmed that when he published an open letter entitled, \"To My City Vitebsk\": {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Artistic inspiration[edit]'} One of the main sources of income for the Jewish population of the town was from the manufacture of clothing that was sold throughout the Russian Empire. They also made furniture and various agricultural tools. [22] From the late 18th century to the First World War, the Imperial Russian government confined Jews to living within the Pale of Settlement , which included modern Ukraine, Belarus, Poland, Lithuania, and Latvia, almost exactly corresponding to the territory of the Polish-Lithuanian Commonwealth which was taken over by Imperial Russia in the late 18th century. That led to the creation of Jewish market-villages ( shtetls ) throughout today's Eastern Europe, with their own markets, schools, hospitals, and other community institutions. [23] :\u200a14 {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} Chagall wrote as a boy; \"I felt at every step that I was a Jew\u2014people made me feel it\". [24] [25] During a pogrom , Chagall wrote that: \"The street lamps are out. I feel panicky, especially in front of butchers' windows. There you can see calves that are still alive lying beside the butchers' hatchets and knives\". [25] [26] When asked by some pogromniks \"Jew or not?\", Chagall remembered thinking: \"My pockets are empty, my fingers sensitive, my legs weak and they are out for blood. My death would be futile. I so wanted to live\". [25] [26] Chagall denied being a Jew, leading the pogromniks to shout \"All right! Get along!\" [25] [26] {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} Most of what is known about Chagall's early life has come from his autobiography, My Life . In it, he described the major influence that the culture of Hasidic Judaism had on his life as an artist. Chagall related how he realised that the Jewish traditions in which he had grown up were fast disappearing and that he needed to document them. From the 1730s, Vitebsk itself had been a centre of that culture, with its teachings derived from the Kabbalah . Chagall scholar, Susan Tumarkin Goodman, describes the links and sources of his art to his early home: {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} Chagall's art can be understood as the response to a situation that has long marked the history of Russian Jews. Though they were cultural innovators who made important contributions to the broader society, Jews were considered outsiders in a frequently hostile society ... Chagall himself was born of a family steeped in religious life; his parents were observant Hasidic Jews who found spiritual satisfaction in a life defined by their faith and organized by prayer. [23] :\u200a14 {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} Art education [ edit ] Portrait of Chagall by Yehuda Pen , his first art teacher in Vitebsk {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Art education[edit]'} In the Russian Empire at that time, Jewish children were not allowed to attend regular schools and universities imposed a quota on Jews . Their movement within the city was also restricted. Chagall therefore received his primary education at the local Jewish religious school, where he studied Hebrew and the Bible. At the age of 13, his mother tried to enrol him in a regular high school, and he recalled: \"But in that school, they don't take Jews. Without a moment's hesitation, my courageous mother walks up to a professor.\" She offered the headmaster 50 roubles to let him attend, which he accepted. [21] {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Art education[edit]'} Goodman writes that Chagall eventually confided to his mother, \"I want to be a painter\", although she could not yet understand his sudden interest in art or why he would choose a vocation that \"seemed so impractical\". The young Chagall explained: \"There's a place in town; if I'm admitted and if I complete the course, I'll come out a regular artist. I'd be so happy!\" It was 1906, and he had noticed the studio of Yehuda (Yuri) Pen , a realist artist who operated a drawing school in Vitebsk. At the same time, future artists El Lissitzky and Ossip Zadkine were also Pen's students. Due to Chagall's youth and lack of income, Pen offered to teach him free of charge. However, after a few months at the school, Chagall realized that academic portrait painting did not suit him. [22] {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Art education[edit]'} Artistic inspiration [ edit ] Marc Chagall, 1912, Calvary ( Golgotha ) , oil on canvas, 174.6 \u00d7 192.4\u00a0cm, Museum of Modern Art , New York. Alternative titles: Kreuzigung Bild 2 Christus gewidmet [Golgotha. Crucifixion. Dedicated to Christ] . Sold through Galerie Der Sturm (Herwarth Walden), Berlin to Bernhard Koehler (1849\u20131927), Berlin, 1913. Exhibited: Erster Deutscher Herbstsalon , Berlin, 1913 {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Artistic inspiration[edit]'} Goodman notes that during that period in Imperial Russia, Jews had two ways to join the art world: one was to \"hide or deny one's Jewish roots\", the other\u2014the one that Chagall chose\u2014was \"to cherish and publicly express one's Jewish roots\" by integrating them into art. For Chagall, that was also his means of \"self-assertion and an expression of principle\". [23] :\u200a14 {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Artistic inspiration[edit]'} Chagall biographer, Franz Meyer, explains that with the connections between his art and early life \"the hassidic spirit is still the basis and source of nourishment for his art\". [27] Lewis adds: \"As cosmopolitan an artist as he would later become, his storehouse of visual imagery would never expand beyond the landscape of his childhood, with its snowy streets, wooden houses, and ubiquitous fiddlers... [with] scenes of childhood so indelibly in one's mind and to invest them with an emotional charge so intense that it could only be discharged obliquely through an obsessive repetition of the same cryptic symbols and ideograms... \" [16] {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Artistic inspiration[edit]'} Why? Why did I leave you many years ago? ... You thought, the boy seeks something, seeks such a special subtlety, that color descending like stars from the sky and landing, bright and transparent, like snow on our roofs. Where did he get it? How would it come to a boy like him? I don't know why he couldn't find it with us, in the city\u2014in his homeland. Maybe the boy is \"crazy\", but \"crazy\" for the sake of art. ...You thought: \"I can see, I am etched in the boy's heart, but he is still 'flying', he is still striving to take off, he has 'wind' in his head.\" ... I did not live with you, but I didn't have one single painting that didn't breathe with your spirit and reflection. [28] {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Artistic inspiration[edit]'} In\u00a0[23]: Copied! <pre>short_chunks.select(short_chunks.text, short_chunks.headings).show(20)\n</pre> short_chunks.select(short_chunks.text, short_chunks.headings).show(20) Out[23]: text headings Marc Chagall - Wikipedia Jump to content Search Search {} Marc Chagall 81 languages Afrikaans Alemannisch \u0627\u0644\u0639\u0631\u0628\u064a\u0629 Aragon\u00e9s \u0531\u0580\u0565\u0582\u0574\u057f\u0561\u0570\u0561\u0575\u0565\u0580\u0567\u0576 Asturianu Az\u0259rbaycanca \u09ac\u09be\u0982\u09b2\u09be \u0411\u0430\u0448\u04a1 {'1': 'Marc Chagall'} \u043e\u0440\u0442\u0441\u0430 \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f (\u0442\u0430\u0440\u0430\u0448\u043a\u0435\u0432\u0456\u0446\u0430) \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 Catal\u00e0 \u010ce\u0161tina Cymraeg Dansk Deutsch Eesti \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Espa\u00f1ol Esperanto Euskara \u0641\u0627\u0631\u0633\u06cc Fran\u00e7ais Galego \ud55c {'1': 'Marc Chagall'} \uad6d\uc5b4 \u0540\u0561\u0575\u0565\u0580\u0565\u0576 \u0939\u093f\u0928\u094d\u0926\u0940 Hrvatski Ido Bahasa Indonesia Interlingua Italiano \u05e2\u05d1\u05e8\u05d9\u05ea Jawa \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 Kiswahili Latina Latvie\u0161u L\u00eb {'1': 'Marc Chagall'} tzebuergesch Lietuvi\u0173 Magyar \u041c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438 Malagasy \u0645\u0635\u0631\u0649 Nederlands Nedersaksies \u65e5\u672c\u8a9e Norsk bokm\u00e5l Norsk nynorsk Occitan O\u02bbzbekcha / \u045e\u0437\u0431\u0435\u043a\u0447\u0430 \u067e\u0646\u062c\u0627\u0628\u06cc Picard Piemont {'1': 'Marc Chagall'} \u00e8is Plattd\u00fc\u00fctsch Polski Portugu\u00eas Rom\u00e2n\u0103 Runa Simi \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Scots Shqip Sicilianu Simple English Sloven\u010dina Sloven\u0161\u010dina \u06a9\u0648\u0631\u062f\u06cc \u0421\u0440\u043f\u0441\u043a\u0438 / srpski Srpskohrvatski / \u0441\u0440\u043f\u0441\u043a\u043e\u0445\u0440\u0432\u0430\u0442\u0441\u043a\u0438 Suomi {'1': 'Marc Chagall'} Svenska \u0e44\u0e17\u0e22 T\u00fcrk\u00e7e \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 Ti\u1ebfng Vi\u1ec7t Winaray \u5434\u8bed \u05d9\u05d9\u05b4\u05d3\u05d9\u05e9 \u7cb5\u8a9e \u4e2d\u6587 Edit links From Wikipedia, the free encyclopedia Russian-French artist (1887\u20131985) \"Chagall\" redirects here {'1': 'Marc Chagall'} . For other uses, see Chagall (disambiguation) . {'1': 'Marc Chagall'} Marc Chagall Chagall, c. 1920 Born Moishe Shagal ( 1887-07-06 ) 6 July 1887 (N.S.) Liozna , Vitebsk Governorate , Russian Empire [1] Died 28 March 1985 (1985-03-28) (aged {'1': 'Marc Chagall'} 97) Saint-Paul-de-Vence , France Nationality Russian, later French [2] Known\u00a0for Painting stained glass Notable work See list of artworks by Marc Chagall Movement Cubism Expressionism School of Paris Spouses Bella Rosenfeld \u200b \u200b ( m. 1915; died\u00a01944) \u200b Valentina (Vava) {'1': 'Marc Chagall'} Brodsky \u200b \u200b ( m. 1952) \u200b [3] Children 2 [4] {'1': 'Marc Chagall'} Marc Chagall [a] (born Moishe Shagal ; 6 July\u00a0[ O.S. 24 June]\u00a01887 \u2013 28 March 1985) was a Russian-French artist. [b] An early modernist , he was associated with the \u00c9cole de Paris as well as several major artistic styles and created works {'1': 'Marc Chagall'} in a wide range of artistic formats, including painting, drawings, book illustrations, stained glass , stage sets, ceramics, tapestries and fine art prints. {'1': 'Marc Chagall'} Chagall was born in 1887, into a Jewish family near Vitebsk , today in Belarus , but at that time in the Pale of Settlement of the Russian Empire. Before World War I , he travelled between Saint Petersburg , Paris , and Berlin . During that period, he created his own mixture and style of modern art, based on his {'1': 'Marc Chagall'} ideas of Eastern European and Jewish folklore. He spent the wartime years in his native Belarus, becoming one of the country's most distinguished artists and a member of the modernist avant-garde , founding the Vitebsk Arts College . He later worked in and near Moscow in difficult conditions during hard times in Russia following the Bolshevik Revolution , before leaving again for Paris {'1': 'Marc Chagall'} in 1923. During World War II , he escaped occupied France to the United States, where he lived in New York City for seven years before returning to France in 1948. {'1': 'Marc Chagall'} Art critic Robert Hughes referred to Chagall as \"the quintessential Jewish artist of the twentieth century\". According to art historian Michael J. Lewis, Chagall was considered to be \"the last survivor of the first generation of European modernists\". For decades, he \"had also been respected as the world's pre-eminent Jewish artist\". [15] {'1': 'Marc Chagall'} Using the medium of stained glass, he produced windows for the cathedrals of Reims and Metz as well as the Fraum\u00fcnster in Z\u00fcrich , windows for the UN and the Art Institute of Chicago and the Jerusalem Windows in Israel. He also did large-scale paintings, including part of the ceiling of the Paris Op\u00e9ra . He experienced {'1': 'Marc Chagall'} modernism's \"golden age\" in Paris, where \"he synthesized the art forms of Cubism , Symbolism , and Fauvism , and the influence of Fauvism gave rise to Surrealism \". Yet throughout these phases of his style \"he remained most emphatically a Jewish artist, whose work was one long dreamy reverie of {'1': 'Marc Chagall'} life in his native village of Vitebsk.\" [16] \"When Matisse dies\", Pablo Picasso remarked in the 1950s, \"Chagall will be the only painter left who understands what colour really is\". [17] {'1': 'Marc Chagall'} In\u00a0[24]: Copied! <pre>short_char_chunks.select(short_char_chunks.text, short_char_chunks.headings).show(20)\n</pre> short_char_chunks.select(short_char_chunks.text, short_char_chunks.headings).show(20) Out[24]: text headings Marc Chagall - Wikipedia Jump to content Search Search {} Marc Chagall 81 languages Afrikaans Alemannisch \u0627\u0644\u0639\u0631\u0628\u064a\u0629 Aragon\u00e9s \u0531\u0580\u0565\u0582\u0574\u057f {'1': 'Marc Chagall'} \u0561\u0570\u0561\u0575\u0565\u0580\u0567\u0576 Asturianu Az\u0259rbaycanca \u09ac\u09be\u0982\u09b2\u09be \u0411\u0430\u0448\u04a1\u043e\u0440\u0442\u0441\u0430 \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f (\u0442 {'1': 'Marc Chagall'} \u0430\u0440\u0430\u0448\u043a\u0435\u0432\u0456\u0446\u0430) \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 Catal\u00e0 \u010ce\u0161tina Cymraeg Dansk Deutsch Eesti \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba {'1': 'Marc Chagall'} \u03ac Espa\u00f1ol Esperanto Euskara \u0641\u0627\u0631\u0633\u06cc Fran\u00e7ais Galego \ud55c\uad6d\uc5b4 \u0540\u0561\u0575\u0565\u0580\u0565\u0576 \u0939\u093f\u0928\u094d\u0926\u0940 Hrv {'1': 'Marc Chagall'} atski Ido Bahasa Indonesia Interlingua Italiano \u05e2\u05d1\u05e8\u05d9\u05ea Jawa \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 Kiswa {'1': 'Marc Chagall'} hili Latina Latvie\u0161u L\u00ebtzebuergesch Lietuvi\u0173 Magyar \u041c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438 Malagasy {'1': 'Marc Chagall'} \u0645\u0635\u0631\u0649 Nederlands Nedersaksies \u65e5\u672c\u8a9e Norsk bokm\u00e5l Norsk nynorsk Occitan O\u02bbzb {'1': 'Marc Chagall'} ekcha / \u045e\u0437\u0431\u0435\u043a\u0447\u0430 \u067e\u0646\u062c\u0627\u0628\u06cc Picard Piemont\u00e8is Plattd\u00fc\u00fctsch Polski Portugu\u00eas R {'1': 'Marc Chagall'} om\u00e2n\u0103 Runa Simi \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Scots Shqip Sicilianu Simple English Sloven\u010dina {'1': 'Marc Chagall'} Sloven\u0161\u010dina \u06a9\u0648\u0631\u062f\u06cc \u0421\u0440\u043f\u0441\u043a\u0438 / srpski Srpskohrvatski / \u0441\u0440\u043f\u0441\u043a\u043e\u0445\u0440\u0432\u0430\u0442\u0441\u043a\u0438 Suomi {'1': 'Marc Chagall'} Svenska \u0e44\u0e17\u0e22 T\u00fcrk\u00e7e \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 Ti\u1ebfng Vi\u1ec7t Winaray \u5434\u8bed \u05d9\u05d9\u05b4\u05d3\u05d9\u05e9 \u7cb5\u8a9e \u4e2d\u6587 Edit li {'1': 'Marc Chagall'} nks From Wikipedia, the free encyclopedia Russian-French artist (1887\u201319 {'1': 'Marc Chagall'} 85) \"Chagall\" redirects here. For other uses, see Chagall (disambiguatio {'1': 'Marc Chagall'} n) . {'1': 'Marc Chagall'} Marc Chagall Chagall, c. 1920 Born Moishe Shagal ( 1887-07-06 ) 6 July {'1': 'Marc Chagall'} 1887 (N.S.) Liozna , Vitebsk Governorate , Russian Empire [1] Died 28 Ma {'1': 'Marc Chagall'} rch 1985 (1985-03-28) (aged\u00a097) Saint-Paul-de-Vence , France Nationality {'1': 'Marc Chagall'} Russian, later French [2] Known\u00a0for Painting stained glass Notable work {'1': 'Marc Chagall'} See list of artworks by Marc Chagall Movement Cubism Expressionism Scho {'1': 'Marc Chagall'} <p>Now let's add a few more documents to our workflow. Notice how all of the downstream views are updated incrementally, processing just the new documents as they are inserted.</p> In\u00a0[15]: Copied! <pre>urls = [\n    'https://en.wikipedia.org/wiki/Pierre-Auguste_Renoir',\n    'https://en.wikipedia.org/wiki/Henri_Matisse',\n    'https://en.wikipedia.org/wiki/Marcel_Duchamp'\n]\ndocs.insert([{'source_doc': url} for url in urls])\n</pre> urls = [     'https://en.wikipedia.org/wiki/Pierre-Auguste_Renoir',     'https://en.wikipedia.org/wiki/Henri_Matisse',     'https://en.wikipedia.org/wiki/Marcel_Duchamp' ] docs.insert([{'source_doc': url} for url in urls]) <pre>Inserting rows into `docs`: 3 rows [00:00, 1907.37 rows/s]\nInserting rows into `sentences`: 2104 rows [00:03, 602.96 rows/s]\nInserting rows into `chunks`: 274 rows [00:00, 8737.80 rows/s]\nInserting rows into `short_chunks`: 802 rows [00:00, 10560.29 rows/s]\nInserting rows into `short_char_chunks`: 2622 rows [00:00, 5677.07 rows/s]</pre> <pre>Inserted 5805 rows with 0 errors.\n</pre> <pre>\n</pre> Out[15]: <pre>UpdateStatus(num_rows=5805, num_computed_values=0, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>Next, let's look at how embeddings can be added seamlessly to existing Pixeltable workflows. To compute our embeddings, we'll use the Huggingface <code>sentence_transformer</code> package, running it over the <code>chunks</code> view that broke our documents up into larger paragraphs. Pixeltable has a built-in <code>sentence_transformer</code> adapter, and all we have to do is add a new column that leverages it. Pixeltable takes care of the rest, applying the new column to all existing data in the view.</p> In\u00a0[16]: Copied! <pre>from pixeltable.functions.huggingface import sentence_transformer, clip\n\nminilm_model_id = 'paraphrase-MiniLM-L6-v2'\n\nchunks.add_column(minilm_embedding=sentence_transformer(chunks.text, model_id=minilm_model_id))\n</pre> from pixeltable.functions.huggingface import sentence_transformer, clip  minilm_model_id = 'paraphrase-MiniLM-L6-v2'  chunks.add_column(minilm_embedding=sentence_transformer(chunks.text, model_id=minilm_model_id)) <pre>Computing cells:   0%|                                                                                                                                                                                                                                                                    | 0/479 [00:00&lt;?, ?cells/s]/Users/asiegel/Dropbox/workspace/pixeltable/pixeltable/.venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nComputing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 479/479 [00:06&lt;00:00, 71.25cells/s]</pre> <pre>added 479 column values with 0 errors\n</pre> <pre>\n</pre> Out[16]: <pre>UpdateStatus(num_rows=479, num_computed_values=479, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> <p>The new column is a computed column: it is defined as a function on top of existing data and updated incrementally as new data are added to the workflow. Let's have a look at how the new column affected the <code>chunks</code> view.</p> In\u00a0[17]: Copied! <pre>chunks\n</pre> chunks Out[17]: Column Name Type Computed With pos int text string title string headings json sourceline int minilm_embedding array((None,), dtype=FLOAT) huggingface.sentence_transformer(text, model_id='paraphrase-MiniLM-L6-v2') source_doc document In\u00a0[18]: Copied! <pre>chunks.head()\n</pre> chunks.head() Out[18]: pos text title headings sourceline minilm_embedding source_doc 0 Marc Chagall - Wikipedia Jump to content Search Search Marc Chagall - Wikipedia {} 0 [-0.26239744, -0.11875608, -0.13270901, 0.048251476, 0.11987579, -0.0060523422, 0.32066357, 0.04835883, 0.29429552, -0.25400946, 0.6250121, 0.17804725, -0.0049092094, 0.26455665, -0.25857177, -0.04235531, 0.36528507, 0.23551288, 0.27595958, -0.3712053, 0.17573264, 0.0029876528, 0.23927844, -0.17485948, 0.1954067, -0.48891908, -0.7418267, -0.30720565, 0.23550902, -0.26159504, 0.5011105, -0.6918158, -0.25462586, -0.19169782, 0.5265674, 0.10684755, -0.3500413, -0.47890776, 0.27644473, 0.2624894, 0.055178, -0.1461069, -0.21482669, 0.7246923, -0.105297744, 0.5106913, -0.18174116, 0.45920599, 0.36721304, 0.51290447, -0.65757185, -0.4469795, -0.26267004, -0.44820127, 0.38971028, -0.1695206, -0.114350036, -0.07236255, 0.2645084, -0.5793037, 0.28047276, 0.091701195, -0.16436026, 0.10646367, -0.1461572, 0.19661109, 0.07363955, 0.21059886, 0.1799219, 0.1598077, -0.37105122, 0.25376227, -0.4467154, 0.6573318, -0.38872772, -0.2764637, -0.79460824, -0.08837392, -0.27318305, -0.21008545, 0.57023394, -0.3434785, 0.15152003, -0.30319378, -0.043730583, -0.3291485, 0.2555499, 0.060874756, 0.23776941, 0.29614958, 0.18648784, -0.35599723, 0.15256202, -0.084133916, -0.48064327, 0.30865645, 0.1097052, 0.11276893, 0.718605, -0.21019463, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 1 Marc Chagall 81 languages Afrikaans Alemannisch \u0627\u0644\u0639\u0631\u0628\u064a\u0629 Aragon\u00e9s \u0531\u0580\u0565\u0582\u0574\u057f\u0561\u0570\u0561\u0575\u0565\u0580\u0567\u0576 Asturianu Az\u0259rbaycanca \u09ac\u09be\u0982\u09b2\u09be \u0411\u0430\u0448\u04a1\u043e\u0440\u0442\u0441\u0430 \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f (\u0442\u0430\u0440\u0430\u0448\u043a\u0435\u0432\u0456\u0446\u0430) \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 Catal\u00e0 \u010ce\u0161tina Cymraeg Dansk Deutsch Eesti \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Espa\u00f1ol Esperanto Euskara \u0641\u0627\u0631\u0633\u06cc Fran\u00e7ais Galego \ud55c\uad6d\uc5b4 \u0540\u0561\u0575\u0565\u0580\u0565\u0576 \u0939\u093f\u0928\u094d\u0926\u0940 Hrvatski Ido Bahasa Indonesia Interlingua Italiano \u05e2\u05d1\u05e8\u05d9\u05ea Jawa \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 Kiswahili Latina Latvie\u0161u L\u00ebtzebuergesch Lietuvi\u0173 Magyar \u041c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438 Malagasy \u0645\u0635\u0631\u0649 Nederlands Nedersaksies \u65e5\u672c\u8a9e Norsk bokm\u00e5l Norsk nynorsk Occitan O\u02bbzbekcha / \u045e\u0437\u0431\u0435\u043a\u0447\u0430 \u067e\u0646\u062c\u0627\u0628\u06cc Picard Piemont\u00e8is Plattd\u00fc\u00fctsch Polski Portugu\u00eas Rom\u00e2n\u0103 Runa Simi \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Scots Shqip Sicilianu Simple English Sloven\u010dina Sloven\u0161\u010dina \u06a9\u0648\u0631\u062f\u06cc \u0421\u0440\u043f\u0441\u043a\u0438 / srpski Srpskohrvatski / \u0441\u0440\u043f\u0441\u043a\u043e\u0445\u0440\u0432\u0430\u0442\u0441\u043a\u0438 Suomi Svenska \u0e44\u0e17\u0e22 T\u00fcrk\u00e7e \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 Ti\u1ebfng Vi\u1ec7t Winaray \u5434\u8bed \u05d9\u05d9\u05b4\u05d3\u05d9\u05e9 \u7cb5\u8a9e \u4e2d\u6587 Edit links From Wikipedia, the free encyclopedia Russian-French artist (1887\u20131985) \"Chagall\" redirects here. For other uses, see Chagall (disambiguation) . Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 820 [-0.1363125, 0.40063262, -0.53002965, -0.18143149, -0.45316985, -0.124922395, 0.7796174, -0.24712479, 0.12325851, -0.22153592, 0.28455305, -0.4370274, 0.23156813, 0.14490244, -0.1085123, -0.28869802, 0.21817636, 0.7690572, -0.31989712, -0.44312742, 0.059898064, -0.08027313, 0.12561844, 0.20749849, -0.04779504, 0.2481188, 0.31219974, -0.08558018, -0.22011802, 0.3522022, 0.58977985, 0.07881048, 0.19522715, -0.14123625, 0.35312974, 0.24841884, -0.13180904, 0.27224553, 0.28210613, 0.13397679, 0.10607662, -0.09232119, 0.09185555, 0.18311317, 0.12448643, -0.050988674, -0.17604467, 0.015647216, -0.05244761, -0.24283391, -0.42616737, -0.45576864, -0.35507995, -0.43146488, 0.30693346, -0.9420446, -0.15023254, 0.73326993, 0.0008648038, -0.36632615, -0.5619301, 0.21601507, -0.6227495, 0.43365502, -0.2858443, -0.33551332, -0.044290252, 0.3440103, -0.2007212, 0.051950164, -0.14124432, -0.12208969, 0.17209955, 0.24971402, -0.114884056, -0.36850527, 0.2503845, 0.2248823, -0.23860496, 0.014345463, 0.13038495, -0.005723685, -0.030419044, -0.29217696, 0.23628014, -0.0753976, -0.011316212, -0.09114735, 0.6540441, -0.9468982, 0.51743305, 0.29965192, 0.23870105, -0.06947729, 0.50110245, -0.08394459, 0.15647276, -0.33553198, 0.086335674, -0.11068067, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 2 Marc Chagall Chagall, c. 1920 Born Moishe Shagal ( 1887-07-06 ) 6 July 1887 (N.S.) Liozna , Vitebsk Governorate , Russian Empire [1] Died 28 March 1985 (1985-03-28) (aged\u00a097) Saint-Paul-de-Vence , France Nationality Russian, later French [2] Known\u00a0for Painting stained glass Notable work See list of artworks by Marc Chagall Movement Cubism Expressionism School of Paris Spouses Bella Rosenfeld \u200b \u200b ( m. 1915; died\u00a01944) \u200b Valentina (Vava) Brodsky \u200b \u200b ( m. 1952) \u200b [3] Children 2 [4] Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1015 [-0.008921713, 0.2953745, -0.27866575, 0.11898915, -0.10827372, 0.34317943, 0.30031225, -0.030542523, 0.140571, -0.28433242, -0.2565046, -0.05376678, 0.15980518, -0.0073799845, -0.28197083, 0.1605216, -0.03273403, -0.023190707, 0.028482616, 0.02866254, 0.2178052, 0.09019671, 0.052278988, 0.061336607, 0.16683066, -0.31540227, -0.019625362, -0.17355925, 0.02343002, -0.018515123, 0.14497948, 0.011320164, -0.3156602, 0.13852714, 0.10553112, -0.044779748, -0.25689107, -0.06320519, 0.25297517, 0.22012936, 0.07603831, 0.0792726, -0.09764494, 0.05466658, 0.17789416, -0.052053563, 0.26565787, 0.00021006167, -0.1526493, 0.12836061, -0.4405348, -0.26161498, 0.12986717, -0.21648112, 0.20075297, -0.44728103, -0.10824932, -0.06369618, 0.1275613, -0.23966262, -0.13780478, -0.046827924, -0.07935211, -0.03928666, -0.25900114, 0.12769607, 0.08089128, -0.10918328, 0.28736144, -0.09079674, 0.18327945, 0.009950456, -0.27137786, -0.015346631, -0.27941808, -0.093986854, -0.16076668, 0.057925873, -0.40844643, -0.32947126, 0.18667138, -0.01637459, 0.17409977, 0.33120197, 0.075517796, 0.048949778, -0.06265739, 0.0670907, 5.528424e-05, -0.00027803052, 0.2049149, 0.3010924, -0.05034807, 0.052502863, 0.10266558, 0.10392622, 0.101448216, 0.0930416, 0.08641965, -0.13062412, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 3 Marc Chagall [a] (born Moishe Shagal ; 6 July\u00a0[ O.S. 24 June]\u00a01887 \u2013 28 March 1985) was a Russian-French artist. [b] An early modernist , he was associated with the \u00c9cole de Paris as well as several major artistic styles and created works in a wide range of artistic formats, including painting, drawings, book illustrations, stained glass , stage sets, ceramics, tapestries and fine art prints. Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1029 [0.06070795, 0.15527856, -0.18933804, 0.1676786, -0.08854648, 0.17130661, 0.15085012, -0.043867312, 0.15022112, -0.47134027, -0.28864872, -0.17173266, -0.047000878, 0.026633887, -0.06628941, 0.16065459, 0.11814179, 0.13180229, -0.004020047, -0.14932036, 0.17918746, 0.21494934, 0.09146305, 0.038962457, 0.038501732, -0.2523544, 0.2707501, -0.25661966, 0.13307239, -0.39810288, 0.21422932, 0.079853565, -0.2808314, -0.009454813, -0.00704834, 0.052204095, -0.21773988, -0.021139788, 0.11031103, 0.26661894, 0.21084817, 0.32182968, -0.09556146, 0.072593026, 0.12131224, -0.10451728, -0.010188689, -0.037562072, -0.22708271, 0.14353341, -0.37686625, -0.17414235, 0.21614799, -0.45889544, 0.07239775, -0.40199217, 0.07049387, 0.02676736, 0.15950078, -0.24915555, -0.09596315, -0.07551933, 0.19581802, -0.035720993, -0.10169222, -0.08450496, -0.091727786, -0.07791178, 0.12658142, -0.039653488, 0.027229717, 0.08718759, 0.037420988, -0.031369355, 0.021826634, -0.50100785, -0.18308267, 0.24249087, -0.30463615, -0.1627777, 0.39998814, -0.16028915, 0.034172066, 0.2015968, 0.08487637, 0.06755659, -0.050601058, 0.14891133, -0.025254607, -0.0067675593, 0.1215523, 0.16791311, -0.24602473, 0.080474414, -0.012239213, 0.09207286, 0.019633006, 0.24711514, 0.19672461, -0.0031050658, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 4 Chagall was born in 1887, into a Jewish family near Vitebsk , today in Belarus , but at that time in the Pale of Settlement of the Russian Empire. Before World War I , he travelled between Saint Petersburg , Paris , and Berlin . During that period, he created his own mixture and style of modern art, based on his ideas of Eastern European and Jewish folklore. He spent the wartime years in his native Belarus, becoming one of the country's most distinguished artists and a member of the modernist avant-garde , founding the Vitebsk Arts College . He later worked in and near Moscow in difficult conditions during hard times in Russia following the Bolshevik Revolution , before leaving again for Paris in 1923. During World War II , he escaped occupied France to the United States, where he lived in New York City for seven years before returning to France in 1948. Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1030 [0.012889067, 0.24784814, -0.6924428, 0.1426121, -0.3790234, 0.25358468, 0.25536245, -0.12604716, 0.116000354, -0.34645474, -0.42178202, 0.019877212, 0.21520866, -0.06495547, -0.15178001, 0.11160548, -0.15971011, 0.06491916, -0.0047337115, -0.33831468, -0.27981135, -0.19120821, 0.3114935, -0.09731045, 0.41788405, -0.36130282, 0.1289389, -0.11600192, -0.041783914, -0.10795093, 0.2949969, -0.13806339, -0.14393348, -0.008052545, 0.016671669, 0.17721409, -0.03954895, -0.10124817, 0.0785659, 0.16309267, 0.18659109, 0.25182652, -0.086883925, 0.08496222, 0.099514656, 0.30495775, 0.17764322, 0.14045668, -0.18228962, 0.042524166, -0.23616257, -0.22173877, 0.12292056, -0.21659315, 0.20440893, -0.26627287, -0.028624976, 0.20077917, 0.17120816, -0.43130222, -0.08327547, -0.26314807, 0.2010209, 0.05320871, -0.23124723, 0.053521108, -0.14058796, -0.009598296, 0.25529027, 0.07367204, 0.108012736, 0.21220206, -0.31999534, -0.011201449, -0.1051358, -0.5790532, -0.09553775, 0.008409397, -0.23266529, -0.08355572, 0.32477862, 0.22916731, 0.07943112, 0.31860423, 0.08367223, 0.026719313, -0.014187841, 0.19423032, 0.059627395, -0.0067669214, 0.5294448, -0.035245955, 0.05879449, -0.06393026, 0.008244172, 0.19260912, 0.016116004, 0.3515519, 0.1926637, -0.24429806, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 5 Art critic Robert Hughes referred to Chagall as \"the quintessential Jewish artist of the twentieth century\". According to art historian Michael J. Lewis, Chagall was considered to be \"the last survivor of the first generation of European modernists\". For decades, he \"had also been respected as the world's pre-eminent Jewish artist\". [15] Using the medium of stained glass, he produced windows for the cathedrals of Reims and Metz as well as the Fraum\u00fcnster in Z\u00fcrich , windows for the UN and the Art Institute of Chicago and the Jerusalem Windows in Israel. He also did large-scale paintings, including part of the ceiling of the Paris Op\u00e9ra . He experienced modernism's \"golden age\" in Paris, where \"he synthesized the art forms of Cubism , Symbolism , and Fauvism , and the influence of Fauvism gave rise to Surrealism \". Yet throughout these phases of his style \"he remained most emphatically a Jewish artist, whose work was one long dreamy reverie of life in his native village of Vitebsk.\" [16] \"When Matisse dies\", Pablo Picasso remarked in the 1950s, \"Chagall will be the only painter left who understands what colour really is\". [17] Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1031 [-0.1718488, 0.34802842, -0.3067041, 0.033759266, -0.07120789, 0.11081593, -0.015894428, -0.13356614, -0.033708245, -0.2419452, -0.44456822, 0.05929219, 0.020918187, 0.14204657, -0.24098685, 0.270058, -0.25892293, 0.045101464, 0.053786207, 0.112981185, -0.08186188, 0.076918334, 0.3056298, -0.1219505, 0.30861628, -0.20567948, 0.19921294, -0.12860534, -0.14399259, -0.060565773, 0.09843977, -0.10340746, -0.26555914, -0.027046643, 0.070481814, 0.07951172, -0.06800346, 0.0012837779, 0.23670606, 0.1605123, 0.08615838, 0.3051123, -0.027099106, -0.17317611, 0.014067065, -0.01578261, 0.12305312, 0.05461803, -0.20789422, 0.11169634, -0.243294, -0.1717479, 0.31153303, -0.477225, 0.08077119, -0.3160271, -0.108076364, -0.060807537, -0.12826538, -0.47114924, -0.11467476, -0.3874791, -0.18139084, 0.17687614, -0.033176806, -0.10800477, -0.113080636, -0.19606844, -0.022167385, 0.08167149, 0.077876404, 0.04912953, 0.019410212, 0.07751435, 0.11992899, -0.27325982, -0.07606392, -0.0123761445, -0.30934036, -0.05539541, 0.49092746, 0.054491326, 0.1359975, 0.29677787, 0.195668, -0.02722781, -0.10856432, 0.039952196, -0.06816634, 0.14353533, 0.10984236, 0.08890318, 0.12124765, 0.23209828, 0.18221292, 0.226612, -0.053041402, 0.17716643, -0.003824023, -0.22502854, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 6 Early life and education [ edit ] Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]'} 1034 [-0.21258694, 0.41762605, 0.09400449, 0.13499947, -0.06885149, 0.26491603, -0.12511107, 0.28833583, 0.04579986, 0.22168949, 0.29161087, -0.31456777, -0.31366986, 0.11542555, 0.08831894, 0.056974404, 0.2402763, -0.25183347, -0.12356235, -0.54612905, -0.09656416, 0.0660866, 0.25659195, -0.052964527, 0.4823795, 0.32737747, 0.086159095, -0.071204886, 0.12762076, 0.42564514, 0.02772967, -0.41478524, 0.5348886, -0.45198312, -0.47164515, 0.31659156, 0.8776631, 0.042706072, -0.255907, 0.044347186, -0.14535584, 0.2864719, -0.113270864, 0.19460054, 0.05073829, -0.15815656, 0.25129333, -0.2220522, -0.09832473, -0.12678048, -0.5666925, -0.12103812, 0.03459396, -0.35877624, 0.19099654, 0.32248336, -0.06600305, 0.4256649, -0.23869184, 0.067017615, -0.83746076, -0.26572597, -0.0097357035, 0.70784605, -0.07748319, 0.27188894, -0.06916828, 0.4451362, 0.1913614, -0.33502167, -0.15556404, -0.2711281, 0.118402824, 0.361828, -0.33293796, -0.13884008, 0.040201046, 0.33501458, 0.11592436, -0.79345524, 0.21795018, 0.23458, -0.09650008, 0.24245013, -0.2910435, 0.41454414, -0.4800957, 0.29933104, -0.14576554, -0.29111043, 0.64425385, -0.46670642, -0.48874134, 0.35364032, 0.6117833, 0.20667987, -0.5535579, -0.32985795, -0.13371441, -0.22560607, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 7 Early life [ edit ] Marc Chagall's childhood home in Vitebsk , Belarus. Currently site of the Marc Chagall Museum . Marc Chagall, 1912, The Spoonful of Milk (La Cuiller\u00e9e de lait) , gouache on paper Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} 1035 [-0.040403567, 0.14281169, -0.35680732, 0.41181752, -0.33060923, 0.20134678, 0.15904729, 0.1680692, 0.23450555, -0.17853774, 0.076216996, -0.23785742, 0.047059476, 0.0723482, -0.5144092, 0.0059390757, 0.11763715, 0.16320866, 0.20046358, -0.31078827, 0.033091, -0.03074765, 0.26112205, -0.040257227, 0.33917278, 0.008225182, -0.21099399, -0.19426702, -0.17069323, -0.15220758, 0.06614052, -0.29302466, -0.16281912, -0.21634808, 0.0507121, 0.36889926, 0.2109983, -0.28517646, 0.046531904, 0.101085275, 0.17541906, 0.27149823, -0.024600174, 0.13682236, -0.073069565, 0.16629833, 0.33900666, -0.0226166, -0.1238528, 0.083200105, -0.60445195, -0.30993247, 0.21716255, -0.29389524, 0.16422015, -0.25379407, 0.059631355, 0.0020764398, 0.3015244, -0.13549966, -0.07433209, -0.2154322, 0.08626243, 0.08691749, -0.27768335, 0.20129625, -0.25110516, 0.100580424, 0.20634235, -0.049445, -0.030263336, -0.07400871, -0.21622524, -0.06387937, -0.32896656, -0.507313, -0.18882531, 0.07538769, -0.36687744, -0.12156589, 0.017601155, -0.00042121453, 0.00610549, 0.0038016152, -0.29164794, 0.097530276, 0.030996814, 0.15973984, -0.16489528, -0.043514118, 0.69870305, 0.05401157, -0.016611714, 0.06936291, 0.02985333, -0.17610958, -0.43028656, 0.2358565, 0.5384827, -0.30086905, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 8 Marc Chagall was born Moishe Shagal in 1887, into a Jewish family in Liozna , [1] near the city of Vitebsk , Belarus, then part of the Russian Empire . [c] [18] At the time of his birth, Vitebsk's population was about 66,000. Half of the population was Jewish. [16] A picturesque city of churches and synagogues, it was called \"Russian Toledo \" by artist Ilya Repin , after the cosmopolitan city of the former Spanish Empire . [19] Because the city was built mostly of wood, little of it survived years of occupation and destruction during World War II. Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} 1038 [0.12289584, 0.19771095, -0.49609926, 0.15436818, -0.3683883, 0.07807937, 0.3530502, -0.059554473, 0.17041667, -0.09993227, -0.12581128, -0.14822444, 0.1960066, -0.049037382, -0.22496143, -0.11782649, -0.029683743, -0.15135886, -0.07608065, -0.13164505, -0.15614808, -0.1281366, 0.26295242, -0.050093833, 0.508169, -0.37993705, 0.2143076, 0.017430518, -0.11382118, -0.0031905696, 0.13804077, 0.042828385, 0.102564044, -0.037603594, 0.059482064, 0.017253254, 0.10230875, -0.17457339, -0.081567675, -0.030254176, 0.009354096, 0.309923, -0.18747081, 0.15136003, -0.076821506, 0.072804056, 0.0394665, 0.16246986, -0.04693833, -0.057768002, -0.28829083, -0.07179849, 0.11064629, 0.080966555, 0.3141635, -0.31155917, -0.20154503, -0.032710448, 0.22301686, -0.018219613, 0.0082920715, -0.14288127, 0.14590013, 0.1464246, -0.21697515, 0.11366698, 0.041973703, -0.2781005, 0.059859313, -0.14236777, 0.1166666, 0.023176108, -0.15179297, 0.19413717, -0.19074057, -0.4553784, -0.10794483, 0.17236865, -0.319219, -0.10242921, 0.1510283, 0.09995351, 0.13968733, 0.23945294, -0.14752798, 0.08886419, -0.28502, 0.082560085, 0.021981327, 0.10126787, 0.41831374, 0.1802515, 0.14450534, -0.15728228, -0.08622702, -0.16223393, -0.16473386, 0.1673045, 0.024511559, -0.30024892, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 9 Chagall was the eldest of nine children. The family name, Shagal, is a variant of the name Segal , which in a Jewish community was usually borne by a Levitic family. [20] His father, Khatskl (Zachar) Shagal, was employed by a herring merchant, and his mother, Feige-Ite, sold groceries from their home. His father worked hard, carrying heavy barrels, earning 20 roubles each month (the average wages across the Russian Empire was 13 roubles a month). Chagall wrote of those early years: Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} 1039 [-0.19016051, 0.2662102, -0.40008038, 0.12919344, -0.4931461, 0.06254342, 0.4524838, -0.19770071, 0.35659614, -0.39628673, 0.0752513, -0.034594607, 0.100775726, -5.697031e-05, -0.0431388, 0.21718843, -0.18270254, 0.023722509, -0.08137782, -0.21935253, 0.23643914, -0.18530129, 0.19012834, -0.13759938, 0.29683122, -0.0026679556, 0.2592335, -0.045603562, 0.074348554, -0.15570927, -0.05742962, 0.024905544, 0.15878385, -0.06530662, 0.06710602, 0.1366059, 0.13979799, -0.26153907, 0.15460359, 0.17037603, 0.31496724, 0.1897313, 0.053521436, -0.04389488, -0.4255563, 0.0038219942, 0.18964615, -0.10599321, -0.019261595, 0.14236806, -0.77524954, -0.119407855, 0.32596987, -0.1358735, 0.46525088, -0.2871111, 0.08861766, -0.16499312, 0.15993859, -0.2544725, -0.45596844, -0.20720147, 0.079662286, -0.0106536085, -0.045571707, -0.19634902, -0.2437222, -0.34079152, 0.14983965, 0.025766388, -0.12969424, 0.14368069, 0.07250721, 0.29788, -0.46605885, -0.3884827, -0.16261555, 0.14219214, -0.34438896, -0.11124558, -0.31215012, -0.19792828, 0.09765506, 0.26211566, -0.18964094, 0.18680178, -0.15452722, 0.0019693451, -0.058514655, 0.16725062, 0.28203857, 0.1375037, 0.23745139, -0.045294467, 0.075898126, -0.058001257, 0.08730732, 0.021642098, -0.2295039, -0.06303484, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 <p>Similarly, we might want to add a CLIP embedding to our workflow; once again, it's just another computed column:</p> In\u00a0[19]: Copied! <pre>clip_model_id = 'openai/clip-vit-base-patch32'\n\nchunks.add_column(clip_embedding=clip(text=chunks.text, model_id=clip_model_id))\n</pre> clip_model_id = 'openai/clip-vit-base-patch32'  chunks.add_column(clip_embedding=clip(text=chunks.text, model_id=clip_model_id)) <pre>Computing cells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 479/479 [00:30&lt;00:00, 15.84cells/s]</pre> <pre>added 479 column values with 0 errors\n</pre> <pre>\n</pre> Out[19]: <pre>UpdateStatus(num_rows=479, num_computed_values=479, num_excs=0, updated_cols=[], cols_with_excs=[])</pre> In\u00a0[20]: Copied! <pre>chunks\n</pre> chunks Out[20]: Column Name Type Computed With pos int text string title string headings json sourceline int minilm_embedding array((None,), dtype=FLOAT) huggingface.sentence_transformer(text, model_id='paraphrase-MiniLM-L6-v2') clip_embedding array((None,), dtype=FLOAT) huggingface.clip(text=text, model_id='openai/clip-vit-base-patch32') source_doc document In\u00a0[21]: Copied! <pre>chunks.head()\n</pre> chunks.head() Out[21]: pos text title headings sourceline minilm_embedding clip_embedding source_doc 0 Marc Chagall - Wikipedia Jump to content Search Search Marc Chagall - Wikipedia {} 0 [-0.26239744, -0.11875608, -0.13270901, 0.048251476, 0.11987579, -0.0060523422, 0.32066357, 0.04835883, 0.29429552, -0.25400946, 0.6250121, 0.17804725, -0.0049092094, 0.26455665, -0.25857177, -0.04235531, 0.36528507, 0.23551288, 0.27595958, -0.3712053, 0.17573264, 0.0029876528, 0.23927844, -0.17485948, 0.1954067, -0.48891908, -0.7418267, -0.30720565, 0.23550902, -0.26159504, 0.5011105, -0.6918158, -0.25462586, -0.19169782, 0.5265674, 0.10684755, -0.3500413, -0.47890776, 0.27644473, 0.2624894, 0.055178, -0.1461069, -0.21482669, 0.7246923, -0.105297744, 0.5106913, -0.18174116, 0.45920599, 0.36721304, 0.51290447, -0.65757185, -0.4469795, -0.26267004, -0.44820127, 0.38971028, -0.1695206, -0.114350036, -0.07236255, 0.2645084, -0.5793037, 0.28047276, 0.091701195, -0.16436026, 0.10646367, -0.1461572, 0.19661109, 0.07363955, 0.21059886, 0.1799219, 0.1598077, -0.37105122, 0.25376227, -0.4467154, 0.6573318, -0.38872772, -0.2764637, -0.79460824, -0.08837392, -0.27318305, -0.21008545, 0.57023394, -0.3434785, 0.15152003, -0.30319378, -0.043730583, -0.3291485, 0.2555499, 0.060874756, 0.23776941, 0.29614958, 0.18648784, -0.35599723, 0.15256202, -0.084133916, -0.48064327, 0.30865645, 0.1097052, 0.11276893, 0.718605, -0.21019463, ...] [0.43900743, -0.20442066, -0.3703856, -0.24842092, 0.2525654, 0.10988422, 0.17879994, -0.196813, -0.21898538, 0.16312195, -0.11581904, 0.10922383, -0.3980483, 0.09145157, 0.10282475, -0.08496836, -0.26351994, 0.21744385, -0.3051855, -0.25689328, 0.3959951, 0.050230637, 0.069754474, 0.024919227, -0.23106074, 0.40560833, 0.055413835, 0.32912296, 0.308473, -0.5097272, -0.09413433, -0.11475259, 0.060904503, -0.4149298, 0.22001794, -0.18334071, -0.17864163, -0.31954357, 0.25738722, -0.22377047, 0.18910344, 0.026809722, -0.004293531, 0.40239182, 0.20990916, 0.097469255, -0.13026372, -0.22480412, -0.57115316, -0.08310877, 0.4732533, -0.18007854, 0.1250679, 0.086631775, 0.9078158, 0.2944157, 0.37376213, 0.0021959953, -0.45549828, 0.3129748, 0.1539275, 0.1920172, 0.4021812, 0.07109217, 0.1754788, -0.15966587, 0.23044436, 0.17929715, -0.062350556, -0.14394853, 0.08396445, -0.1978707, 0.15875788, 0.15464768, -0.12898067, -0.12406565, -0.4527824, 0.09551789, 0.0028743632, 0.68251455, -0.59881175, -0.33829093, -0.3487394, 0.075701036, -0.35363907, -0.31604585, -0.14599548, -0.5174625, -0.13107216, 0.020409035, -0.47953704, -0.080894835, -1.0206147, -0.15478382, 0.2360041, 0.29316625, -0.44745338, -0.07385804, -0.11532639, -0.1653951, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 1 Marc Chagall 81 languages Afrikaans Alemannisch \u0627\u0644\u0639\u0631\u0628\u064a\u0629 Aragon\u00e9s \u0531\u0580\u0565\u0582\u0574\u057f\u0561\u0570\u0561\u0575\u0565\u0580\u0567\u0576 Asturianu Az\u0259rbaycanca \u09ac\u09be\u0982\u09b2\u09be \u0411\u0430\u0448\u04a1\u043e\u0440\u0442\u0441\u0430 \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f \u0411\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f (\u0442\u0430\u0440\u0430\u0448\u043a\u0435\u0432\u0456\u0446\u0430) \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 Catal\u00e0 \u010ce\u0161tina Cymraeg Dansk Deutsch Eesti \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Espa\u00f1ol Esperanto Euskara \u0641\u0627\u0631\u0633\u06cc Fran\u00e7ais Galego \ud55c\uad6d\uc5b4 \u0540\u0561\u0575\u0565\u0580\u0565\u0576 \u0939\u093f\u0928\u094d\u0926\u0940 Hrvatski Ido Bahasa Indonesia Interlingua Italiano \u05e2\u05d1\u05e8\u05d9\u05ea Jawa \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 Kiswahili Latina Latvie\u0161u L\u00ebtzebuergesch Lietuvi\u0173 Magyar \u041c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438 Malagasy \u0645\u0635\u0631\u0649 Nederlands Nedersaksies \u65e5\u672c\u8a9e Norsk bokm\u00e5l Norsk nynorsk Occitan O\u02bbzbekcha / \u045e\u0437\u0431\u0435\u043a\u0447\u0430 \u067e\u0646\u062c\u0627\u0628\u06cc Picard Piemont\u00e8is Plattd\u00fc\u00fctsch Polski Portugu\u00eas Rom\u00e2n\u0103 Runa Simi \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Scots Shqip Sicilianu Simple English Sloven\u010dina Sloven\u0161\u010dina \u06a9\u0648\u0631\u062f\u06cc \u0421\u0440\u043f\u0441\u043a\u0438 / srpski Srpskohrvatski / \u0441\u0440\u043f\u0441\u043a\u043e\u0445\u0440\u0432\u0430\u0442\u0441\u043a\u0438 Suomi Svenska \u0e44\u0e17\u0e22 T\u00fcrk\u00e7e \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 Ti\u1ebfng Vi\u1ec7t Winaray \u5434\u8bed \u05d9\u05d9\u05b4\u05d3\u05d9\u05e9 \u7cb5\u8a9e \u4e2d\u6587 Edit links From Wikipedia, the free encyclopedia Russian-French artist (1887\u20131985) \"Chagall\" redirects here. For other uses, see Chagall (disambiguation) . Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 820 [-0.1363125, 0.40063262, -0.53002965, -0.18143149, -0.45316985, -0.124922395, 0.7796174, -0.24712479, 0.12325851, -0.22153592, 0.28455305, -0.4370274, 0.23156813, 0.14490244, -0.1085123, -0.28869802, 0.21817636, 0.7690572, -0.31989712, -0.44312742, 0.059898064, -0.08027313, 0.12561844, 0.20749849, -0.04779504, 0.2481188, 0.31219974, -0.08558018, -0.22011802, 0.3522022, 0.58977985, 0.07881048, 0.19522715, -0.14123625, 0.35312974, 0.24841884, -0.13180904, 0.27224553, 0.28210613, 0.13397679, 0.10607662, -0.09232119, 0.09185555, 0.18311317, 0.12448643, -0.050988674, -0.17604467, 0.015647216, -0.05244761, -0.24283391, -0.42616737, -0.45576864, -0.35507995, -0.43146488, 0.30693346, -0.9420446, -0.15023254, 0.73326993, 0.0008648038, -0.36632615, -0.5619301, 0.21601507, -0.6227495, 0.43365502, -0.2858443, -0.33551332, -0.044290252, 0.3440103, -0.2007212, 0.051950164, -0.14124432, -0.12208969, 0.17209955, 0.24971402, -0.114884056, -0.36850527, 0.2503845, 0.2248823, -0.23860496, 0.014345463, 0.13038495, -0.005723685, -0.030419044, -0.29217696, 0.23628014, -0.0753976, -0.011316212, -0.09114735, 0.6540441, -0.9468982, 0.51743305, 0.29965192, 0.23870105, -0.06947729, 0.50110245, -0.08394459, 0.15647276, -0.33553198, 0.086335674, -0.11068067, ...] [0.10576726, 0.0062548285, -0.15221648, 0.04325895, 0.28336343, -0.017216904, 0.048432305, 0.18082103, -0.38419753, 0.1942887, -0.3934702, 0.1703408, -0.29696217, 0.009378701, -0.07561199, 0.09139115, -0.21508363, -0.002944082, -0.23163866, -0.2664358, 0.43764433, -0.09557707, 0.04955954, 0.10321079, -0.4440287, 0.088803366, 0.31638646, 0.24560744, 0.3107057, -0.4979143, -0.100728914, -0.38821647, -0.109925725, -0.4855165, 0.01807117, -0.233836, -0.12965867, -0.2497466, 0.38025331, 0.019615296, 0.16431904, -0.005382888, 0.051134765, 0.285679, 0.0700022, 0.03818, 0.035019174, -0.11470949, -0.4450416, -0.056285903, 0.59716856, -0.09969357, -0.023412608, 0.032318383, 0.6703502, 0.15605195, 0.4311117, -0.081973225, -0.27741277, -0.102946505, 0.16821143, 0.33112323, 0.1849161, 0.2880625, -0.14098072, -0.03131099, 0.33622795, 0.06441298, 0.015533805, -0.0046834317, 0.09588139, 0.03722093, 0.1061594, 0.109761484, -0.39696816, -0.3427739, -0.2742528, 0.084733956, -0.04741838, 0.6563601, -0.75865734, -0.1213026, -0.36402082, -0.38133097, -0.399796, -0.6459371, -0.08603081, -0.22102787, -0.103263326, -0.057846203, -0.03279003, 0.15000474, -0.9866644, -0.15627575, 0.30921665, 0.52998817, -0.45030674, 0.08764841, 0.018438563, -0.012725789, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 2 Marc Chagall Chagall, c. 1920 Born Moishe Shagal ( 1887-07-06 ) 6 July 1887 (N.S.) Liozna , Vitebsk Governorate , Russian Empire [1] Died 28 March 1985 (1985-03-28) (aged\u00a097) Saint-Paul-de-Vence , France Nationality Russian, later French [2] Known\u00a0for Painting stained glass Notable work See list of artworks by Marc Chagall Movement Cubism Expressionism School of Paris Spouses Bella Rosenfeld \u200b \u200b ( m. 1915; died\u00a01944) \u200b Valentina (Vava) Brodsky \u200b \u200b ( m. 1952) \u200b [3] Children 2 [4] Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1015 [-0.008921713, 0.2953745, -0.27866575, 0.11898915, -0.10827372, 0.34317943, 0.30031225, -0.030542523, 0.140571, -0.28433242, -0.2565046, -0.05376678, 0.15980518, -0.0073799845, -0.28197083, 0.1605216, -0.03273403, -0.023190707, 0.028482616, 0.02866254, 0.2178052, 0.09019671, 0.052278988, 0.061336607, 0.16683066, -0.31540227, -0.019625362, -0.17355925, 0.02343002, -0.018515123, 0.14497948, 0.011320164, -0.3156602, 0.13852714, 0.10553112, -0.044779748, -0.25689107, -0.06320519, 0.25297517, 0.22012936, 0.07603831, 0.0792726, -0.09764494, 0.05466658, 0.17789416, -0.052053563, 0.26565787, 0.00021006167, -0.1526493, 0.12836061, -0.4405348, -0.26161498, 0.12986717, -0.21648112, 0.20075297, -0.44728103, -0.10824932, -0.06369618, 0.1275613, -0.23966262, -0.13780478, -0.046827924, -0.07935211, -0.03928666, -0.25900114, 0.12769607, 0.08089128, -0.10918328, 0.28736144, -0.09079674, 0.18327945, 0.009950456, -0.27137786, -0.015346631, -0.27941808, -0.093986854, -0.16076668, 0.057925873, -0.40844643, -0.32947126, 0.18667138, -0.01637459, 0.17409977, 0.33120197, 0.075517796, 0.048949778, -0.06265739, 0.0670907, 5.528424e-05, -0.00027803052, 0.2049149, 0.3010924, -0.05034807, 0.052502863, 0.10266558, 0.10392622, 0.101448216, 0.0930416, 0.08641965, -0.13062412, ...] [0.27890137, -0.20730078, -0.21657133, -0.11899415, 0.29705253, 0.13267045, 0.144259, 0.4943046, -0.0672164, 0.10724728, -0.28608358, 0.08189191, -0.1404834, -0.022452347, -0.075431496, -0.13546634, 0.023324817, -0.12881926, -0.3592385, -0.2945941, 0.50179446, 0.21628043, -0.23906408, 0.082132295, 0.015869483, -0.032170683, 0.059255913, 0.29289043, 0.4030633, -0.64645654, -0.20299308, -0.078597784, -0.10301193, -0.4085632, 0.0032864995, -0.40147346, -0.20502825, -0.4041382, 0.6891718, -0.036338326, 0.12626752, 0.028391868, -0.0016252697, 0.369042, 0.25803536, 0.07382333, -0.19590165, 0.035416022, -0.6005479, -0.024783045, 0.3842185, -0.044771258, -0.15902333, -0.1151039, 0.8336, 0.18546708, 0.5050619, -0.16106965, -0.23294158, 0.0684662, 0.20496517, 0.24494071, 0.3122273, 0.45877573, 0.009733893, 0.10309622, 0.114777304, 0.13349582, 0.0892286, 0.15880138, 0.098774984, -0.16649732, 0.1431975, 0.040802434, -0.19765553, -0.08852293, -0.274639, 0.21479043, -0.114407524, 0.5625518, -0.7192221, -0.17440435, -0.7244936, -0.1871125, -0.5983864, -0.47310275, -0.15488116, -0.36789304, -0.14778556, 0.11746228, -0.3866823, 0.08936779, -0.5849571, -0.18929294, 0.30989763, 0.46090806, -0.56554836, 0.05129993, -0.077630825, -0.14868318, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 3 Marc Chagall [a] (born Moishe Shagal ; 6 July\u00a0[ O.S. 24 June]\u00a01887 \u2013 28 March 1985) was a Russian-French artist. [b] An early modernist , he was associated with the \u00c9cole de Paris as well as several major artistic styles and created works in a wide range of artistic formats, including painting, drawings, book illustrations, stained glass , stage sets, ceramics, tapestries and fine art prints. Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1029 [0.06070795, 0.15527856, -0.18933804, 0.1676786, -0.08854648, 0.17130661, 0.15085012, -0.043867312, 0.15022112, -0.47134027, -0.28864872, -0.17173266, -0.047000878, 0.026633887, -0.06628941, 0.16065459, 0.11814179, 0.13180229, -0.004020047, -0.14932036, 0.17918746, 0.21494934, 0.09146305, 0.038962457, 0.038501732, -0.2523544, 0.2707501, -0.25661966, 0.13307239, -0.39810288, 0.21422932, 0.079853565, -0.2808314, -0.009454813, -0.00704834, 0.052204095, -0.21773988, -0.021139788, 0.11031103, 0.26661894, 0.21084817, 0.32182968, -0.09556146, 0.072593026, 0.12131224, -0.10451728, -0.010188689, -0.037562072, -0.22708271, 0.14353341, -0.37686625, -0.17414235, 0.21614799, -0.45889544, 0.07239775, -0.40199217, 0.07049387, 0.02676736, 0.15950078, -0.24915555, -0.09596315, -0.07551933, 0.19581802, -0.035720993, -0.10169222, -0.08450496, -0.091727786, -0.07791178, 0.12658142, -0.039653488, 0.027229717, 0.08718759, 0.037420988, -0.031369355, 0.021826634, -0.50100785, -0.18308267, 0.24249087, -0.30463615, -0.1627777, 0.39998814, -0.16028915, 0.034172066, 0.2015968, 0.08487637, 0.06755659, -0.050601058, 0.14891133, -0.025254607, -0.0067675593, 0.1215523, 0.16791311, -0.24602473, 0.080474414, -0.012239213, 0.09207286, 0.019633006, 0.24711514, 0.19672461, -0.0031050658, ...] [0.31319043, -0.1560022, -0.14035743, -0.061735544, 0.42363116, 0.07034189, 0.22905919, 0.76764786, -0.11780238, 0.113086894, -0.18308343, 0.2016515, -0.21681885, 0.041388772, -0.020286843, -0.09577894, -0.111465864, -0.004856445, -0.39506912, -0.18178557, 0.41950294, 0.13025184, -0.0733778, 0.017768443, -0.26477298, 0.031200737, 0.04882873, 0.24986002, 0.32550868, -0.6700022, -0.13368644, -0.16846476, -0.112990335, -0.48804194, 0.059935343, -0.2884813, -0.14705978, -0.20621212, 0.6466737, -0.077737086, 0.025872868, 0.11426908, 0.0791159, 0.368575, 0.25322148, 0.043255813, -0.18690658, 0.032138467, -0.56945956, 0.0041377842, 0.5705812, -0.11751311, -0.06906898, -0.16005844, 0.8113265, 0.29465753, 0.5470754, 0.12775023, -0.23945804, 0.12890235, 0.11779701, 0.17128803, 0.19173062, 0.34948987, 0.0593511, -0.00599128, 0.21449581, 0.17856844, -0.0017768741, -0.026937973, 0.20174496, 0.014691558, 0.15926166, 0.11113167, -0.23153263, -0.12869568, -0.41356862, 0.2590595, -0.12656093, 0.5451278, -0.585286, -0.18912783, -0.5723392, -0.12212754, -0.48440865, -0.5028284, -0.12991165, -0.23104712, -0.28743368, 0.11462467, -0.27056375, 0.023289394, -0.9101886, -0.01346302, 0.33331668, 0.44557577, -0.6020771, 0.09257904, -0.08192372, -0.07527991, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 4 Chagall was born in 1887, into a Jewish family near Vitebsk , today in Belarus , but at that time in the Pale of Settlement of the Russian Empire. Before World War I , he travelled between Saint Petersburg , Paris , and Berlin . During that period, he created his own mixture and style of modern art, based on his ideas of Eastern European and Jewish folklore. He spent the wartime years in his native Belarus, becoming one of the country's most distinguished artists and a member of the modernist avant-garde , founding the Vitebsk Arts College . He later worked in and near Moscow in difficult conditions during hard times in Russia following the Bolshevik Revolution , before leaving again for Paris in 1923. During World War II , he escaped occupied France to the United States, where he lived in New York City for seven years before returning to France in 1948. Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1030 [0.012889067, 0.24784814, -0.6924428, 0.1426121, -0.3790234, 0.25358468, 0.25536245, -0.12604716, 0.116000354, -0.34645474, -0.42178202, 0.019877212, 0.21520866, -0.06495547, -0.15178001, 0.11160548, -0.15971011, 0.06491916, -0.0047337115, -0.33831468, -0.27981135, -0.19120821, 0.3114935, -0.09731045, 0.41788405, -0.36130282, 0.1289389, -0.11600192, -0.041783914, -0.10795093, 0.2949969, -0.13806339, -0.14393348, -0.008052545, 0.016671669, 0.17721409, -0.03954895, -0.10124817, 0.0785659, 0.16309267, 0.18659109, 0.25182652, -0.086883925, 0.08496222, 0.099514656, 0.30495775, 0.17764322, 0.14045668, -0.18228962, 0.042524166, -0.23616257, -0.22173877, 0.12292056, -0.21659315, 0.20440893, -0.26627287, -0.028624976, 0.20077917, 0.17120816, -0.43130222, -0.08327547, -0.26314807, 0.2010209, 0.05320871, -0.23124723, 0.053521108, -0.14058796, -0.009598296, 0.25529027, 0.07367204, 0.108012736, 0.21220206, -0.31999534, -0.011201449, -0.1051358, -0.5790532, -0.09553775, 0.008409397, -0.23266529, -0.08355572, 0.32477862, 0.22916731, 0.07943112, 0.31860423, 0.08367223, 0.026719313, -0.014187841, 0.19423032, 0.059627395, -0.0067669214, 0.5294448, -0.035245955, 0.05879449, -0.06393026, 0.008244172, 0.19260912, 0.016116004, 0.3515519, 0.1926637, -0.24429806, ...] [0.3260236, 0.06720028, -0.06100463, -0.04561384, 0.2423084, 0.22669676, 0.035891097, 0.2509161, -0.106639236, 0.25306195, -0.19362219, 0.105219536, -0.24750978, -0.022878632, -0.010763168, -0.23732483, 0.020199887, 0.059316933, -0.4728327, -0.07102768, 0.41458455, 0.058558926, -0.16911799, 0.039997205, -0.23728761, 0.15409654, 0.16028914, 0.4212034, 0.2691457, -0.82328445, 0.020973414, -0.09555048, -0.0505076, -0.40467718, -0.10258034, -0.3156195, -0.14072889, -0.45515656, 0.6852393, 0.01587819, 0.21748453, 0.11716142, 0.08289739, 0.39309347, 0.38873634, -0.07149842, -0.20025074, -0.1520394, -0.7935029, 0.13830628, 0.1815696, -0.12217435, -0.04690223, -0.0042369366, 0.75748557, 0.0061985645, 0.36204237, 0.101865456, -0.044472437, 0.02997367, 0.156785, 0.19892272, 0.06683682, 0.56358945, -0.13283905, 0.16568443, 0.16774036, 0.05625753, 0.0010502934, 0.15627444, 0.27494252, -0.16978766, 0.070807844, -0.034206897, -0.037819564, -0.03261423, -0.35324097, -0.019239023, -0.03625813, 0.44367996, -0.54978395, -0.17079037, -0.58789563, -0.14337218, -0.5649993, -0.25570738, -0.06714849, -0.23282252, -0.0035443343, 0.25267553, -0.2822091, -0.14999099, -0.7506616, -0.05953388, 0.23797072, 0.38653335, -0.4898622, 0.0012848079, -0.10379305, -0.20454393, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 5 Art critic Robert Hughes referred to Chagall as \"the quintessential Jewish artist of the twentieth century\". According to art historian Michael J. Lewis, Chagall was considered to be \"the last survivor of the first generation of European modernists\". For decades, he \"had also been respected as the world's pre-eminent Jewish artist\". [15] Using the medium of stained glass, he produced windows for the cathedrals of Reims and Metz as well as the Fraum\u00fcnster in Z\u00fcrich , windows for the UN and the Art Institute of Chicago and the Jerusalem Windows in Israel. He also did large-scale paintings, including part of the ceiling of the Paris Op\u00e9ra . He experienced modernism's \"golden age\" in Paris, where \"he synthesized the art forms of Cubism , Symbolism , and Fauvism , and the influence of Fauvism gave rise to Surrealism \". Yet throughout these phases of his style \"he remained most emphatically a Jewish artist, whose work was one long dreamy reverie of life in his native village of Vitebsk.\" [16] \"When Matisse dies\", Pablo Picasso remarked in the 1950s, \"Chagall will be the only painter left who understands what colour really is\". [17] Marc Chagall - Wikipedia {'1': 'Marc Chagall'} 1031 [-0.1718488, 0.34802842, -0.3067041, 0.033759266, -0.07120789, 0.11081593, -0.015894428, -0.13356614, -0.033708245, -0.2419452, -0.44456822, 0.05929219, 0.020918187, 0.14204657, -0.24098685, 0.270058, -0.25892293, 0.045101464, 0.053786207, 0.112981185, -0.08186188, 0.076918334, 0.3056298, -0.1219505, 0.30861628, -0.20567948, 0.19921294, -0.12860534, -0.14399259, -0.060565773, 0.09843977, -0.10340746, -0.26555914, -0.027046643, 0.070481814, 0.07951172, -0.06800346, 0.0012837779, 0.23670606, 0.1605123, 0.08615838, 0.3051123, -0.027099106, -0.17317611, 0.014067065, -0.01578261, 0.12305312, 0.05461803, -0.20789422, 0.11169634, -0.243294, -0.1717479, 0.31153303, -0.477225, 0.08077119, -0.3160271, -0.108076364, -0.060807537, -0.12826538, -0.47114924, -0.11467476, -0.3874791, -0.18139084, 0.17687614, -0.033176806, -0.10800477, -0.113080636, -0.19606844, -0.022167385, 0.08167149, 0.077876404, 0.04912953, 0.019410212, 0.07751435, 0.11992899, -0.27325982, -0.07606392, -0.0123761445, -0.30934036, -0.05539541, 0.49092746, 0.054491326, 0.1359975, 0.29677787, 0.195668, -0.02722781, -0.10856432, 0.039952196, -0.06816634, 0.14353533, 0.10984236, 0.08890318, 0.12124765, 0.23209828, 0.18221292, 0.226612, -0.053041402, 0.17716643, -0.003824023, -0.22502854, ...] [0.37371883, 0.031517506, -0.31062502, -0.093097195, 0.24152097, 0.26400828, -0.16518655, 0.30133694, -0.08091084, 0.14807537, -0.15886195, 0.14782012, -0.19089215, -0.27328497, 0.027997017, -0.08933134, -0.13361098, -0.011525825, -0.5003743, -0.29616696, 0.43145713, 0.18745854, -0.19747896, 0.17880838, -0.47594684, 0.07138191, 0.33363938, 0.28388476, 0.30272815, -0.7221526, -0.13787824, -0.029895931, -0.13562766, -0.40576217, -0.09930601, -0.34826538, -0.2795905, -0.43808073, 0.6397612, 0.14684781, 0.2334369, 0.14553761, 0.07168442, 0.53430367, 0.036504, 0.011418276, -0.1445462, -0.3075632, -0.5589618, 0.17260133, 0.34423184, -0.15806657, -0.06070686, -0.12075645, 0.47494018, -0.093615875, 0.4080602, 0.031534944, -0.051487587, 0.021138325, 0.12258445, 0.3677423, -0.17544807, 0.6622064, 0.050919354, 0.10766199, 0.2418495, 0.2056752, 0.09901829, 0.010521844, 0.26210117, -0.031790487, 0.09848264, 0.12550955, -0.20656416, -0.17304093, -0.37142733, 0.16360284, -0.27655625, 0.5082086, -0.4015825, -0.13790771, -0.31900492, -0.040414073, -0.57742345, -0.2768371, -0.0019161701, -0.22578019, -0.17013973, 0.17284118, -0.0052040275, -0.21579233, -0.9814019, 0.037708744, 0.08085903, 0.42327997, -0.5028246, 0.038658917, -0.14375632, -0.16322409, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 6 Early life and education [ edit ] Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]'} 1034 [-0.21258694, 0.41762605, 0.09400449, 0.13499947, -0.06885149, 0.26491603, -0.12511107, 0.28833583, 0.04579986, 0.22168949, 0.29161087, -0.31456777, -0.31366986, 0.11542555, 0.08831894, 0.056974404, 0.2402763, -0.25183347, -0.12356235, -0.54612905, -0.09656416, 0.0660866, 0.25659195, -0.052964527, 0.4823795, 0.32737747, 0.086159095, -0.071204886, 0.12762076, 0.42564514, 0.02772967, -0.41478524, 0.5348886, -0.45198312, -0.47164515, 0.31659156, 0.8776631, 0.042706072, -0.255907, 0.044347186, -0.14535584, 0.2864719, -0.113270864, 0.19460054, 0.05073829, -0.15815656, 0.25129333, -0.2220522, -0.09832473, -0.12678048, -0.5666925, -0.12103812, 0.03459396, -0.35877624, 0.19099654, 0.32248336, -0.06600305, 0.4256649, -0.23869184, 0.067017615, -0.83746076, -0.26572597, -0.0097357035, 0.70784605, -0.07748319, 0.27188894, -0.06916828, 0.4451362, 0.1913614, -0.33502167, -0.15556404, -0.2711281, 0.118402824, 0.361828, -0.33293796, -0.13884008, 0.040201046, 0.33501458, 0.11592436, -0.79345524, 0.21795018, 0.23458, -0.09650008, 0.24245013, -0.2910435, 0.41454414, -0.4800957, 0.29933104, -0.14576554, -0.29111043, 0.64425385, -0.46670642, -0.48874134, 0.35364032, 0.6117833, 0.20667987, -0.5535579, -0.32985795, -0.13371441, -0.22560607, ...] [-0.11143042, -0.3177344, 0.043278307, 0.032855134, 0.041524187, -0.5313429, 0.45811015, -0.3606873, 0.054696023, -0.3428524, 0.3170445, -0.19573388, -0.027914956, -0.39266098, -0.026370842, 0.01974721, -0.39866096, -0.070209086, -0.26962164, 0.51094794, 0.32380602, 0.058651097, 0.09770484, -0.007524483, -0.2722217, 0.41854805, 0.2856537, -0.07448056, -0.23930608, -0.14176765, 0.20248072, -0.009274196, 0.43742988, -0.09010367, -0.5735017, -0.35785252, -0.35996717, 0.04306226, -0.035681237, -0.3756672, -0.04626941, 0.13364795, -0.049246185, -0.14865316, -0.15109596, -0.14720687, 0.31307077, -0.1954595, 0.40953222, -0.0045743138, 0.435866, -0.17121388, 0.027291171, -0.0052670687, -0.02731806, -0.30504042, 0.03360878, 0.4287191, 0.24126011, -0.08407598, 0.21431592, -0.4253294, -0.28839022, -0.27269614, -0.36684537, -0.3885652, -0.2741109, 0.4462211, -0.12703028, -0.32499513, -0.053103972, -0.14677432, 0.047115974, -0.060834333, 0.036224555, -0.17463647, 0.15566204, -0.102302015, -0.11055364, 0.052487373, -0.4164579, 0.065115996, 0.01235643, 1.1083236, -0.12187713, 0.15824632, 0.26677424, -0.3387624, 0.29505423, 0.23318543, 0.38895285, -0.49044752, -1.3143318, 0.068582594, 0.12922636, -0.17053914, -0.17255586, 0.51328915, -0.25261456, -0.19256735, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 7 Early life [ edit ] Marc Chagall's childhood home in Vitebsk , Belarus. Currently site of the Marc Chagall Museum . Marc Chagall, 1912, The Spoonful of Milk (La Cuiller\u00e9e de lait) , gouache on paper Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} 1035 [-0.040403567, 0.14281169, -0.35680732, 0.41181752, -0.33060923, 0.20134678, 0.15904729, 0.1680692, 0.23450555, -0.17853774, 0.076216996, -0.23785742, 0.047059476, 0.0723482, -0.5144092, 0.0059390757, 0.11763715, 0.16320866, 0.20046358, -0.31078827, 0.033091, -0.03074765, 0.26112205, -0.040257227, 0.33917278, 0.008225182, -0.21099399, -0.19426702, -0.17069323, -0.15220758, 0.06614052, -0.29302466, -0.16281912, -0.21634808, 0.0507121, 0.36889926, 0.2109983, -0.28517646, 0.046531904, 0.101085275, 0.17541906, 0.27149823, -0.024600174, 0.13682236, -0.073069565, 0.16629833, 0.33900666, -0.0226166, -0.1238528, 0.083200105, -0.60445195, -0.30993247, 0.21716255, -0.29389524, 0.16422015, -0.25379407, 0.059631355, 0.0020764398, 0.3015244, -0.13549966, -0.07433209, -0.2154322, 0.08626243, 0.08691749, -0.27768335, 0.20129625, -0.25110516, 0.100580424, 0.20634235, -0.049445, -0.030263336, -0.07400871, -0.21622524, -0.06387937, -0.32896656, -0.507313, -0.18882531, 0.07538769, -0.36687744, -0.12156589, 0.017601155, -0.00042121453, 0.00610549, 0.0038016152, -0.29164794, 0.097530276, 0.030996814, 0.15973984, -0.16489528, -0.043514118, 0.69870305, 0.05401157, -0.016611714, 0.06936291, 0.02985333, -0.17610958, -0.43028656, 0.2358565, 0.5384827, -0.30086905, ...] [-0.2106729, 0.1813906, -0.23682462, 0.15844774, 0.33680773, -0.14441323, 0.11554897, 0.8311518, -0.36302215, -0.17966662, -0.42524242, 0.14120685, -0.109049045, 0.38845176, 0.14302501, -0.33268875, -0.3242424, -0.060191467, -0.23298776, 0.4607867, 0.3490119, 0.13597272, -0.43231064, 0.24163917, 0.07982436, 0.04012401, 0.19880758, -0.030124325, 0.38552117, -0.7492682, -0.13019815, -0.0036394075, 0.1128995, -0.0040483996, -0.68424433, -0.24232826, 0.053719036, -0.29459232, 0.5278423, -0.098981336, -0.14561291, 0.025891736, 0.022710666, 0.13442543, -0.03602831, -0.10110382, 0.20455986, 0.0023501068, -0.20882827, -0.007938746, 0.66060054, 0.109627016, -0.28556165, -0.26774395, 0.64127535, 0.14560302, 0.3547237, 0.079871185, -0.49003696, 0.020767748, -0.16763894, -0.19990939, 0.08094209, -0.12488873, -0.1433922, -0.17905958, 0.066211194, 0.33662805, 0.057264388, 0.39783138, -0.017675027, -0.0054890737, 0.2644306, -0.062752895, -0.026210006, 0.28899932, 0.087647706, -0.009886503, -0.24725036, 0.30802214, -0.44759646, -0.062987104, -0.6606446, -0.2001296, -0.1659831, -0.30995846, -0.113578856, -0.40124434, 0.02397404, -0.0061898082, -0.17440921, 0.015801698, -0.4450708, 0.11005801, 0.61295617, 0.23613659, -0.60851413, 0.1676628, 0.021511607, -0.11083612, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 8 Marc Chagall was born Moishe Shagal in 1887, into a Jewish family in Liozna , [1] near the city of Vitebsk , Belarus, then part of the Russian Empire . [c] [18] At the time of his birth, Vitebsk's population was about 66,000. Half of the population was Jewish. [16] A picturesque city of churches and synagogues, it was called \"Russian Toledo \" by artist Ilya Repin , after the cosmopolitan city of the former Spanish Empire . [19] Because the city was built mostly of wood, little of it survived years of occupation and destruction during World War II. Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} 1038 [0.12289584, 0.19771095, -0.49609926, 0.15436818, -0.3683883, 0.07807937, 0.3530502, -0.059554473, 0.17041667, -0.09993227, -0.12581128, -0.14822444, 0.1960066, -0.049037382, -0.22496143, -0.11782649, -0.029683743, -0.15135886, -0.07608065, -0.13164505, -0.15614808, -0.1281366, 0.26295242, -0.050093833, 0.508169, -0.37993705, 0.2143076, 0.017430518, -0.11382118, -0.0031905696, 0.13804077, 0.042828385, 0.102564044, -0.037603594, 0.059482064, 0.017253254, 0.10230875, -0.17457339, -0.081567675, -0.030254176, 0.009354096, 0.309923, -0.18747081, 0.15136003, -0.076821506, 0.072804056, 0.0394665, 0.16246986, -0.04693833, -0.057768002, -0.28829083, -0.07179849, 0.11064629, 0.080966555, 0.3141635, -0.31155917, -0.20154503, -0.032710448, 0.22301686, -0.018219613, 0.0082920715, -0.14288127, 0.14590013, 0.1464246, -0.21697515, 0.11366698, 0.041973703, -0.2781005, 0.059859313, -0.14236777, 0.1166666, 0.023176108, -0.15179297, 0.19413717, -0.19074057, -0.4553784, -0.10794483, 0.17236865, -0.319219, -0.10242921, 0.1510283, 0.09995351, 0.13968733, 0.23945294, -0.14752798, 0.08886419, -0.28502, 0.082560085, 0.021981327, 0.10126787, 0.41831374, 0.1802515, 0.14450534, -0.15728228, -0.08622702, -0.16223393, -0.16473386, 0.1673045, 0.024511559, -0.30024892, ...] [0.27152428, -0.13698247, -0.2572204, -0.08675922, 0.42969704, 0.17921159, 0.22596544, 0.74167085, -0.1986554, 0.023573756, -0.1288221, 0.11156627, -0.2901746, 0.07495565, -0.018235408, -0.18144451, -0.06604696, -0.08419872, -0.43689924, -0.20866485, 0.38949496, 0.051266737, -0.11438696, -0.14504969, -0.14231065, -0.035830826, 0.17235345, 0.3132749, 0.23830715, -0.8352432, -0.20216438, -0.15945658, -0.21852452, -0.3853222, 0.10512352, -0.23563763, -0.2935429, -0.3082856, 0.5636081, 0.09332925, 0.03198697, 0.06579302, -0.030807257, 0.3039636, 0.23006293, 0.044860575, -0.17087252, 0.16843368, -0.56279254, 0.05256664, 0.5561236, -0.12561178, -0.09115761, -0.15193811, 0.95173144, 0.26651013, 0.47748995, 0.11504638, -0.19116402, 0.16940834, 0.17024904, 0.13633826, 0.3252074, 0.3592638, 0.010318585, -0.06500144, 0.19266394, 0.22522259, 0.021036088, 0.07234384, 0.23579478, 0.01980519, 0.1650174, 0.11221548, -0.20417781, -0.12707269, -0.30592173, 0.15413406, -0.0797362, 0.62609667, -0.6972417, -0.3098553, -0.6728849, -0.18736564, -0.4787558, -0.38787156, -0.13616131, -0.36475113, -0.25538492, 0.081598386, -0.23162037, 0.02140272, -0.93636477, -0.11674568, 0.32556087, 0.42079818, -0.62667125, -0.002921909, -0.11793229, -0.1351109, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51 9 Chagall was the eldest of nine children. The family name, Shagal, is a variant of the name Segal , which in a Jewish community was usually borne by a Levitic family. [20] His father, Khatskl (Zachar) Shagal, was employed by a herring merchant, and his mother, Feige-Ite, sold groceries from their home. His father worked hard, carrying heavy barrels, earning 20 roubles each month (the average wages across the Russian Empire was 13 roubles a month). Chagall wrote of those early years: Marc Chagall - Wikipedia {'1': 'Marc Chagall', '2': 'Early life and education[edit]', '3': 'Early life[edit]'} 1039 [-0.19016051, 0.2662102, -0.40008038, 0.12919344, -0.4931461, 0.06254342, 0.4524838, -0.19770071, 0.35659614, -0.39628673, 0.0752513, -0.034594607, 0.100775726, -5.697031e-05, -0.0431388, 0.21718843, -0.18270254, 0.023722509, -0.08137782, -0.21935253, 0.23643914, -0.18530129, 0.19012834, -0.13759938, 0.29683122, -0.0026679556, 0.2592335, -0.045603562, 0.074348554, -0.15570927, -0.05742962, 0.024905544, 0.15878385, -0.06530662, 0.06710602, 0.1366059, 0.13979799, -0.26153907, 0.15460359, 0.17037603, 0.31496724, 0.1897313, 0.053521436, -0.04389488, -0.4255563, 0.0038219942, 0.18964615, -0.10599321, -0.019261595, 0.14236806, -0.77524954, -0.119407855, 0.32596987, -0.1358735, 0.46525088, -0.2871111, 0.08861766, -0.16499312, 0.15993859, -0.2544725, -0.45596844, -0.20720147, 0.079662286, -0.0106536085, -0.045571707, -0.19634902, -0.2437222, -0.34079152, 0.14983965, 0.025766388, -0.12969424, 0.14368069, 0.07250721, 0.29788, -0.46605885, -0.3884827, -0.16261555, 0.14219214, -0.34438896, -0.11124558, -0.31215012, -0.19792828, 0.09765506, 0.26211566, -0.18964094, 0.18680178, -0.15452722, 0.0019693451, -0.058514655, 0.16725062, 0.28203857, 0.1375037, 0.23745139, -0.045294467, 0.075898126, -0.058001257, 0.08730732, 0.021642098, -0.2295039, -0.06303484, ...] [0.18217605, -0.07319644, -0.19468212, -0.14967602, 0.27654436, 0.24555618, 0.051268373, 0.34588543, -0.06652638, 0.20431729, -0.16331406, 0.26935354, -0.11542318, 0.009639803, 0.060736224, -0.22838107, -0.114356816, -0.0025013685, -0.38089743, -0.2933352, 0.5265533, 0.14625165, -0.32505187, 0.017311625, -0.3003168, 0.19884071, 0.27903628, 0.46846792, 0.39547157, -0.83511984, 0.07834871, -0.05997783, -0.12875333, -0.43704984, -0.14172675, -0.39207605, -0.11775714, -0.43573603, 0.7732164, -0.042661734, 0.19813177, 0.046419635, 0.04452227, 0.24076807, 0.23203501, 0.0570008, -0.26807785, -0.15271573, -0.8536604, 0.1862087, 0.14610264, -0.15371722, -0.12421906, -0.044895664, 0.71839833, -0.009791836, 0.33814403, 0.096963376, -0.12863003, 0.025278047, 0.12703587, 0.256715, 0.09690946, 0.39806953, -0.1784999, 0.040076897, 0.15242463, 0.25959492, -0.020206124, 0.047548197, 0.33762947, -0.067527674, -0.018146971, -0.011285953, -0.14204751, -0.075025454, -0.37610686, 0.11125929, -0.11869543, 0.44446653, -0.56478745, -0.074560374, -0.5185307, -0.15623264, -0.56246865, -0.32528496, 0.018042564, -0.1616676, -0.068809316, 0.18100347, 0.009668887, -0.29734492, -0.94131565, -0.11885197, 0.19610521, 0.2202949, -0.55619186, -0.15192273, -0.124419, 0.09338665, ...] /Users/asiegel/.pixeltable/file_cache/a34a1838d0db4b6297e5c301481ee747_0_3c5b8031c7610e17a42ab6df79e614c2ee1a85dbd022497373d574cf65e15c51"},{"location":"tutorials/rag-demo/#rag-operations-in-pixeltable","title":"RAG Operations in Pixeltable\u00b6","text":"<p>In this tutorial, we'll explore Pixeltable's flexible handling of RAG operations on unstructured text. In a traditional AI workflow, such operations might be implemented as a Python script that runs on a periodic schedule or in response to certain events. In Pixeltable, as with everything else, they are implemented as persistent table operations that update incrementally as new data becomes available. In our tutorial workflow, we'll chunk Wikipedia articles in various ways with a document splitter, then apply several kinds of embeddings to the chunks.</p> <p>To run this tutorial, you'll need to have Pixeltable installed, along with the Huggingface <code>sentence_transformers</code> package.</p>"},{"location":"tutorials/rag-demo/#set-up-the-table-structure","title":"Set Up the Table Structure\u00b6","text":"<p>We start by creating a Pixeltable client object.</p>"},{"location":"tutorials/rag-demo/#creating-tables-and-views","title":"Creating Tables and Views\u00b6","text":"<p>Now we'll create the tables that represent our workflow, starting with a table to hold references to source documents. The table contains a single column <code>source_doc</code> whose elements have type <code>pxt.DocumentType</code>, representing a general document instance. In this tutorial, we'll be working with HTML documents, but Pixeltable supports a range of other document types, such as Markdown and PDF.</p>"},{"location":"tutorials/rag-demo/#data-ingestion","title":"Data Ingestion\u00b6","text":""},{"location":"tutorials/rag-demo/#experimenting-with-chunking","title":"Experimenting with Chunking\u00b6","text":""},{"location":"tutorials/rag-demo/#further-experiments","title":"Further Experiments\u00b6","text":"<p>This is a good time to mention another important guiding principle of Pixeltable. The preceding examples all used the built-in <code>DocumentSplitter</code> class with various configurations. That's probably fine as a first cut or to prototype an application quickly, and it might be sufficient for some applications. But other applications might want to do more sophisticated kinds of chunking, implementing their own specialized logic or leveraging third-party tools. Pixeltable imposes no constraints on the AI or RAG operations a workflow uses: the iterator interface is highly general, and it's easy to implement new operations or adapt existing code or third-party tools into the Pixeltable workflow. Pixeltable manages data storage and workflow that is common to all such operations; above the data plane, it's fully general and extensible.</p> <p>TODO: Example of a custom splitter?</p>"},{"location":"tutorials/rag-demo/#adding-embeddings","title":"Adding embeddings\u00b6","text":""}]}